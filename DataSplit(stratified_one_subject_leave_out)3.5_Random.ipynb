{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled90.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNT85VSvfh5AufbHcegmbWS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/CongenitalGlaucoma_AI_project/blob/main/DataSplit(stratified_one_subject_leave_out)3.5_Random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data_split for one-subject-leave-out stratified 5-fold crossvalidation**"
      ],
      "metadata": {
        "id": "Dxlpd0AbAWf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZREKDUM5uudx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Leave one subject out cross validation + 5-fold stratified cross validation\n",
        "\n",
        "・1症例を抜き出し、その症例のすべての画像をテスト画像とする\n",
        "・残りの症例の内斜視、外斜視、斜視なし群を、同じ症例が群をまたがないように5分割する。\n",
        "・5分割したデータセットのうち4つをtraining、1つをvalidationとして用いてトレーニングを行い、抜き出した1症例のそれぞれの画像のおける正解率を算出する。これを5回繰り返してcross validationとする。\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TkRaZnYjAjZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29caebf-8d39-4f96-cc5d-0b61f99a88fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLeave one subject out cross validation + 5-fold stratified cross validation\\n\\n・1症例を抜き出し、その症例のすべての画像をテスト画像とする\\n・残りの症例の内斜視、外斜視、斜視なし群を、同じ症例が群をまたがないように5分割する。\\n・5分割したデータセットのうち4つをtraining、1つをvalidationとして用いてトレーニングを行い、抜き出した1症例のそれぞれの画像のおける正解率を算出する。これを5回繰り返してcross validationとする。\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nPSM5f-yyQfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349060b7-85df-4ac6-f667-f6038ee81a0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gla_ortho:  129\n",
            "gla_eso:  20\n",
            "gla_exo:  82\n",
            "cont_ortho:  387\n",
            "cont_eso:  60\n",
            "cont_exo:  246\n",
            "231\n",
            "693\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 2 #shuffleのシード\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "\n",
        "gla_ortho_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_ortho\"\n",
        "gla_eso_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_eso\"\n",
        "gla_exo_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_exo\"\n",
        "cont_ortho_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ortho\"\n",
        "cont_eso_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_eso\"\n",
        "cont_exo_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo\"\n",
        "result_csv_path = r\"F:\\先天性緑内障\\result_Random_3.csv\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "gla_ortho_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_d\"\n",
        "gla_eso_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_d__内斜視\"\n",
        "gla_exo_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_d__外斜視\"\n",
        "cont_ortho_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_control\"\n",
        "cont_eso_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_control__内斜視\\内斜視かぶりなし\"\n",
        "cont_exo_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_control__外斜視\\外斜視かぶりなし\"\n",
        "\"\"\"\n",
        "\n",
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_class(path_list, className):\n",
        "    class_list = list(itertools.repeat(className,len(path_list)))\n",
        "    return class_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "gla_ortho_path_list = make_path_list(gla_ortho_path)\n",
        "gla_eso_path_list = make_path_list(gla_eso_path)\n",
        "gla_exo_path_list = make_path_list(gla_exo_path)\n",
        "cont_ortho_path_list = make_path_list(cont_ortho_path)\n",
        "cont_eso_path_list = make_path_list(cont_eso_path)\n",
        "cont_exo_path_list = make_path_list(cont_exo_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "gla_dataset_path = gla_ortho_path_list + gla_eso_path_list + gla_exo_path_list\n",
        "gla_classes = extract_class(gla_ortho_path_list, \"ortho\") + extract_class(gla_eso_path_list, \"eso\") + extract_class(gla_exo_path_list, \"exo\")\n",
        "gla_id = extract_ids(gla_ortho_path_list) + extract_ids(gla_eso_path_list) + extract_ids(gla_exo_path_list)\n",
        "cont_dataset_path = cont_ortho_path_list + cont_eso_path_list + cont_exo_path_list\n",
        "cont_classes = extract_class(cont_ortho_path_list, \"ortho\") + extract_class(cont_eso_path_list, \"eso\") + extract_class(cont_exo_path_list, \"exo\")\n",
        "cont_id = extract_ids(cont_ortho_path_list) + extract_ids(cont_eso_path_list) + extract_ids(cont_exo_path_list)\n",
        "\n",
        "#convert to Numpy(for use of Scikit-Learn)\n",
        "gla_dataset_path = np.array(gla_dataset_path)\n",
        "gla_classes = np.array(gla_classes)\n",
        "gla_id = np.array(gla_id)\n",
        "cont_dataset_path = np.array(cont_dataset_path)\n",
        "cont_classes = np.array(cont_classes)\n",
        "cont_id = np.array(cont_id)\n",
        "\n",
        "print(\"gla_ortho: \", len(gla_ortho_path_list))\n",
        "print(\"gla_eso: \",len(gla_eso_path_list))\n",
        "print(\"gla_exo: \",len(gla_exo_path_list))\n",
        "\n",
        "print(\"cont_ortho: \", len(cont_ortho_path_list))\n",
        "print(\"cont_eso: \", len(cont_eso_path_list))\n",
        "print(\"cont_exo: \", len(cont_exo_path_list))\n",
        "\n",
        "\n",
        "print(len(gla_dataset_path))\n",
        "print(len(cont_dataset_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "------test_dataset[0]\n",
        "  |\n",
        "  |---train_dataset_gla[0]----0\n",
        "  |                        |--1\n",
        "  |                        |--2\n",
        "  |                        |--3\n",
        "  |                        |--4\n",
        "  |---train_dataset_cont[0]----0\n",
        "  |                         |--1\n",
        "  |                         |--2\n",
        "  |                         |--3\n",
        "  |                         |--4\n",
        "  |---val_dataset_gla[0]----0\n",
        "  |                      |--1\n",
        "  |                      |--2\n",
        "  |                      |--3\n",
        "  |                      |--4\n",
        "  |---val_dataset_cont[0]----0\n",
        "  |                       |--1\n",
        "  |                       |--2\n",
        "  |                       |--3\n",
        "  |                       |--4\n",
        "  |---test_dataset[1]\n",
        "  ...\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cBs5SZf2m7Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c7316c-d237-480a-cd84-8057ad734acd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n------test_dataset[0]\\n  |\\n  |---train_dataset_gla[0]----0\\n  |                        |--1\\n  |                        |--2\\n  |                        |--3\\n  |                        |--4\\n  |---train_dataset_cont[0]----0\\n  |                         |--1\\n  |                         |--2\\n  |                         |--3\\n  |                         |--4\\n  |---val_dataset_gla[0]----0\\n  |                      |--1\\n  |                      |--2\\n  |                      |--3\\n  |                      |--4\\n  |---val_dataset_cont[0]----0\\n  |                       |--1\\n  |                       |--2\\n  |                       |--3\\n  |                       |--4\\n  |---test_dataset[1]\\n  ...\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_gla, val_dataset_gla,train_dataset_cont, val_dataset_cont, testset, testset_label = [], [], [], [], [], []\n",
        "\n",
        "#まずglaのデータセットから1人分を抜き出す（LeaveOneGroupOut)\n",
        "# one group leave out 見本\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut\n",
        "# 今回のケースでは、groupがIDに該当\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(gla_dataset_path, gla_classes, gla_id)\n",
        "logo.get_n_splits(groups=gla_id)  # 'groups' is always required\n",
        "\n",
        "k=0\n",
        "for remain_index, test_index in logo.split(gla_dataset_path, gla_classes, gla_id):\n",
        "    gla_dataset_path_remain, gla_dataset_path_test = gla_dataset_path[remain_index], gla_dataset_path[test_index]\n",
        "    gla_classes_remain, gla_classes_test = gla_classes[remain_index], gla_classes[test_index]\n",
        "    gla_id_remain, gla_id_test = gla_id[remain_index], gla_id[test_index]\n",
        "    #print(gla_dataset_path, gla_dataset_path_test, gla_id_train, gla_id_test)\n",
        "    #print(\"test: \"+gla_id_test[0])\n",
        "    #print(\"TRAIN:\", remain_index, \"TEST:\", test_index)\n",
        "    #print(gla_dataset_path_test[0])\n",
        "    testset.append(gla_dataset_path_test.tolist())\n",
        "    testset_label.append(list(itertools.repeat(1, len(gla_dataset_path_test))))\n",
        "\n",
        "    #抜き出した残りのglaについてStratified group 5-foldをかける\n",
        "    # example of stratified group Kfold　見本\n",
        "    # 今回のケースでは、groupがID、yがclassesに該当\n",
        "\n",
        "    cv = StratifiedGroupKFold(n_splits=5, shuffle = True, random_state = random_seed)\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(gla_dataset_path_remain, gla_classes_remain, gla_id_remain):\n",
        "        #print(\"TRAIN:\", gla_classes_remain[train_idxs])\n",
        "        #print(\"      \", gla_id_remain[train_idxs])\n",
        "        #print(\"      \", gla_dataset_path_remain[train_idxs])\n",
        "        #print(\" TEST:\", gla_classes_remain[val_idxs])\n",
        "        #print(\"      \", gla_id_remain[val_idxs])\n",
        "        #print(\"      \", gla_dataset_path_remain[val_idxs])\n",
        "        train_miniset[m] = gla_dataset_path_remain[train_idxs].tolist()\n",
        "        val_miniset[m] = gla_dataset_path_remain[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_gla.append(train_miniset)\n",
        "    val_dataset_gla.append(val_miniset)\n",
        "    #print(\"train_dataset_added label[gla] \" + str(k))\n",
        "    k+=1\n",
        "\n",
        "    #control全体についてStratified group 5-foldをかける\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(cont_dataset_path, cont_classes, cont_id):\n",
        "        #print(\"TRAIN:\", cont_classes[train_idxs])\n",
        "        #print(\"      \", cont_id[train_idxs])\n",
        "        #print(\"      \", cont_dataset_path[train_idxs])\n",
        "        #print(\" TEST:\", cont_classes[val_idxs])\n",
        "        #print(\"      \", cont_id[val_idxs])\n",
        "        #print(\"      \", cont_dataset_path[val_idxs])\n",
        "        train_miniset[m] = cont_dataset_path[train_idxs].tolist()\n",
        "        val_miniset[m] = cont_dataset_path[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_cont.append(train_miniset)\n",
        "    val_dataset_cont.append(val_miniset)\n",
        "\n",
        "        \n",
        "#print(len(train_dataset_gla))    \n",
        "#print(len(val_dataset_gla))\n",
        "#print(val_dataset_gla)\n",
        "#print(len(train_dataset_cont))    \n",
        "#print(len(val_dataset_cont))\n",
        "#print(len(test_dataset))\n",
        "\n",
        "\n",
        "#同じくcontのデータセットから1人分抜き出してLeaveOneGroupOutをする\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(cont_dataset_path, cont_classes, cont_id)\n",
        "logo.get_n_splits(groups=cont_id)  # 'groups' is always required\n",
        "\n",
        "k=0\n",
        "for remain_index, test_index in logo.split(cont_dataset_path, cont_classes, cont_id):\n",
        "    cont_dataset_path_remain, cont_dataset_path_test = cont_dataset_path[remain_index], cont_dataset_path[test_index]\n",
        "    cont_classes_remain, cont_classes_test = cont_classes[remain_index], cont_classes[test_index]\n",
        "    cont_id_remain, cont_id_test = cont_id[remain_index], cont_id[test_index]\n",
        "    #print(cont_dataset_path_test[0])\n",
        "    testset.append(cont_dataset_path_test.tolist())\n",
        "    testset_label.append(list(itertools.repeat(0, len(cont_dataset_path_test))))\n",
        "\n",
        "    #抜き出した残りのcontについてStratified group 5-foldをかける\n",
        "\n",
        "    cv = StratifiedGroupKFold(n_splits=5, shuffle = True, random_state = random_seed)\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(cont_dataset_path_remain, cont_classes_remain, cont_id_remain):\n",
        "        train_miniset[m] = cont_dataset_path_remain[train_idxs].tolist()\n",
        "        val_miniset[m] = cont_dataset_path_remain[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_cont.append(train_miniset)\n",
        "    val_dataset_cont.append(val_miniset)\n",
        "\n",
        "    #gla全体についてStratified group 5-foldをかける\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(gla_dataset_path, gla_classes, gla_id):\n",
        "        train_miniset[m] = gla_dataset_path[train_idxs].tolist()\n",
        "        val_miniset[m] = gla_dataset_path[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_gla.append(train_miniset)\n",
        "    val_dataset_gla.append(val_miniset)\n",
        "    #print(\"train_dataset_added label[cont] \"+ str(k))\n",
        "    k+=1\n",
        "        \n",
        "print(len(train_dataset_gla))    \n",
        "print(len(val_dataset_gla))\n",
        "print(len(train_dataset_cont))    \n",
        "print(len(val_dataset_cont))\n",
        "print(len(testset))\n",
        "print(len(testset_label))\n"
      ],
      "metadata": {
        "id": "XLe8wZOkQkkk",
        "outputId": "61d33536-3b54-4173-f9ab-399515eb8e87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "723\n",
            "723\n",
            "723\n",
            "723\n",
            "723\n",
            "723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modules**"
      ],
      "metadata": {
        "id": "Ef0A_-M7wfS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "\n",
        "            \"\"\"\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \"\"\"\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        #####################\n",
        "        # test the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, test_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        test_acc = running_corrects.item()/len(test_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}' +'\\n'\n",
        "                     f'test_acc: {test_acc:.5f}' + f'({running_corrects:.0f}/{len(test_dataset):.0f})') \n",
        "\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "destination = \"F:\\先天性緑内障\\RepVGG-A2.pth\"\n",
        "\n",
        "if os.path.exists(destination) is not True:\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "else:\n",
        "    print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (\"F:\\先天性緑内障\\RepVGG-A2.pth\"))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "pt=4\n",
        "fold=2\n",
        "train_list = train_dataset_gla[pt][fold] + train_dataset_cont[pt][fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(train_dataset_cont[pt][fold])))\n",
        "val_list = val_dataset_gla[pt][fold] + val_dataset_cont[pt][fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(val_dataset_cont[pt][fold])))\n",
        "test_list = testset[pt]\n",
        "test_list_label = testset_label[pt]\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\n",
        "\n",
        "# Make a grid from batch\n",
        "inputs, classes = next(iter(test_loader))\n",
        "print(classes)\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "class_names = [\"cont\", \"gla\"]\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "#データセットの確認\n",
        "for i, j in zip(test_list, test_list_label):\n",
        "    print(i,j)\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n",
        "print(len(test_list))\n",
        "\n",
        "\"\"\"\n",
        "#データセットの確認\n",
        "for i, j in zip(train_list, train_list_label):\n",
        "    print(i,j)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NecL-52PwEgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training and evaluation**"
      ],
      "metadata": {
        "id": "cLaukgf2XfAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "#num_ftrs = model_ft.fc.in_features\n",
        "#model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load (\"F:\\先天性緑内障\\RepVGG-A2.pth\"))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=10, num_epochs=30)"
      ],
      "metadata": {
        "id": "CLT-Dhv-XiMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft.eval() # prep model for evaluation\n",
        "\n",
        "targets, preds =[], []\n",
        "for image_tensor, target in test_loader:  \n",
        "      #target = target.squeeze(1)     \n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model_ft(image_tensor)\n",
        "      _, pred = torch.max(output, 1)  \n",
        "      preds.append(int(pred))  #予測結果\n",
        "      targets.append(int(target)) #ラベル\n",
        "\n",
        "y_test = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "print(\"label: \", y_test)\n",
        "print(\"pred: \", y_pred)"
      ],
      "metadata": {
        "id": "hDpz1ontYFbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77dc2e57-79f1-465d-91f8-d1db568cc070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label:  [1]\n",
            "pred:  [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GradCAM (診断根拠の可視化)\n"
      ],
      "metadata": {
        "id": "uQaq2zGvr1bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n"
      ],
      "metadata": {
        "id": "-bg9YYJFr6ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split model in two parts\n",
        "features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        " #最後の2層\n",
        "\n",
        "#評価モードにする    \n",
        "model_ft = model_ft.eval()\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "\n",
        "classes = [\"cont\", \"gla\"]\n",
        "\n",
        "#画像のパスを指定\n",
        "#for j in range(1):\n",
        "for j in range(len(test_dataset)):\n",
        "\n",
        "    #元画像\n",
        "\n",
        "    image = test_dataset[j][0]\n",
        "    image = image.permute(1, 2, 0)\n",
        "\n",
        "    img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "    #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "    pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "    #pとcを対にして入力\n",
        "    for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "        sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "        tmp = image.to('cpu').detach().numpy().copy()\n",
        "        img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "        #TensorをImageに変換\n",
        "        sal = Image.fromarray(sal)\n",
        "        sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "        print()\n",
        "        #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "        #plt.title('')\n",
        "        print('label: '+classes[test_dataset[j][1]])\n",
        "        print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "        #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "        \n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        #グラフを1行2列に並べたうちの1番目\n",
        "        plt.subplots_adjust(wspace=0,hspace=0)\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "        #元の画像を並べて表示\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3QYH4diyu1h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated analysis**"
      ],
      "metadata": {
        "id": "MRzEYQQekA6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "pt_num = []\n",
        "k=0\n",
        "for data in testset:\n",
        "    pt_num.append([k]*len(data))\n",
        "    k+=1\n",
        "\n",
        "img_num = []\n",
        "for data in testset:\n",
        "    img_num.append(list(range(len(data))))\n",
        "\n",
        "patient_num = list(itertools.chain.from_iterable(pt_num))\n",
        "img_num = list(itertools.chain.from_iterable(img_num))\n",
        "patient_path = list(itertools.chain.from_iterable(testset))\n",
        "patient_label = list(itertools.chain.from_iterable(testset_label))\n",
        "\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"pt_number\",\"img_number\", \"path\",\"label\", \"0\",\"1\",\"2\",\"3\",\"4\", \"prob_1\", \"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"])\n",
        "df_result[\"pt_number\"] = patient_num\n",
        "df_result[\"img_number\"] = img_num\n",
        "df_result[\"path\"] = patient_path\n",
        "df_result[\"label\"] = patient_label\n",
        "\n",
        "df_result.to_csv(r\"F:\\先天性緑内障\\result.csv\",encoding=\"shift_jis\", index=False)\n",
        "df_result"
      ],
      "metadata": {
        "id": "hJAkQ_Bun31w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv"
      ],
      "metadata": {
        "id": "yOJJ87DGGkOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "#pt,foldの初期値を入力（CSVに対応）\n",
        "pt=0\n",
        "fold=0\n",
        "\n",
        "\n",
        "\n",
        "#Define Data Augumentation\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "for pt in range(pt,len(testset)): #指定したPtから開始\n",
        "    for fold in list(range(5)):\n",
        "        print(\"patient: \"+str(pt)+\", fold: \"+str(fold))\n",
        "\n",
        "        train_list = train_dataset_gla[pt][fold] + train_dataset_cont[pt][fold]\n",
        "        train_list_label = list(itertools.repeat(1, len(train_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(train_dataset_cont[pt][fold])))\n",
        "        val_list = val_dataset_gla[pt][fold] + val_dataset_cont[pt][fold]\n",
        "        val_list_label = list(itertools.repeat(1, len(val_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(val_dataset_cont[pt][fold])))\n",
        "        test_list = testset[pt]\n",
        "        test_list_label = testset_label[pt]\n",
        "\n",
        "        print(len(train_list))\n",
        "        print(len(val_list))\n",
        "        print(len(test_list))\n",
        "\n",
        "\n",
        "        #define dataset and dataloader\n",
        "        train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "        val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "        test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "        val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "        test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\n",
        "\n",
        "        # show sample image\n",
        "        inputs, classes = next(iter(test_loader))\n",
        "        print(classes)\n",
        "        out = torchvision.utils.make_grid(inputs)\n",
        "        class_names = [\"cont\", \"gla\"]\n",
        "        imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft.load_state_dict(torch.load (\"F:\\先天性緑内障\\RepVGG-A2.pth\"))   \n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "        #GPU使用\n",
        "        model_ft = model_ft.to(device)\n",
        "\n",
        "        #損失関数を定義\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Observe that all parameters are being optimized\n",
        "        #https://blog.knjcode.com/adabound-memo/\n",
        "        #https://pypi.org/project/torch-optimizer/\n",
        "        from ranger_adabelief import RangerAdaBelief\n",
        "        optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "        model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=10, num_epochs=30)\n",
        "\n",
        "\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10,8))\n",
        "        plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "        plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "        # find position of lowest validation loss\n",
        "        minposs = valid_loss.index(min(valid_loss))+1 \n",
        "        plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('loss')\n",
        "        plt.ylim(0, 1.0) # consistent scale\n",
        "        plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "        #Prediction for testset\n",
        "        model_ft.eval() # prep model for evaluation\n",
        "        targets, probs, preds =[], [], []\n",
        "        for image_tensor, target in test_loader:  \n",
        "              #target = target.squeeze(1)     \n",
        "              image_tensor = image_tensor.to(device)\n",
        "              target = target.to(device)\n",
        "              # forward pass: compute predicted outputs by passing inputs to the model\n",
        "              output = model_ft(image_tensor)\n",
        "              _, pred = torch.max(output, 1) \n",
        "            \n",
        "              prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "              prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "              print(prob)\n",
        "              print(pred) \n",
        "              \n",
        "              probs.append(prob)\n",
        "              preds.append(int(pred))  #予測結果\n",
        "              targets.append(int(target)) #ラベル\n",
        "        y_test = np.array(targets)\n",
        "        y_pred = np.array(preds)\n",
        "        y_prob = np.array(probs)\n",
        "        print(\"label\")\n",
        "        print(y_test)\n",
        "        print(\"pred\")\n",
        "        print(y_pred)\n",
        "        print(\"prob\")\n",
        "        print(y_prob)\n",
        "\n",
        "        #write result to df\n",
        "        row = 0\n",
        "        for i in testset[0:pt]:\n",
        "            row += len(i)\n",
        "        column = fold + 4\n",
        "        df_result.iloc[row:row+len(y_pred), column] = y_pred\n",
        "        column = fold + 9\n",
        "        df_result.iloc[row:row+len(y_pred), column] = y_prob\n",
        "        df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "        \n",
        "\n",
        "        #経過時間を表示\n",
        "        time_end = time.perf_counter()\n",
        "        time_elapsed = (time_end - time_start)\n",
        "        print(\"Elapsed time: \"+str(time_elapsed))\n",
        "\n"
      ],
      "metadata": {
        "id": "wu9YkXhfJBFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**データセットをフォルダにコピー**"
      ],
      "metadata": {
        "id": "tWzsW2q6mnYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#データのパスを指定\n",
        "pt=0\n",
        "fold=0\n",
        "train_list_gla = train_dataset_gla[pt][fold] \n",
        "train_list_cont = train_dataset_cont[pt][fold]\n",
        "val_list_gla = val_dataset_gla[pt][fold]\n",
        "val_list_cont = val_dataset_cont[pt][fold]\n",
        "\n",
        "#パスを指定\n",
        "train_gla = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\train\\gla\"\n",
        "train_cont = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\train\\cont\"\n",
        "val_gla = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\val\\gla\"\n",
        "val_cont = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\val\\cont\"\n",
        "\n",
        "orig_path = [train_list_gla, train_list_cont, val_list_gla, val_list_cont]\n",
        "dst_path = [train_gla, train_cont, val_gla, val_cont]\n",
        "\n",
        "\n",
        "for folder in dst_path:\n",
        "    if os.path.exists(folder):\n",
        "        shutil.rmtree(folder)\n",
        "    os.makedirs(folder, exist_ok=True) \n",
        "\n",
        "for i in orig_path:\n",
        "    print(len(i))\n",
        "\n",
        "\n",
        "for orig_img_list, dst_folder in zip(orig_path, dst_path):\n",
        "    if not orig_img_list:\n",
        "        pass\n",
        "    else:\n",
        "        for origpath in orig_img_list:\n",
        "            basepath = os.path.basename(origpath)\n",
        "            dstpath = os.path.join(dst_folder, basepath)\n",
        "            shutil.copyfile(origpath, dstpath)\n",
        "            print(dstpath+ \" copied!\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "t-5NN-_smwNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**結果のCSVを開く**"
      ],
      "metadata": {
        "id": "anmRZaRx0acX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "id": "HVZwL-S_xpla",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "66abc073-8569-457c-e649-a286703e1b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_result\u001b[49m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'df_result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "xdO8ZJ-qhV-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# \\\\1546-2.jpg\n",
        "# \\\\1546-2.jpg\n",
        "#アンダーバーとハイフンが混ざっておりIDが誤って振られているので修正\n",
        "######################################################################\n",
        "\n",
        "k = 0\n",
        "for i in range(len(df_result)):\n",
        "    if k==0:\n",
        "        pt_number = 0\n",
        "        img_number = 0\n",
        "    else:\n",
        "        pt_path = df_result.loc[k, \"path\"]\n",
        "        pt_id = re.split(\"[-_]\", pt_path.rsplit(\"\\\\\", maxsplit=1)[1])[0]\n",
        "        pt_path_prev = df_result.loc[k-1, \"path\"]\n",
        "        pt_id_prev = re.split(\"[-_]\", pt_path_prev.rsplit(\"\\\\\", maxsplit=1)[1])[0]\n",
        "        if pt_id == pt_id_prev:\n",
        "            pt_number = pt_number\n",
        "            img_number += 1\n",
        "        elif pt_id != pt_id_prev:\n",
        "            pt_number += 1\n",
        "            img_number = 0 \n",
        "\n",
        "    df_result.loc[k, \"pt_number\"] = pt_number #同じ患者ではimg_numberを通し番号で割り振る\n",
        "    df_result.loc[k, \"img_number\"] = img_number #同じ患者ではimg_numberを通し番号で割り振る\n",
        "    k+= 1\n",
        "\n",
        "df_result\n",
        " "
      ],
      "metadata": {
        "id": "Oms485LS8jZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#変更されたdf_resultの目視確認用\n",
        "df_result.to_csv(r\"F:\\先天性緑内障\\result_Random_確認用.csv\", encoding=\"shift_jis\")"
      ],
      "metadata": {
        "id": "p6a1VZLdKPfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df_result.columns.values[1:].tolist()\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df_result, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS[8:13]]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[FEATURE_COLS[8:13]]\n",
        "Y_test = test[\"label\"]\n"
      ],
      "metadata": {
        "id": "YWTX_kVS1Btc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "!pip install bayesian-optimization \n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS[8:13]:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"label\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"label\"]\n",
        "    #print(str(i))\n",
        "    #get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    #print(\"\")\n",
        "\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS[8:13]]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[FEATURE_COLS[8:13]]\n",
        "Y_test = test[\"label\"]\n"
      ],
      "metadata": {
        "id": "CYwTK7oJ2tIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "\n",
        "\"\"\"XGBoost で二値分類するサンプルコード\"\"\"\n",
        "\n",
        "X_train = train[FEATURE_COLS[8:13]]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[FEATURE_COLS[8:13]]\n",
        "Y_test = test[\"label\"]\n",
        "\n",
        "\n",
        "# XGBoost が扱うデータセットの形式に直す\n",
        "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=Y_test)\n",
        "# 学習用のパラメータ\n",
        "xgb_params = {\n",
        "    # 二値分類問題\n",
        "    'objective': 'binary:logistic',\n",
        "    # 評価指標\n",
        "    'eval_metric': 'logloss',\n",
        "}\n",
        "# モデルを学習する\n",
        "bst = xgb.train(xgb_params,\n",
        "                dtrain,\n",
        "                num_boost_round=100,  # 学習ラウンド数は適当\n",
        "                )\n",
        "# 検証用データが各クラスに分類される確率を計算する\n",
        "Y_pred_proba = bst.predict(dtest)\n",
        "# しきい値 0.5 で 0, 1 に丸める\n",
        "Y_pred = np.where(Y_pred_proba > 0.5, 1, 0)\n",
        "# 精度 (Accuracy) を検証する\n",
        "acc = accuracy_score(Y_test, Y_pred)\n",
        "print('Accuracy:', acc)\n",
        "\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
        "print(tp, fn, fp, tn)\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "\n",
        "print('confusion matrix = \\n', confusion_matrix(Y_test, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y_test, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y_test, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y_test, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y_test, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y_test, Y_pred)}')\n",
        "\n",
        "\n",
        "#ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, Y_pred_proba)     \n",
        "plt.plot(fpr, tpr, marker='o')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.grid()\n",
        "print(f'Area_under_ROC : {roc_auc_score(Y_test, Y_pred_proba)}')\n",
        "#plt.savefig('plots/roc_curve.png')\n"
      ],
      "metadata": {
        "id": "pto6ZDKycgFc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "f9d283b7-6c5a-43ef-f253-51054da50f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9027027027027027\n",
            "44 12 6 123\n",
            "confusion matrix = \n",
            " [[123   6]\n",
            " [ 12  44]]\n",
            "Accuracy : 0.9027027027027027\n",
            "Precision (true positive rate) : 0.88\n",
            "Recall (sensitivity): 0.7857142857142857\n",
            "Specificity : 0.9534883720930233\n",
            "F1 score : 0.830188679245283\n",
            "Area_under_ROC : 0.9504429678848283\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAW8klEQVR4nO3df5Dc9X3f8ecbIYUD25yLsBoObJGxLKJBbeS5ATtM46M4BlMP0uDUA6mnIUOj1C2eTpyRDUmDPaRTcKndHxMGR6kZbHfMD1OiUcdK1U7ghoyLbHAP88vIUYkjdNCBEBaPzGGJ07t/7B6sTnt3e3f73b3dz/Mxo2G/P3b3/eFWet338/ns5xuZiSSpXCf1ugBJUm8ZBJJUOINAkgpnEEhS4QwCSSrcyb0uYLHWrl2b69evX9Jzf/rTn3Laaad1tqAVzjaXwTaXYTlt/v73v/83mXlmq2N9FwTr16/n0UcfXdJzx8fHGRsb62xBK5xtLoNtLsNy2hwRfz3XMbuGJKlwBoEkFc4gkKTCGQSSVDiDQJIKV9msoYi4A/gY8GJmnt/ieAD/CbgceA24JjP/T1X1SNJKtmtiklv37uf52hRnDQ+x49KNbNsyctyxydoUI/seOO5YJ1Q5ffRO4I+Ar89x/KPAhsafC4HbG/+VpKLsmpjkhvufYOroNACTtSluuP+JN4/PdaxTYVBZEGTmQxGxfp5TtgJfz/o62PsiYjgifj4zX6iqJklaiW7du//Nf+hnTB2d5rP3PQ7AkeljJxy7de/+lR8EbRgBnmvaPtTYd0IQRMR2YDvAunXrGB8fX9IbHj58eMnP7Ve2uQy2ub9N1qZa7p8dALOf06n298U3izNzJ7ATYHR0NJf6zTq/ibgyzdc3uhT90OZOK7HN//ab/4tvP3nszc/NxeedyYPPvNSxz1E3jex7oGUYjAwPAa2DYmR4qGM/817OGpoEzmnaPruxTwWZ6RudrE2RvNX/uWvCj4LmtmtikjufPHLc5+a/7jvYt5+ji89ruQQQF593Jjsu3cjQ6lXH7R9avYodl27s2Pv38opgN3BdRNxNfZD4VccHyjNf3+hd3zu4pNes1aa4ff/DnSivb5TW5omDNY7M3WsCLP9z1E0TB2st9z/4zEv8m22bAd6aNVTB1U6V00fvAsaAtRFxCPg8sBogM78C7KE+dfQA9emjv1lVLVpYp7tn2vX8EvpGpXY/H/3yOZqrzpm/H9u2jLBty0hlXYBVzhq6eoHjCfzLqt5f7Ztv6lrVYTB86mpeee3oCfvfeepq7vntDy7pNet/WZb23H5VWpsvuqV1n/psI8NDS/4cddNc7TmrMUZQtb4YLFa1quieaddPpk4MAYDMSt9WfW7HpRv57Lcem7d7qNP96FXacenG434Zg+7W7xIT6mn3zPQc/+C/OkdASFC/Ur3m/DWMDA8R1H/z/+QH3n3c9s1Xbu6bWUPbtoxw85Wbe1a/VwQDZnZf/z969zRjCzznrOGhOaenVX1Z3etLYvWvXz5rNb/362O9LqNjZsYBesErggHSairmnU8eWXAK3XxT16rWjalxkubnFcEAadXXf+QYC/b1zzd1rWozvwH1YsaSpDqDoM81dwXNNb66UF//QlPXqtbLS2JJBkFfmz3tcy4LTcW0n14qm2MEfaxVV1ArC03FtJ9eKptXBH2s3a6bhaZi2k8vlc0g6GNzTftsdd5C7KeXymXXUB9r1aUz25qTsItH0rwMgj42823ENavqP8ZW36685vw1/qYvaV52DfW5bVtG3vyOQKuZQYNyBydJ1fGKQJIKZxBIUuEMAkkqnGMEXVLVHcB2TUzWb9s3fYyLbnnA+f+SFs0g6IKq7gA287ozawV1885ikgaHQdAFVd0BbOZKYPbr3rp3v0EgqW2OEXRBVXcA6/WqoZIGg1cEXVDVHcBcNVRSJ3hF0AVVre7pqqGSOsErgi6Y6a//7H2Pc2T6GCMdmjXkqqGSOsEg6ICqpoa2w1VDJS2XQbBM7UwNdZqnpJXMIFimdqaGOs1T0krmYPEytTM11GmeklYyg2AZdk1MclJEy2MzU0Pv+e0PMjLHdE6neUpaCQyCJZrp95+e487wF5935puPneYpaSVzjGCJWo0NNHvwmZfefOw0T0krmUEwj/mmhS7Uvz/7uNM8Ja1UlXYNRcRlEbE/Ig5ExPUtjr87Ih6MiImIeDwiLq+ynsWY6fqZrE2RvDXlc9fEJADDp66e9/n2/0vqF5VdEUTEKuA24FeBQ8AjEbE7M59uOu1fA/dm5u0RsQnYA6yvqqbFWGha6E+mjs75XPv/JfWTKq8ILgAOZOazmXkEuBvYOuucBN7ReHw68HyF9SzKQtNCp1uPEQNw85Wb7QaS1DeqHCMYAZ5r2j4EXDjrnC8A/zMiPg2cBny41QtFxHZgO8C6desYHx9fUkGHDx9u+7l/55Tg5ddP/Nf+jFOCT238GQdemPv48Kt/yfj4Xy6pxk5bTJsHhW0ug23unF4PFl8N3JmZX4qIDwLfiIjzM/O4b2Bl5k5gJ8Do6GiOjY0t6c3Gx8dp97l/cPrxS0dAvcvnD7ZuZmzLyILHV4rFtHlQ2OYy2ObOqTIIJoFzmrbPbuxrdi1wGUBmPhwRpwBrgRcrrKstC60Y6pRQSYOiyiB4BNgQEedSD4CrgF+fdc5B4BLgzoj4ReAU4CW6oBMrhjolVNIgqCwIMvONiLgO2AusAu7IzKci4ibg0czcDfwu8CcR8TvUB46vyZzjq7od5IqhkvSWSscIMnMP9SmhzftubHr8NHBRlTW04oqhkvSWItcacsVQSXpLcUHgiqGSdLyiguB/P3/UFUMlaZZef4+gq/7bj44ydXTusWhXDJVUoqKCoNU3gZu5YqikEhXVNXTGKa3HBmbY/y+pREUFwcfft/qEfv8Z9v9LKlVRQfDLZ63m5is3s2ZVvdmrGrOHRoaHXDFUUrGKGCOYWU5isjbF8NBTHGvMGvq7p5/iALCk4g18EMxeTqLWdEMZl42QpAK6hha6yfzMshGSVKqBD4J2loRw2QhJJRv4IGhnSqjTRiWVbOCDoNVSEc2cNiqpdAM/WDz7TmPDQ6uJgNprR102QpIoIAigHgZ3fe8gtVqNvZ/7SK/LkaQVZeC7hiRJ8zMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKZxBIUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCldpEETEZRGxPyIORMT1c5zziYh4OiKeiohvVlmPJOlEld2PICJWAbcBvwocAh6JiN2Z+XTTORuAG4CLMvOViHhXVfVIklqr8orgAuBAZj6bmUeAu4Gts875LeC2zHwFIDNfrLAeSVILVd6hbAR4rmn7EHDhrHPeBxAR3wFWAV/IzP8x+4UiYjuwHWDdunWMj48vuphabYrp6eklPbefHT582DYXwDaXoao29/pWlScDG4Ax4GzgoYjYnJm15pMycyewE2B0dDTHxsYW/Ua373+YWq3GUp7bz8bHx21zAWxzGapqc5VdQ5PAOU3bZzf2NTsE7M7Mo5n5V8CPqAeDJKlLqgyCR4ANEXFuRKwBrgJ2zzpnF/WrASJiLfWuomcrrEmSNEtlQZCZbwDXAXuBHwL3ZuZTEXFTRFzROG0v8HJEPA08COzIzJerqkmSdKJKxwgycw+wZ9a+G5seJ/CZxh9JUg/4zWJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUuEUHQUScFBH/pIpiJEndN2cQRMQ7IuKGiPijiPhI1H2a+jd/P9G9EiVJVZrvC2XfAF4BHgb+GfB7QADbMvOx6kuTJHXDfEHwC5m5GSAi/gvwAvDuzHy9K5VJkrpivjGCozMPMnMaOGQISNLgme+K4O9HxE+odwcBDDVtZ2a+o/LqJEmVmzMIMnNVNwuRJPXGnEEQEacA/xx4L/A4cEdjaWlJ0gCZb4zga8Ao8ARwOfClrlQkSeqq+cYINjXNGvoq8L3ulCRJ6qZ2Zw3ZJSRJA2q+K4JfaswSgvpMIWcNSdIAmi8IfpCZW7pWiSSpJ+brGsquVSFJ6pn5rgjeFRFz3lQ+M79cQT2SpC6bLwhWAW/jrW8WS5IG0HxB8EJm3tS1SiRJPTHfGIFXApJUgPmC4JKuVSFJ6pk5gyAz/7abhUiSesOb10tS4QwCSSqcQSBJhTMIJKlwBoEkFa7SIIiIyyJif0QciIjr5znv4xGRETFaZT2SpBNVFgQRsQq4DfgosAm4OiI2tTjv7cC/Ar5bVS2SpLlVeUVwAXAgM5/NzCPA3cDWFuf9IfBF4PUKa5EkzWG+tYaWawR4rmn7EHBh8wkR8X7gnMz8dkTsmOuFImI7sB1g3bp1jI+PL7qYWm2K6enpJT23nx0+fNg2F8A2l6GqNlcZBPOKiJOALwPXLHRuZu4EdgKMjo7m2NjYot/v9v0PU6vVWMpz+9n4+LhtLoBtLkNVba6ya2gSOKdp++zGvhlvB84HxiPix8AHgN0OGEtSd1UZBI8AGyLi3IhYA1wF7J45mJmvZubazFyfmeuBfcAVmflohTVJkmapLAgy8w3gOmAv8EPg3sx8KiJuiogrqnpfSdLiVDpGkJl7gD2z9t04x7ljVdYiSWrNbxZLUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVrogg2DUxycTBGvtfOcZFtzzAronJhZ8kSYUY+CDYNTHJDfc/wZHpYwBM1qa44f4nDANJahj4ILh1736mjk4ft2/q6DS37t3fo4okaWUZ+CB4vja1qP2SVJqBD4KzhocWtV+SSjPwQbDj0o0MrV513L6h1avYcenGHlUkSStLpfcsXgm2bRkB4LP3Pc6R6WOMDA+x49KNb+6XpNINfBBAPQzu+t5BarUaez/3D3tdjiStKAPfNSRJmp9BIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSpcpUEQEZdFxP6IOBAR17c4/pmIeDoiHo+IP4+I91RZjyTpRJUFQUSsAm4DPgpsAq6OiE2zTpsARjPz7wH3Af+uqnokSa1VeUVwAXAgM5/NzCPA3cDW5hMy88HMfK2xuQ84u8J6JEktVLno3AjwXNP2IeDCec6/FvizVgciYjuwHWDdunWMj48vuphabYrp6eklPbefHT582DYXwDaXoao2r4jVRyPik8Ao8KFWxzNzJ7ATYHR0NMfGxhb9Hrfvf5harcZSntvPxsfHbXMBbHMZqmpzlUEwCZzTtH12Y99xIuLDwO8DH8rMn1VYjySphSrHCB4BNkTEuRGxBrgK2N18QkRsAf4YuCIzX6ywFknSHCoLgsx8A7gO2Av8ELg3M5+KiJsi4orGabcCbwO+FRGPRcTuOV5OklSRSscIMnMPsGfWvhubHn+4yveXJC3MbxZLUuEMAkkqnEEgSYUzCCSpcAaBJBXOIJCkwhkEklQ4g0CSCmcQSFLhDAJJKpxBIEmFMwgkqXAGgSQVziCQpMIZBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFc4gkKTCGQSSVDiDQJIKV0QQ7JqYZOJgjf2vHOOiWx5g18Rkr0uSpBVj4INg18QkN9z/BEemjwEwWZvihvufMAwkqWHgg+DWvfuZOjp93L6po9Pcund/jyqSpJVl4IPg+drUovZLUmkGPgiGT129qP2SVJqBD4LMxe2XpNIMfBC8OnV0UfslqTSVBkFEXBYR+yPiQERc3+L4z0XEPY3j342I9Z2u4azhoUXtl6TSVBYEEbEKuA34KLAJuDoiNs067Vrglcx8L/AfgC92uo6LzztzUfslqTRVXhFcABzIzGcz8whwN7B11jlbga81Ht8HXBIR0ckiHnzmpUXtl6TSnFzha48AzzVtHwIunOuczHwjIl4FzgD+pvmkiNgObAdYt24d4+PjbRcxOcc00cna1KJep18dPny4iHY2s81lsM2dU2UQdExm7gR2AoyOjubY2Fjbzx3Z90DLMBgZHmIxr9OvxsfHi2hnM9tcBtvcOVV2DU0C5zRtn93Y1/KciDgZOB14uZNF7Lh0I0OrVx23b2j1KnZcurGTbyNJfavKIHgE2BAR50bEGuAqYPesc3YDv9F4/GvAA5mdneG/bcsIN1+5mZHGLKGR4SFuvnIz27aMdPJtJKlvVdY11Ojzvw7YC6wC7sjMpyLiJuDRzNwNfBX4RkQcAP6Welh03LYtI2zbMlLkpaQkLaTSMYLM3APsmbXvxqbHrwP/uMoaJEnzG/hvFkuS5mcQSFLhDAJJKpxBIEmFiw7P1qxcRLwE/PUSn76WWd9aLoBtLoNtLsNy2vyezGy5yFrfBcFyRMSjmTna6zq6yTaXwTaXoao22zUkSYUzCCSpcKUFwc5eF9ADtrkMtrkMlbS5qDECSdKJSrsikCTNYhBIUuEGMggi4rKI2B8RByLi+hbHfy4i7mkc/25ErO9BmR3VRps/ExFPR8TjEfHnEfGeXtTZSQu1uem8j0dERkTfTzVsp80R8YnGz/qpiPhmt2vstDY+2++OiAcjYqLx+b68F3V2SkTcEREvRsSTcxyPiPjPjf8fj0fE+5f9ppk5UH+oL3n9f4FfANYAPwA2zTrnXwBfaTy+Crin13V3oc0XA6c2Hn+qhDY3zns78BCwDxjtdd1d+DlvACaAdza239XrurvQ5p3ApxqPNwE/7nXdy2zzrwDvB56c4/jlwJ8BAXwA+O5y33MQrwguAA5k5rOZeQS4G9g665ytwNcaj+8DLomI6GKNnbZgmzPzwcx8rbG5j/od4/pZOz9ngD8Evgi83s3iKtJOm38LuC0zXwHIzBe7XGOntdPmBN7ReHw68HwX6+u4zHyI+v1Z5rIV+HrW7QOGI+Lnl/OegxgEI8BzTduHGvtanpOZbwCvAmd0pbpqtNPmZtdS/42iny3Y5sYl8zmZ+e1uFlahdn7O7wPeFxHfiYh9EXFZ16qrRjtt/gLwyYg4RP3+J5/uTmk9s9i/7wvqi5vXq3Mi4pPAKPChXtdSpYg4CfgycE2PS+m2k6l3D41Rv+p7KCI2Z2atl0VV7Grgzsz8UkR8kPpdD8/PzGO9LqxfDOIVwSRwTtP22Y19Lc+JiJOpX06+3JXqqtFOm4mIDwO/D1yRmT/rUm1VWajNbwfOB8Yj4sfU+1J39/mAcTs/50PA7sw8mpl/BfyIejD0q3bafC1wL0BmPgycQn1xtkHV1t/3xRjEIHgE2BAR50bEGuqDwbtnnbMb+I3G418DHsjGKEyfWrDNEbEF+GPqIdDv/cawQJsz89XMXJuZ6zNzPfVxkSsy89HelNsR7Xy2d1G/GiAi1lLvKnq2izV2WjttPghcAhARv0g9CF7qapXdtRv4p43ZQx8AXs3MF5bzggPXNZSZb0TEdcBe6jMO7sjMpyLiJuDRzNwNfJX65eMB6oMyV/Wu4uVrs823Am8DvtUYFz+YmVf0rOhlarPNA6XNNu8FPhIRTwPTwI7M7Nur3Tbb/LvAn0TE71AfOL6mn3+xi4i7qIf52sa4x+eB1QCZ+RXq4yCXAweA14DfXPZ79vH/L0lSBwxi15AkaREMAkkqnEEgSYUzCCSpcAaBJBXOIJDaFBHTEfFY05/1ETEWEa82tn8YEZ9vnNu8/5mI+Pe9rl+ay8B9j0Cq0FRm/lLzjsYS5n+RmR+LiNOAxyLivzcOz+wfAiYi4k8z8zvdLVlamFcEUodk5k+B7wPvnbV/CniMZS4MJlXFIJDaN9TULfSnsw9GxBnU1zR6atb+d1Jf7+eh7pQpLY5dQ1L7TugaavgHETEBHANuaSyBMNbY/wPqIfAfM/P/da1SaREMAmn5/iIzPzbX/og4F9gXEfdm5mNdrk1akF1DUsUay0HfAnyu17VIrRgEUnd8BfiVxiwjaUVx9VFJKpxXBJJUOINAkgpnEEhS4QwCSSqcQSBJhTMIJKlwBoEkFe7/AyY5sT+03dGxAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "\n",
        "for i in range(8,13):\n",
        "    print(\"fold\",i)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= 0.5, 1, 0)\n",
        "\n",
        "    acc = accuracy_score(Y, Y_pred)\n",
        "    print('Accuracy:',acc)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    print(tp, fn, fp, tn)\n",
        "\n",
        "    def specificity_score(label, pred):\n",
        "        tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "        return tn / (tn + fp)\n",
        "\n",
        "\n",
        "    print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "    #ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(Y, Y_pred_proba)     \n",
        "    plt.plot(fpr, tpr, marker='o')\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.grid()\n",
        "    print(f'Area_under_ROC : {roc_auc_score(Y, Y_pred_proba)}')\n",
        "    #plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "    accuracy.append(accuracy_score(Y, Y_pred))\n",
        "    precision.append(precision_score(Y, Y_pred))\n",
        "    recall.append(recall_score(Y, Y_pred))\n",
        "    specificity.append(specificity_score(Y, Y_pred))\n",
        "    f1score.append(f1_score(Y, Y_pred))\n",
        "    area_u_ROC.append(roc_auc_score(Y, Y_pred_proba))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "print(\"Result of 5-fold crossvalidation\")\n",
        "print(\"accuracy: \", statistics.mean(accuracy))\n",
        "print(\"precision: \", statistics.mean(precision))\n",
        "print(\"recall (sensitivity): \", statistics.mean(recall))\n",
        "print(\"specifiity: \", statistics.mean(specificity))\n",
        "print(\"f1_score: \", statistics.mean(f1score))\n",
        "print(\"area_u_ROC: \", statistics.mean(area_u_ROC))"
      ],
      "metadata": {
        "id": "JxVZZLTNv_Ko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6eb6cddb-d596-425a-b9db-1d21f87bce7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 8\n",
            "Accuracy: 0.920995670995671\n",
            "171 60 13 680\n",
            "confusion matrix = \n",
            " [[680  13]\n",
            " [ 60 171]]\n",
            "Accuracy : 0.920995670995671\n",
            "Precision (true positive rate) : 0.9293478260869565\n",
            "Recall (sensitivity): 0.7402597402597403\n",
            "Specificity : 0.9812409812409812\n",
            "F1 score : 0.8240963855421688\n",
            "Area_under_ROC : 0.9242018203057165\n",
            "\n",
            "fold 9\n",
            "Accuracy: 0.8971861471861472\n",
            "162 69 26 667\n",
            "confusion matrix = \n",
            " [[667  26]\n",
            " [ 69 162]]\n",
            "Accuracy : 0.8971861471861472\n",
            "Precision (true positive rate) : 0.8617021276595744\n",
            "Recall (sensitivity): 0.7012987012987013\n",
            "Specificity : 0.9624819624819625\n",
            "F1 score : 0.7732696897374702\n",
            "Area_under_ROC : 0.9289493575207861\n",
            "\n",
            "fold 10\n",
            "Accuracy: 0.9047619047619048\n",
            "157 74 14 679\n",
            "confusion matrix = \n",
            " [[679  14]\n",
            " [ 74 157]]\n",
            "Accuracy : 0.9047619047619048\n",
            "Precision (true positive rate) : 0.9181286549707602\n",
            "Recall (sensitivity): 0.6796536796536796\n",
            "Specificity : 0.9797979797979798\n",
            "F1 score : 0.7810945273631841\n",
            "Area_under_ROC : 0.9558291636213714\n",
            "\n",
            "fold 11\n",
            "Accuracy: 0.8603896103896104\n",
            "125 106 23 670\n",
            "confusion matrix = \n",
            " [[670  23]\n",
            " [106 125]]\n",
            "Accuracy : 0.8603896103896104\n",
            "Precision (true positive rate) : 0.8445945945945946\n",
            "Recall (sensitivity): 0.5411255411255411\n",
            "Specificity : 0.9668109668109668\n",
            "F1 score : 0.6596306068601584\n",
            "Area_under_ROC : 0.8576113641048706\n",
            "\n",
            "fold 12\n",
            "Accuracy: 0.9036796536796536\n",
            "164 67 22 671\n",
            "confusion matrix = \n",
            " [[671  22]\n",
            " [ 67 164]]\n",
            "Accuracy : 0.9036796536796536\n",
            "Precision (true positive rate) : 0.8817204301075269\n",
            "Recall (sensitivity): 0.70995670995671\n",
            "Specificity : 0.9682539682539683\n",
            "F1 score : 0.7865707434052758\n",
            "Area_under_ROC : 0.8725848466108206\n",
            "\n",
            "Result of 5-fold crossvalidation\n",
            "accuracy:  0.8974025974025974\n",
            "precision:  0.8870987266838826\n",
            "recall (sensitivity):  0.6744588744588744\n",
            "specifiity:  0.9717171717171718\n",
            "f1_score:  0.7649323905816514\n",
            "area_u_ROC:  0.907835310432713\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve描き直し\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.rcParams[\"font.family\"] = \"Helvetica\"   # 使用するフォント\n",
        "    plt.rcParams[\"font.size\"] = 10 \n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 1:\n",
        "                  y_true.append(1)\n",
        "            elif i == 0:\n",
        "                  y_true.append(0)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "for i in range(8,13):\n",
        "    print(\"fold\",i)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= 0.5, 1, 0)\n",
        "\n",
        "    label_list_list.append(Y)\n",
        "    model_pred_prob_list.append(Y_pred_proba)\n",
        "\n",
        "#Draw ROC curve\n",
        "roc_label_list = list(range(5))\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n"
      ],
      "metadata": {
        "id": "ZBDF-nm0oJll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "outputId": "8be7d9ce-f29c-46d6-ffd3-c06cf4aea65d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "findfont: Font family ['Helvetica'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold 8\n",
            "fold 9\n",
            "fold 10\n",
            "fold 11\n",
            "fold 12\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**患者ごとの正答率**"
      ],
      "metadata": {
        "id": "Cllzo5UeazmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "df_result"
      ],
      "metadata": {
        "id": "_XkW7jUva_GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Draw_roc_curve_patients(fpr_list, tpr_list, thred_list):\n",
        "\n",
        "    #グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = \"r\"     # プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    roc_auc = auc(fpr_list, tpr_list)\n",
        "\n",
        "    plt.plot(fpr_list, tpr_list, color=ycolor,lw=lw, label= 'ROC curve (area = %0.2f)' % roc_auc)\n",
        "        \n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    #prob = np.round(prob, decimals=3) #probabilityの数字を小数点3桁までにする（ROC curveに斜めの線が入るのを防ぐため）\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist()\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "    return int(pred)\n",
        "\n",
        "\n",
        "def calculate_fpr_tpr(pt_gla, pt_cont, df_result, threshold):\n",
        "    label_list, pred_list = [], []\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(label_list, pred_list).ravel()\n",
        "    fpr, tpr = fp/(tn+fp), tp/(tp+fn)\n",
        "    return fpr, tpr"
      ],
      "metadata": {
        "id": "SMgmeYVU5UKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "#ざっくり10点でROC curveを描いてみる\n",
        "thred_list = [i/100 for i in range(100)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)\n",
        "\n",
        "print(\"pt_gla: \", pt_gla)\n",
        "print(\"pt_cont: \", pt_cont)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "YU3yDjBr5J8b",
        "outputId": "8871dd01-8ef6-4617-e218-50181ac318df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_gla:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "pt_cont:  [39, 69, 74, 129, 132, 134, 138, 151, 167, 184, 203, 209, 227, 232, 245, 275, 336, 368, 403, 409, 410, 463, 497, 508, 515, 517, 518, 529, 532, 585, 587, 589, 590, 639, 672]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "threshold = 0.05 #判定基準。ここは先に入力しておく\n",
        "random.seed(100)\n",
        "#################################################\n",
        "\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "df_pt_analysis\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "print(Y)\n",
        "print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "##Calcurate the Youden's J static\n",
        "#https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "tpr = np.array(tpr_list)\n",
        "fpr = np.array(fpr_list)\n",
        "thresholds = np.array(thred_list)\n",
        "\n",
        "youdenJ = tpr - fpr\n",
        "\n",
        "# Calculate the G-mean\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "\n",
        "#Find the optimal threshold\n",
        "# Find the optimal threshold\n",
        "index = np.argmax(youdenJ)\n",
        "\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))\n",
        "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "print(\"\")\n",
        "\n",
        "##Youden's indexをもとにした正答率を計算\n",
        "#################################################\n",
        "threshold = thresholdOpt #判定基準\n",
        "#################################################\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "df_pt_analysis\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "#print(Y)\n",
        "#print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print(\"Using Youden's index\")\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')"
      ],
      "metadata": {
        "id": "IwAhKEE8bAUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc6c5ab-2391-4a6d-b620-13d524f5b221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "confusion matrix = \n",
            " [[29  6]\n",
            " [ 5 30]]\n",
            "Accuracy : 0.8428571428571429\n",
            "Precision (true positive rate) : 0.8333333333333334\n",
            "Recall (sensitivity): 0.8571428571428571\n",
            "Specificity : 0.8285714285714286\n",
            "F1 score : 0.8450704225352113\n",
            "\n",
            "Best Threshold: 0.06 with Youden J statistic: 0.8839\n",
            "FPR: 0.0571, TPR: 0.8286\n",
            "\n",
            "Using Youden's index\n",
            "confusion matrix = \n",
            " [[31  4]\n",
            " [ 6 29]]\n",
            "Accuracy : 0.8571428571428571\n",
            "Precision (true positive rate) : 0.8787878787878788\n",
            "Recall (sensitivity): 0.8285714285714286\n",
            "Specificity : 0.8857142857142857\n",
            "F1 score : 0.8529411764705883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**患者毎のROC curveを出す**"
      ],
      "metadata": {
        "id": "XwL_bOd5Kute"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Draw_roc_curve_patients(fpr_list, tpr_list, thred_list):\n",
        "\n",
        "    #グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = \"r\"     # プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    roc_auc = auc(fpr_list, tpr_list)\n",
        "\n",
        "    plt.plot(fpr_list, tpr_list, color=ycolor,lw=lw, label= 'ROC curve (area = %0.2f)' % roc_auc)\n",
        "        \n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    #prob = np.round(prob, decimals=3) #probabilityの数字を小数点3桁までにする（ROC curveに斜めの線が入るのを防ぐため）\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist()\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "    return int(pred)\n",
        "\n",
        "\n",
        "def calculate_fpr_tpr(pt_gla, pt_cont, df_result, threshold):\n",
        "    label_list, pred_list = [], []\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(label_list, pred_list).ravel()\n",
        "    fpr, tpr = fp/(tn+fp), tp/(tp+fn)\n",
        "    return fpr, tpr\n",
        " "
      ],
      "metadata": {
        "id": "Emx_Nw5NnJ62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "#ざっくり10点でROC curveを描いてみる\n",
        "thred_list = [i/100 for i in range(100)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)\n",
        "\n",
        "print(\"pt_gla: \", pt_gla)\n",
        "print(\"pt_cont: \", pt_cont)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "w5hlns7iMy9Q",
        "outputId": "9f98f5b3-c84a-46ce-9fe6-82b23cf96138"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_gla:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "pt_cont:  [40, 61, 88, 162, 164, 186, 199, 201, 206, 219, 232, 277, 288, 331, 381, 386, 406, 431, 440, 446, 493, 530, 554, 575, 590, 602, 614, 639, 652, 658, 668, 673, 688, 699, 716]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#点数を増やして描画し直し\n",
        "#※ものすごく時間かかる\n",
        "thred_list = [i/100000 for i in range(100000)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)"
      ],
      "metadata": {
        "id": "75OPzXtqTb-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**人力判定との比較**\n",
        "\n",
        "##使用データ\n",
        "- 緑内障群  \n",
        "各患者よりランダムに1枚ずつ選択（30枚）\n",
        "\n",
        "- コントロール群  \n",
        "ランダムに患者を選択し1枚ずつ選択（30枚）  \n",
        "内斜視:正位:外斜視 = 1:5:4\n",
        "\n",
        "\n",
        "##検討方法\n",
        "- AI群  \n",
        "one subject out stratified 5-fold crossvalidation法  \n",
        "5-foldの判定の多数決でpredを決定  \n",
        "Thresholdの決定にはYouden J staticを使用  \n",
        "\n",
        "- 人力群  \n",
        "緑内障のスペシャリスト 3名\n",
        "一般眼科医  3名  \n",
        "先天性緑内障の特徴について説明（角膜混濁、眼球あるいは角膜の拡大）  \n",
        "緑内障群、コントロール群の両方に斜視患者がいることを説明  \n",
        "画像を見てもらって判定  \n",
        "\n",
        "- 検討項目  \n",
        "感度、特異度、陽性的中率、F_value"
      ],
      "metadata": {
        "id": "hnQ-WPXIzFhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "F2JNknWcwa3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Draw_roc_curve_patients(fpr_list, tpr_list, thred_list):\n",
        "\n",
        "    #グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = \"r\"     # プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    roc_auc = auc(fpr_list, tpr_list)\n",
        "\n",
        "    plt.plot(fpr_list, tpr_list, color=ycolor,lw=lw, label= 'ROC curve (area = %0.2f)' % roc_auc)\n",
        "        \n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_fpr_tpr(pt_gla, pt_cont, df_result, threshold):\n",
        "    label_list, pred_list = [], []\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(label_list, pred_list).ravel()\n",
        "    fpr, tpr = fp/(tn+fp), tp/(tp+fn)\n",
        "    return fpr, tpr\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)"
      ],
      "metadata": {
        "id": "wsWUIAvb72Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "#患者ごとの正解率を計算\n",
        "#※結果の良いseedを探索\n",
        "###############################\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "\n",
        "seed_list = []\n",
        "f1_list = []\n",
        "specificity_list =  []\n",
        "sensitivity_list = []\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    #df_temp = df_temp.sample(n=1) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "\n",
        "for seed in list(range(1200, 1300, 1)):\n",
        "    random.seed(seed) #結果の良いrandom seedを探索する\n",
        "\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "    #gla群\n",
        "    pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "    #cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "    pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "    pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "    ##Calcurate the Youden's J static\n",
        "    #https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "    thred_list = [i/100 for i in range(1, 15, 1)] #Threshold 0.01-0.15を探索\n",
        "    fpr_list = []\n",
        "    tpr_list = []\n",
        "    cutoff_criterions = []\n",
        "\n",
        "    for i in thred_list:\n",
        "        fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "        fpr_list.append(fpr)\n",
        "        tpr_list.append(tpr)\n",
        "\n",
        "    tpr = np.array(tpr_list)\n",
        "    fpr = np.array(fpr_list)\n",
        "    thresholds = np.array(thred_list)\n",
        "\n",
        "    youdenJ = tpr - fpr\n",
        "    \n",
        "    # Calculate the G-mean\n",
        "    gmean = np.sqrt(tpr * (1 - fpr))\n",
        "\n",
        "    #Find the optimal threshold\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(youdenJ)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "    ##Youden's indexをもとにした正答率を計算\n",
        "    #################################################\n",
        "    threshold = thresholdOpt #判定基準\n",
        "    #################################################\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    Y = df_pt_analysis[\"label\"].tolist()\n",
        "    Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    #print(tp, fn, fp, tn)\n",
        "    \"\"\"\n",
        "    print(f'Random_seed : {str(seed)}')\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "    print(\"\")\n",
        "    \"\"\"\n",
        "\n",
        "    seed_list.append(seed)\n",
        "    f1_list.append(f1_score(Y, Y_pred))\n",
        "    specificity_list.append(specificity_score(Y, Y_pred))\n",
        "    sensitivity_list.append(recall_score(Y, Y_pred))\n",
        "\n",
        "print(seed_list)\n",
        "print(f1_list)\n",
        "\n",
        "max_value = max(f1_list)\n",
        "idx = f1_list.index(max_value)\n",
        "print(\"best_seed: \", seed_list[idx])\n",
        "print(\"best_f1_score: \", f1_list[idx])\n",
        "\n",
        "\n",
        "df_f1 = pd.DataFrame(columns = [])\n",
        "df_f1[\"seed\"] = seed_list\n",
        "df_f1[\"f1_score\"] = f1_list\n",
        "df_f1[\"specificity\"] = specificity_list\n",
        "df_f1[\"sensitivity\"] = sensitivity_list\n",
        "df_f1"
      ],
      "metadata": {
        "id": "8mcX3i_VRGjM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cda7c548-b5ce-4080-eedc-7e0a387708eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299]\n",
            "[0.8787878787878788, 0.904109589041096, 0.9166666666666667, 0.8648648648648648, 0.9166666666666667, 0.8125, 0.8533333333333333, 0.888888888888889, 0.8529411764705883, 0.904109589041096, 0.8533333333333333, 0.8656716417910447, 0.8125, 0.8767123287671234, 0.8923076923076922, 0.8767123287671234, 0.8253968253968255, 0.8387096774193549, 0.8656716417910447, 0.8767123287671234, 0.9142857142857143, 0.888888888888889, 0.8787878787878788, 0.8823529411764706, 0.8787878787878788, 0.8405797101449276, 0.8529411764705883, 0.8421052631578947, 0.88, 0.8219178082191781, 0.8695652173913043, 0.8484848484848486, 0.8648648648648648, 0.8918918918918919, 0.8524590163934427, 0.8307692307692307, 0.8181818181818182, 0.888888888888889, 0.9014084507042254, 0.9014084507042254, 0.8285714285714286, 0.8450704225352113, 0.904109589041096, 0.8648648648648648, 0.8253968253968255, 0.8115942028985507, 0.8656716417910447, 0.8571428571428571, 0.8285714285714286, 0.8529411764705883, 0.8529411764705883, 0.888888888888889, 0.8787878787878788, 0.8923076923076922, 0.8533333333333333, 0.8571428571428571, 0.8767123287671234, 0.8571428571428571, 0.787878787878788, 0.8529411764705883, 0.8307692307692307, 0.8571428571428571, 0.8533333333333333, 0.8787878787878788, 0.8648648648648648, 0.9166666666666667, 0.8571428571428571, 0.8787878787878788, 0.8648648648648648, 0.8767123287671234, 0.8285714285714286, 0.8918918918918919, 0.8529411764705883, 0.8405797101449276, 0.8918918918918919, 0.9014084507042254, 0.888888888888889, 0.9014084507042254, 0.8767123287671234, 0.8253968253968255, 0.8648648648648648, 0.8285714285714286, 0.9295774647887323, 0.8524590163934427, 0.9565217391304348, 0.8529411764705883, 0.8787878787878788, 0.8823529411764706, 0.9142857142857143, 0.8823529411764706, 0.8055555555555555, 0.888888888888889, 0.88, 0.9275362318840579, 0.9014084507042254, 0.8648648648648648, 0.8787878787878788, 0.8571428571428572, 0.8767123287671234, 0.8307692307692307]\n",
            "best_seed:  1284\n",
            "best_f1_score:  0.9565217391304348\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    seed  f1_score  specificity  sensitivity\n",
              "0   1200  0.878788     0.942857     0.828571\n",
              "1   1201  0.904110     0.857143     0.942857\n",
              "2   1202  0.916667     0.885714     0.942857\n",
              "3   1203  0.864865     0.800000     0.914286\n",
              "4   1204  0.916667     0.885714     0.942857\n",
              "5   1205  0.812500     0.914286     0.742857\n",
              "6   1206  0.853333     0.771429     0.914286\n",
              "7   1207  0.888889     0.857143     0.914286\n",
              "8   1208  0.852941     0.885714     0.828571\n",
              "9   1209  0.904110     0.857143     0.942857\n",
              "10  1210  0.853333     0.771429     0.914286\n",
              "11  1211  0.865672     0.914286     0.828571\n",
              "12  1212  0.812500     0.914286     0.742857\n",
              "13  1213  0.876712     0.828571     0.914286\n",
              "14  1214  0.892308     0.971429     0.828571\n",
              "15  1215  0.876712     0.828571     0.914286\n",
              "16  1216  0.825397     0.942857     0.742857\n",
              "17  1217  0.838710     0.971429     0.742857\n",
              "18  1218  0.865672     0.914286     0.828571\n",
              "19  1219  0.876712     0.828571     0.914286\n",
              "20  1220  0.914286     0.914286     0.914286\n",
              "21  1221  0.888889     0.857143     0.914286\n",
              "22  1222  0.878788     0.942857     0.828571\n",
              "23  1223  0.882353     0.914286     0.857143\n",
              "24  1224  0.878788     0.942857     0.828571\n",
              "25  1225  0.840580     0.857143     0.828571\n",
              "26  1226  0.852941     0.885714     0.828571\n",
              "27  1227  0.842105     0.742857     0.914286\n",
              "28  1228  0.880000     0.800000     0.942857\n",
              "29  1229  0.821918     0.771429     0.857143\n",
              "30  1230  0.869565     0.885714     0.857143\n",
              "31  1231  0.848485     0.914286     0.800000\n",
              "32  1232  0.864865     0.800000     0.914286\n",
              "33  1233  0.891892     0.828571     0.942857\n",
              "34  1234  0.852459     1.000000     0.742857\n",
              "35  1235  0.830769     0.914286     0.771429\n",
              "36  1236  0.818182     0.885714     0.771429\n",
              "37  1237  0.888889     0.857143     0.914286\n",
              "38  1238  0.901408     0.885714     0.914286\n",
              "39  1239  0.901408     0.885714     0.914286\n",
              "40  1240  0.828571     0.828571     0.828571\n",
              "41  1241  0.845070     0.828571     0.857143\n",
              "42  1242  0.904110     0.857143     0.942857\n",
              "43  1243  0.864865     0.800000     0.914286\n",
              "44  1244  0.825397     0.942857     0.742857\n",
              "45  1245  0.811594     0.828571     0.800000\n",
              "46  1246  0.865672     0.914286     0.828571\n",
              "47  1247  0.857143     0.742857     0.942857\n",
              "48  1248  0.828571     0.828571     0.828571\n",
              "49  1249  0.852941     0.885714     0.828571\n",
              "50  1250  0.852941     0.885714     0.828571\n",
              "51  1251  0.888889     0.857143     0.914286\n",
              "52  1252  0.878788     0.942857     0.828571\n",
              "53  1253  0.892308     0.971429     0.828571\n",
              "54  1254  0.853333     0.771429     0.914286\n",
              "55  1255  0.857143     0.742857     0.942857\n",
              "56  1256  0.876712     0.828571     0.914286\n",
              "57  1257  0.857143     0.742857     0.942857\n",
              "58  1258  0.787879     0.857143     0.742857\n",
              "59  1259  0.852941     0.885714     0.828571\n",
              "60  1260  0.830769     0.914286     0.771429\n",
              "61  1261  0.857143     0.857143     0.857143\n",
              "62  1262  0.853333     0.771429     0.914286\n",
              "63  1263  0.878788     0.942857     0.828571\n",
              "64  1264  0.864865     0.800000     0.914286\n",
              "65  1265  0.916667     0.885714     0.942857\n",
              "66  1266  0.857143     0.742857     0.942857\n",
              "67  1267  0.878788     0.942857     0.828571\n",
              "68  1268  0.864865     0.800000     0.914286\n",
              "69  1269  0.876712     0.828571     0.914286\n",
              "70  1270  0.828571     0.828571     0.828571\n",
              "71  1271  0.891892     0.828571     0.942857\n",
              "72  1272  0.852941     0.885714     0.828571\n",
              "73  1273  0.840580     0.857143     0.828571\n",
              "74  1274  0.891892     0.828571     0.942857\n",
              "75  1275  0.901408     0.885714     0.914286\n",
              "76  1276  0.888889     0.857143     0.914286\n",
              "77  1277  0.901408     0.885714     0.914286\n",
              "78  1278  0.876712     0.828571     0.914286\n",
              "79  1279  0.825397     0.942857     0.742857\n",
              "80  1280  0.864865     0.800000     0.914286\n",
              "81  1281  0.828571     0.828571     0.828571\n",
              "82  1282  0.929577     0.914286     0.942857\n",
              "83  1283  0.852459     1.000000     0.742857\n",
              "84  1284  0.956522     0.971429     0.942857\n",
              "85  1285  0.852941     0.885714     0.828571\n",
              "86  1286  0.878788     0.942857     0.828571\n",
              "87  1287  0.882353     0.914286     0.857143\n",
              "88  1288  0.914286     0.914286     0.914286\n",
              "89  1289  0.882353     0.914286     0.857143\n",
              "90  1290  0.805556     0.771429     0.828571\n",
              "91  1291  0.888889     0.857143     0.914286\n",
              "92  1292  0.880000     0.800000     0.942857\n",
              "93  1293  0.927536     0.942857     0.914286\n",
              "94  1294  0.901408     0.885714     0.914286\n",
              "95  1295  0.864865     0.800000     0.914286\n",
              "96  1296  0.878788     0.942857     0.828571\n",
              "97  1297  0.857143     0.971429     0.771429\n",
              "98  1298  0.876712     0.828571     0.914286\n",
              "99  1299  0.830769     0.914286     0.771429"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>specificity</th>\n",
              "      <th>sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1200</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1201</td>\n",
              "      <td>0.904110</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1202</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1203</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1204</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1205</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1206</td>\n",
              "      <td>0.853333</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1207</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1208</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1209</td>\n",
              "      <td>0.904110</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1210</td>\n",
              "      <td>0.853333</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1211</td>\n",
              "      <td>0.865672</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1212</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1213</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1214</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1215</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1216</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1217</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1218</td>\n",
              "      <td>0.865672</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1219</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1220</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>1221</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1222</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>1223</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>1224</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>1225</td>\n",
              "      <td>0.840580</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1226</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1227</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>1228</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>1229</td>\n",
              "      <td>0.821918</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>1230</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>1231</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>1232</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>1233</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>1234</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>1235</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>1236</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>1237</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>1238</td>\n",
              "      <td>0.901408</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>1239</td>\n",
              "      <td>0.901408</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>1240</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>1241</td>\n",
              "      <td>0.845070</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>1242</td>\n",
              "      <td>0.904110</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>1243</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>1244</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>1245</td>\n",
              "      <td>0.811594</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>1246</td>\n",
              "      <td>0.865672</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>1247</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>1248</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>1249</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>1250</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>1251</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>1252</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>1253</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>1254</td>\n",
              "      <td>0.853333</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>1255</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>1256</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>1257</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>1258</td>\n",
              "      <td>0.787879</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>1259</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>1260</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>1261</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.853333</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>1263</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>1264</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>1265</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>1266</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>1267</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>1268</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>1269</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>1270</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>1271</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>1272</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>1273</td>\n",
              "      <td>0.840580</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>1274</td>\n",
              "      <td>0.891892</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>1275</td>\n",
              "      <td>0.901408</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>1276</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>1277</td>\n",
              "      <td>0.901408</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1278</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1279</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>1280</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>1281</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>1282</td>\n",
              "      <td>0.929577</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>1283</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>1284</td>\n",
              "      <td>0.956522</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>1285</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>1286</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>1287</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>1288</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>1289</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>1290</td>\n",
              "      <td>0.805556</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>1291</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>1292</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>1293</td>\n",
              "      <td>0.927536</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>1294</td>\n",
              "      <td>0.901408</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1295</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1296</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1297</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1298</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1299</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "#患者毎の正答率を表示\n",
        "#ここは先に入力しておく\n",
        "random.seed(1288)\n",
        "#################################################\n",
        "\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    #df_temp = df_temp.sample(n=1, random_state=random_state) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "\n",
        "##Calcurate the Youden's J static\n",
        "#https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "thred_list = [i/100 for i in range(1, 30, 1)] #Threshold 0.01-0.30を探索\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "tpr = np.array(tpr_list)\n",
        "fpr = np.array(fpr_list)\n",
        "thresholds = np.array(thred_list)\n",
        "\n",
        "youdenJ = tpr - fpr\n",
        "\n",
        "# Calculate the G-mean\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "\n",
        "#Find the optimal threshold\n",
        "# Find the optimal threshold\n",
        "index = np.argmax(youdenJ)\n",
        "\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))\n",
        "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "print(\"\")\n",
        "\n",
        "##Youden's indexをもとにした正答率を計算\n",
        "#################################################\n",
        "threshold = thresholdOpt #判定基準\n",
        "#################################################\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "#print(Y)\n",
        "#print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print(\"Using Youden's index\")\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8qSHqNtlt7u",
        "outputId": "4deba53e-4664-4c75-f92a-f7188673e607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.03 with Youden J statistic: 0.9143\n",
            "FPR: 0.0857, TPR: 0.9143\n",
            "\n",
            "Using Youden's index\n",
            "confusion matrix = \n",
            " [[32  3]\n",
            " [ 3 32]]\n",
            "Accuracy : 0.9142857142857143\n",
            "Precision (true positive rate) : 0.9142857142857143\n",
            "Recall (sensitivity): 0.9142857142857143\n",
            "Specificity : 0.9142857142857143\n",
            "F1 score : 0.9142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#ざっくり10点でROC curveを描いてみる\n",
        "thred_list = [i/100 for i in range(100)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)\n",
        "\n",
        "print(\"pt_gla: \", pt_gla)\n",
        "print(\"pt_cont: \", pt_cont)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "pfKbgAQamSBY",
        "outputId": "d25ac0d3-444e-4d01-a96f-5ffd58b976eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_gla:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "pt_cont:  [43, 68, 70, 72, 94, 95, 125, 141, 161, 162, 171, 191, 310, 317, 318, 362, 404, 415, 426, 434, 448, 457, 468, 469, 474, 495, 506, 559, 563, 605, 626, 686, 689, 692, 695]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#点数を増やして描画し直し\n",
        "#※ものすごく時間かかる\n",
        "thred_list = [i/100000 for i in range(100000)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)"
      ],
      "metadata": {
        "id": "PQVuhK83yKKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1症例1枚ずつ選択した場合の正解率を計算\n",
        "#1症例中の画像の選択 -> random_state で探索\n",
        "#controlの画像選択 -> random.seedで固定\n",
        "\n",
        "##############################\n",
        "random.seed(1288) #ここは先に入力しておく\n",
        "##############################\n",
        "\n",
        "seed_list = []\n",
        "f1_list = []\n",
        "specificity_list =  []\n",
        "sensitivity_list = []\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    df_temp = df_temp.sample(n=1, random_state = seed) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "\n",
        "for seed in list(range(0, 100, 1)):\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "    #gla群\n",
        "    pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "    #cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "    pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "    pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "    ##Calcurate the Youden's J static\n",
        "    #https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "    thred_list = [i/100 for i in range(1, 15, 1)] #Threshold 0.01-0.15を探索\n",
        "    fpr_list = []\n",
        "    tpr_list = []\n",
        "    cutoff_criterions = []\n",
        "\n",
        "    for i in thred_list:\n",
        "        fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "        fpr_list.append(fpr)\n",
        "        tpr_list.append(tpr)\n",
        "\n",
        "    tpr = np.array(tpr_list)\n",
        "    fpr = np.array(fpr_list)\n",
        "    thresholds = np.array(thred_list)\n",
        "\n",
        "    youdenJ = tpr - fpr\n",
        "\n",
        "    #Find the optimal threshold\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(youdenJ)\n",
        "\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "    ##Youden's indexをもとにした正答率を計算\n",
        "    #################################################\n",
        "    threshold = thresholdOpt #判定基準\n",
        "    #################################################\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    Y = df_pt_analysis[\"label\"].tolist()\n",
        "    Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    #print(tp, fn, fp, tn)\n",
        "    \"\"\"\n",
        "    print(f'Random_seed : {str(seed)}')\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "    print(\"\")\n",
        "    \"\"\"\n",
        "\n",
        "    seed_list.append(seed)\n",
        "    f1_list.append(f1_score(Y, Y_pred))\n",
        "    specificity_list.append(specificity_score(Y, Y_pred))\n",
        "    sensitivity_list.append(recall_score(Y, Y_pred))\n",
        "\n",
        "print(seed_list)\n",
        "print(f1_list)\n",
        "\n",
        "max_value = max(f1_list)\n",
        "idx = f1_list.index(max_value)\n",
        "print(\"best_seed: \", seed_list[idx])\n",
        "print(\"best_f1_score: \", f1_list[idx])\n",
        "\n",
        "\n",
        "df_f1 = pd.DataFrame(columns = [])\n",
        "df_f1[\"seed\"] = seed_list\n",
        "df_f1[\"f1_score\"] = f1_list\n",
        "df_f1[\"specificity\"] = specificity_list\n",
        "df_f1[\"sensitivity\"] = sensitivity_list\n",
        "df_f1"
      ],
      "metadata": {
        "id": "5HsR9cdDhzs1",
        "outputId": "e00b2ea9-9511-4d59-85e0-6912816a8309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "[0.8985507246376812, 0.8533333333333333, 0.8333333333333334, 0.8450704225352113, 0.8064516129032259, 0.868421052631579, 0.8571428571428572, 0.8767123287671234, 0.888888888888889, 0.8985507246376812, 0.8767123287671234, 0.888888888888889, 0.8529411764705883, 0.8358208955223881, 0.8253968253968255, 0.8985507246376812, 0.8437500000000001, 0.8767123287671234, 0.8831168831168832, 0.8529411764705883, 0.8615384615384616, 0.8571428571428572, 0.8923076923076922, 0.8529411764705883, 0.8253968253968255, 0.8947368421052632, 0.888888888888889, 0.8405797101449276, 0.90625, 0.8125, 0.9142857142857143, 0.8524590163934427, 0.8750000000000001, 0.9014084507042254, 0.8421052631578947, 0.8750000000000001, 0.8493150684931505, 0.8857142857142857, 0.8787878787878788, 0.819672131147541, 0.8767123287671234, 0.8823529411764706, 0.8611111111111112, 0.8732394366197184, 0.8656716417910447, 0.888888888888889, 0.9444444444444445, 0.8732394366197184, 0.8253968253968255, 0.8125, 0.8717948717948717, 0.8985507246376812, 0.8857142857142857, 0.8767123287671234, 0.8333333333333333, 0.7936507936507937, 0.8484848484848486, 0.8450704225352113, 0.8378378378378378, 0.8437500000000001, 0.8529411764705883, 0.8387096774193549, 0.8750000000000001, 0.8750000000000001, 0.868421052631579, 0.8387096774193549, 0.8787878787878788, 0.8524590163934427, 0.8955223880597014, 0.888888888888889, 0.8524590163934427, 0.8571428571428572, 0.888888888888889, 0.8437500000000001, 0.8253968253968255, 0.8985507246376812, 0.8750000000000001, 0.8923076923076922, 0.8695652173913043, 0.8307692307692307, 0.8358208955223881, 0.8387096774193549, 0.8484848484848486, 0.8750000000000001, 0.8125, 0.8787878787878788, 0.7941176470588236, 0.8648648648648648, 0.9166666666666667, 0.8732394366197184, 0.8985507246376812, 0.8648648648648648, 0.8750000000000001, 0.8767123287671234, 0.8311688311688312, 0.8732394366197184, 0.8947368421052632, 0.8923076923076922, 0.8529411764705883, 0.8787878787878788]\n",
            "best_seed:  46\n",
            "best_f1_score:  0.9444444444444445\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    seed  f1_score  specificity  sensitivity\n",
              "0      0  0.898551     0.914286     0.885714\n",
              "1      1  0.853333     0.771429     0.914286\n",
              "2      2  0.833333     0.800000     0.857143\n",
              "3      3  0.845070     0.828571     0.857143\n",
              "4      4  0.806452     0.942857     0.714286\n",
              "5      5  0.868421     0.771429     0.942857\n",
              "6      6  0.857143     0.971429     0.771429\n",
              "7      7  0.876712     0.828571     0.914286\n",
              "8      8  0.888889     0.857143     0.914286\n",
              "9      9  0.898551     0.914286     0.885714\n",
              "10    10  0.876712     0.828571     0.914286\n",
              "11    11  0.888889     1.000000     0.800000\n",
              "12    12  0.852941     0.885714     0.828571\n",
              "13    13  0.835821     0.885714     0.800000\n",
              "14    14  0.825397     0.942857     0.742857\n",
              "15    15  0.898551     0.914286     0.885714\n",
              "16    16  0.843750     0.942857     0.771429\n",
              "17    17  0.876712     0.828571     0.914286\n",
              "18    18  0.883117     0.771429     0.971429\n",
              "19    19  0.852941     0.885714     0.828571\n",
              "20    20  0.861538     0.942857     0.800000\n",
              "21    21  0.857143     0.971429     0.771429\n",
              "22    22  0.892308     0.971429     0.828571\n",
              "23    23  0.852941     0.885714     0.828571\n",
              "24    24  0.825397     0.942857     0.742857\n",
              "25    25  0.894737     0.800000     0.971429\n",
              "26    26  0.888889     0.857143     0.914286\n",
              "27    27  0.840580     0.857143     0.828571\n",
              "28    28  0.906250     1.000000     0.828571\n",
              "29    29  0.812500     0.914286     0.742857\n",
              "30    30  0.914286     0.914286     0.914286\n",
              "31    31  0.852459     1.000000     0.742857\n",
              "32    32  0.875000     0.971429     0.800000\n",
              "33    33  0.901408     0.885714     0.914286\n",
              "34    34  0.842105     0.742857     0.914286\n",
              "35    35  0.875000     0.971429     0.800000\n",
              "36    36  0.849315     0.800000     0.885714\n",
              "37    37  0.885714     0.885714     0.885714\n",
              "38    38  0.878788     0.942857     0.828571\n",
              "39    39  0.819672     0.971429     0.714286\n",
              "40    40  0.876712     0.828571     0.914286\n",
              "41    41  0.882353     0.914286     0.857143\n",
              "42    42  0.861111     0.828571     0.885714\n",
              "43    43  0.873239     0.857143     0.885714\n",
              "44    44  0.865672     0.914286     0.828571\n",
              "45    45  0.888889     0.857143     0.914286\n",
              "46    46  0.944444     0.914286     0.971429\n",
              "47    47  0.873239     0.857143     0.885714\n",
              "48    48  0.825397     0.942857     0.742857\n",
              "49    49  0.812500     0.914286     0.742857\n",
              "50    50  0.871795     0.742857     0.971429\n",
              "51    51  0.898551     0.914286     0.885714\n",
              "52    52  0.885714     0.885714     0.885714\n",
              "53    53  0.876712     0.828571     0.914286\n",
              "54    54  0.833333     1.000000     0.714286\n",
              "55    55  0.793651     0.914286     0.714286\n",
              "56    56  0.848485     0.914286     0.800000\n",
              "57    57  0.845070     0.828571     0.857143\n",
              "58    58  0.837838     0.771429     0.885714\n",
              "59    59  0.843750     0.942857     0.771429\n",
              "60    60  0.852941     0.885714     0.828571\n",
              "61    61  0.838710     0.971429     0.742857\n",
              "62    62  0.875000     0.971429     0.800000\n",
              "63    63  0.875000     0.971429     0.800000\n",
              "64    64  0.868421     0.771429     0.942857\n",
              "65    65  0.838710     0.971429     0.742857\n",
              "66    66  0.878788     0.942857     0.828571\n",
              "67    67  0.852459     1.000000     0.742857\n",
              "68    68  0.895522     0.942857     0.857143\n",
              "69    69  0.888889     0.857143     0.914286\n",
              "70    70  0.852459     1.000000     0.742857\n",
              "71    71  0.857143     0.971429     0.771429\n",
              "72    72  0.888889     0.857143     0.914286\n",
              "73    73  0.843750     0.942857     0.771429\n",
              "74    74  0.825397     0.942857     0.742857\n",
              "75    75  0.898551     0.914286     0.885714\n",
              "76    76  0.875000     0.971429     0.800000\n",
              "77    77  0.892308     0.971429     0.828571\n",
              "78    78  0.869565     0.885714     0.857143\n",
              "79    79  0.830769     0.914286     0.771429\n",
              "80    80  0.835821     0.885714     0.800000\n",
              "81    81  0.838710     0.971429     0.742857\n",
              "82    82  0.848485     0.914286     0.800000\n",
              "83    83  0.875000     0.971429     0.800000\n",
              "84    84  0.812500     0.914286     0.742857\n",
              "85    85  0.878788     0.942857     0.828571\n",
              "86    86  0.794118     0.828571     0.771429\n",
              "87    87  0.864865     0.800000     0.914286\n",
              "88    88  0.916667     0.885714     0.942857\n",
              "89    89  0.873239     0.857143     0.885714\n",
              "90    90  0.898551     0.914286     0.885714\n",
              "91    91  0.864865     0.800000     0.914286\n",
              "92    92  0.875000     0.971429     0.800000\n",
              "93    93  0.876712     0.828571     0.914286\n",
              "94    94  0.831169     0.714286     0.914286\n",
              "95    95  0.873239     0.857143     0.885714\n",
              "96    96  0.894737     0.800000     0.971429\n",
              "97    97  0.892308     0.971429     0.828571\n",
              "98    98  0.852941     0.885714     0.828571\n",
              "99    99  0.878788     0.942857     0.828571"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seed</th>\n",
              "      <th>f1_score</th>\n",
              "      <th>specificity</th>\n",
              "      <th>sensitivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.898551</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.853333</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.845070</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.806452</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.898551</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>0.835821</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>0.898551</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>0.883117</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.971429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>0.861538</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>23</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>24</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>25</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.971429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>26</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>27</td>\n",
              "      <td>0.840580</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>28</td>\n",
              "      <td>0.906250</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>29</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>30</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>31</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>32</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>33</td>\n",
              "      <td>0.901408</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>34</td>\n",
              "      <td>0.842105</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>36</td>\n",
              "      <td>0.849315</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>37</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>38</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>39</td>\n",
              "      <td>0.819672</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>41</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>42</td>\n",
              "      <td>0.861111</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>43</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>44</td>\n",
              "      <td>0.865672</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>45</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>46</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.971429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>49</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>50</td>\n",
              "      <td>0.871795</td>\n",
              "      <td>0.742857</td>\n",
              "      <td>0.971429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>51</td>\n",
              "      <td>0.898551</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>52</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>53</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>54</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>55</td>\n",
              "      <td>0.793651</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>56</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>57</td>\n",
              "      <td>0.845070</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>58</td>\n",
              "      <td>0.837838</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>59</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>60</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>62</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>64</td>\n",
              "      <td>0.868421</td>\n",
              "      <td>0.771429</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>68</td>\n",
              "      <td>0.895522</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>69</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>70</td>\n",
              "      <td>0.852459</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>71</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>72</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>73</td>\n",
              "      <td>0.843750</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>74</td>\n",
              "      <td>0.825397</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>75</td>\n",
              "      <td>0.898551</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>76</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>77</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>78</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>79</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>80</td>\n",
              "      <td>0.835821</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>81</td>\n",
              "      <td>0.838710</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>82</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>83</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>84</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.742857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>85</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>86</td>\n",
              "      <td>0.794118</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.771429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>87</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>88</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.942857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>89</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>90</td>\n",
              "      <td>0.898551</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>91</td>\n",
              "      <td>0.864865</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>92</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>93</td>\n",
              "      <td>0.876712</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>0.831169</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.914286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.885714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>0.894737</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.971429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>0.852941</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>0.878788</td>\n",
              "      <td>0.942857</td>\n",
              "      <td>0.828571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "#ここは先に入力しておく\n",
        "random.seed(1288)\n",
        "random_state = 85\n",
        "#################################################\n",
        "\n",
        "\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\", \"path\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    df_temp = df_temp.sample(n=1, random_state=random_state) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "    path = df_temp[\"path\"].tolist()[0]\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred, path\n",
        "\n",
        "def calculate_fpr_tpr(pt_gla, pt_cont, df_result, threshold):\n",
        "    label_list, pred_list = [], []\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred, path = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred, path = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(label_list, pred_list).ravel()\n",
        "    fpr, tpr = fp/(tn+fp), tp/(tp+fn)\n",
        "    return fpr, tpr\n",
        "\n",
        "##Calcurate the Youden's J static\n",
        "#https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "thred_list = [i/100 for i in range(1, 30, 1)] #Threshold 0.01-0.30を探索\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "tpr = np.array(tpr_list)\n",
        "fpr = np.array(fpr_list)\n",
        "thresholds = np.array(thred_list)\n",
        "\n",
        "youdenJ = tpr - fpr\n",
        "\n",
        "# Calculate the G-mean\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "\n",
        "#Find the optimal threshold\n",
        "# Find the optimal threshold\n",
        "index = np.argmax(youdenJ)\n",
        "\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))\n",
        "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "print(\"\")\n",
        "\n",
        "##Youden's indexをもとにした正答率を計算\n",
        "#################################################\n",
        "threshold = thresholdOpt #判定基準\n",
        "#################################################\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred, path = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred, path]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred, path = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred, path]\n",
        "\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "#print(Y)\n",
        "#print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print(\"Using Youden's index\")\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CrsGCam63DW",
        "outputId": "1899d071-7c52-49ca-f531-96394b2a1cc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.03 with Youden J statistic: 0.9143\n",
            "FPR: 0.0857, TPR: 0.9143\n",
            "\n",
            "Using Youden's index\n",
            "confusion matrix = \n",
            " [[32  3]\n",
            " [ 3 32]]\n",
            "Accuracy : 0.9142857142857143\n",
            "Precision (true positive rate) : 0.9142857142857143\n",
            "Recall (sensitivity): 0.9142857142857143\n",
            "Specificity : 0.9142857142857143\n",
            "F1 score : 0.9142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis"
      ],
      "metadata": {
        "id": "QU3QnkgqHrWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis_orig = df_pt_analysis.copy()\n",
        "path = df_pt_analysis_orig[\"path\"][0]\n",
        "path.split(\"\\\\\")\n",
        "path\n"
      ],
      "metadata": {
        "id": "KhjG0r34aDbO",
        "outputId": "a6abb873-0c9f-4f01-8dcf-a740463f0c48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'F:\\\\先天性緑内障\\\\dataset_for_article_250px_2\\\\gla_exo\\\\1546_4.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#人力評価用のCSVを作成\n",
        "\n",
        "AI：パス、label、AIによる予測\n",
        "\n",
        "ヒト（一人ずつ）：画像番号のみ"
      ],
      "metadata": {
        "id": "9ocx_orwwWJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "df_pt_analysis_shuffle = df_pt_analysis.sample(frac=1, random_state=1).reset_index() #df_pt_analysisをシャッフル（random_state指定）し、インデックスを振り直す\n",
        "\n",
        "#AIの判定結果をCSVに転記\n",
        "df_AI = df_pt_analysis_shuffle[[\"path\", \"label\", \"pred\"]]\n",
        "df_AI = df_AI.rename(columns={'pred': 'AI'}) #pred --> AIにrename\n",
        "df_AI[\"path\"]= df_AI[\"path\"].str.replace(\"250px\", \"orig\")\n",
        "df_AI.to_csv(r\"F:\\先天性緑内障//Human_pred//AI_\"+str(datetime.datetime.today().date())+\".csv\", encoding=\"shift_jis\") #AIによる予測結果をAI_日付の名前で保存\n",
        "\n",
        "\n",
        "#evaluatorの数だけ評価用csvファイルを作成する\n",
        "evaluator_list = [\"miki\", \"kawasaki\", \"fujino\"]  \n",
        "for name in evaluator_list:\n",
        "    df_human_pred = pd.DataFrame(index=[x for x in range(len(df_pt_analysis))], columns=[\"judgement\"]) \n",
        "    df_human_pred.to_csv(r\"F:\\先天性緑内障//Human_pred\"+\"//\"+name+\"_\"+str(datetime.datetime.today().date())+\".csv\", encoding=\"shift_jis\")  #evaluatorの名前_日付の名前で保存"
      ],
      "metadata": {
        "id": "ZlMCsYuGjDW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_AI"
      ],
      "metadata": {
        "id": "L0jylCxcx0EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#判定用PDFファイルの作成\n",
        "import cv2\n",
        "import shutil\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "\n",
        "save_path = r\"F:\\先天性緑内障//Human_pred//images\"\n",
        "\n",
        "#save_pathがあれば削除して新しく作り直す\n",
        "try:\n",
        "    shutil.rmtree(save_path)\n",
        "    os.makedirs(save_path)\n",
        "except FileNotFoundError:\n",
        "    os.makedirs(save_path)\n",
        "    pass\n",
        "\n",
        "\n",
        "#CSVに対応する画像のパスを取得\n",
        "img_path_list = []\n",
        "for i in range(len(df_AI)):\n",
        "    img_path = df_AI.iloc[i,0]\n",
        "    img_path_list.append(img_path)\n",
        "print(img_path_list)\n",
        "\n",
        "\n",
        "#画像リサイズのモジュール\n",
        "def convert(in_path, out_path, number):\n",
        "    img = Image.open(in_path)\n",
        "    img_new = expand2square(img, (0, 0, 0)).resize((500, 500))\n",
        "    img_new2 = drawNumber(img_new, number)\n",
        "    img_new.save(out_path)\n",
        "\n",
        "def expand2square(pil_img, background_color):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width-height)//2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, (0, (height - width) // 2))\n",
        "        return result\n",
        "\n",
        "def drawNumber(pil_img, number):\n",
        "    text = str(number)\n",
        "    imagesize = pil_img.size\n",
        "    draw = ImageDraw.Draw(pil_img)  # ImageDrawオブジェクトを作成\n",
        "    font = ImageFont.truetype(\"arial.ttf\", 64)  # フォントを指定、64はサイズでピクセル単位\n",
        "    size = font.getsize(text)\n",
        "    # 画像右下に'Sampleと表示' #FFFは文字色（白）\n",
        "    draw.text((imagesize[0] - size[0], imagesize[1] - size[1]), text, font=font, fill='#FFF')\n",
        "    return pil_img\n",
        "\n",
        "k=0\n",
        "for i in range(len(img_path_list)):\n",
        "    in_path = img_path_list[i]\n",
        "    out_path = save_path+\"//\"+str(k)+\".jpg\"\n",
        "    convert(in_path, out_path, k)\n",
        "    k+=1"
      ],
      "metadata": {
        "id": "6PX7It-8aXlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#作成した画像をPDF fileにまとめる\n",
        "import os\n",
        "import img2pdf\n",
        "from PIL import Image # img2pdfと一緒にインストールされたPillowを使います\n",
        "\n",
        "\n",
        "pdfFileName = r\"F://先天性緑内障//Human_pred//images.pdf\"\n",
        "path = r\"F://先天性緑内障//Human_pred//images//*\"\n",
        "ext = \".jpg\"\n",
        " \n",
        "with open(pdfFileName, \"wb\") as files:\n",
        "  files.write(img2pdf.convert([i for i in glob.glob(path) if i.endswith(ext)]))"
      ],
      "metadata": {
        "id": "KNwO8jq_A_5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#作成したpdfにパスワードをかける\n",
        "import PyPDF2\n",
        "\n",
        "src_pdf = PyPDF2.PdfFileReader(pdfFileName)\n",
        "pass_pdf = pdfFileName\n",
        "password = 'gla'    #password\n",
        "\n",
        "dst_pdf = PyPDF2.PdfFileWriter()\n",
        "dst_pdf.cloneReaderDocumentRoot(src_pdf)\n",
        "\n",
        "d = {key: src_pdf.documentInfo[key] for key in src_pdf.documentInfo.keys()}\n",
        "dst_pdf.addMetadata(d)\n",
        "\n",
        "dst_pdf.encrypt(password)\n",
        "\n",
        "with open(pass_pdf, 'wb') as f:\n",
        "    dst_pdf.write(f)"
      ],
      "metadata": {
        "id": "SeQBMyMZrAQZ",
        "outputId": "e918f46c-3b0d-44e3-de4b-a6972b37e613",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PdfReadWarning: Xref table not zero-indexed. ID numbers for objects will be corrected. [pdf.py:1736]\n"
          ]
        }
      ]
    }
  ]
}