{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled90.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiSt9wJDQXiRX33qOpb2jh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/CongenitalGlaucoma_AI_project/blob/main/DataSplit(stratified_one_subject_leave_out)3.1_Random.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data_split for one-subject-leave-out stratified 5-fold crossvalidation**"
      ],
      "metadata": {
        "id": "Dxlpd0AbAWf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZREKDUM5uudx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Leave one subject out cross validation + 5-fold stratified cross validation\n",
        "\n",
        "・1症例を抜き出し、その症例のすべての画像をテスト画像とする\n",
        "・残りの症例の内斜視、外斜視、斜視なし群を、同じ症例が群をまたがないように5分割する。\n",
        "・5分割したデータセットのうち4つをtraining、1つをvalidationとして用いてトレーニングを行い、抜き出した1症例のそれぞれの画像のおける正解率を算出する。これを5回繰り返してcross validationとする。\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TkRaZnYjAjZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29caebf-8d39-4f96-cc5d-0b61f99a88fe"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nLeave one subject out cross validation + 5-fold stratified cross validation\\n\\n・1症例を抜き出し、その症例のすべての画像をテスト画像とする\\n・残りの症例の内斜視、外斜視、斜視なし群を、同じ症例が群をまたがないように5分割する。\\n・5分割したデータセットのうち4つをtraining、1つをvalidationとして用いてトレーニングを行い、抜き出した1症例のそれぞれの画像のおける正解率を算出する。これを5回繰り返してcross validationとする。\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nPSM5f-yyQfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9089eb-a00b-4084-c9ed-19204eb23081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\ykita\\AppData\\Local\\Programs\\Python\\Python38\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "229\n",
            "693\n"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import shutil\n",
        "import re\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import time\n",
        "import glob\n",
        "import copy\n",
        "import pickle\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "random_seed = 2 #shuffleのシード\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "\n",
        "gla_ortho_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_ortho\"\n",
        "gla_eso_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_eso\"\n",
        "gla_exo_path = r\"F:\\先天性緑内障\\dataset_for_article_250px\\gla_exo\"\n",
        "cont_ortho_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ortho\"\n",
        "cont_eso_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_eso\"\n",
        "cont_exo_path = r\"F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo\"\n",
        "result_csv_path = r\"F:\\先天性緑内障\\result_Random_2.csv\"\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "gla_ortho_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_d\"\n",
        "gla_eso_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_d__内斜視\"\n",
        "gla_exo_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_d__外斜視\"\n",
        "cont_ortho_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_control\"\n",
        "cont_eso_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_control__内斜視\\内斜視かぶりなし\"\n",
        "cont_exo_path = r\"F:\\先天性緑内障\\データ引継ぎ\\children_control__外斜視\\外斜視かぶりなし\"\n",
        "\"\"\"\n",
        "\n",
        "def make_path_list(dir):\n",
        "    path_list =  [file for file in glob.glob(dir+\"/*\") if os.path.isfile(file) == True ]\n",
        "    return path_list\n",
        "\n",
        "def extract_class(path_list, className):\n",
        "    class_list = list(itertools.repeat(className,len(path_list)))\n",
        "    return class_list\n",
        "\n",
        "def extract_ids(path_list):\n",
        "    id_list = [re.split('[-_]',os.path.basename(name))[0] for name in path_list]\n",
        "    #id_list = [os.path.basename(name).split(\"_\")[0] for name in path_list]\n",
        "    return(id_list)\n",
        "\n",
        "\n",
        "gla_ortho_path_list = make_path_list(gla_ortho_path)\n",
        "gla_eso_path_list = make_path_list(gla_eso_path)\n",
        "gla_exo_path_list = make_path_list(gla_exo_path)\n",
        "cont_ortho_path_list = make_path_list(cont_ortho_path)\n",
        "cont_eso_path_list = make_path_list(cont_eso_path)\n",
        "cont_exo_path_list = make_path_list(cont_exo_path)\n",
        "\n",
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "gla_dataset_path = gla_ortho_path_list + gla_eso_path_list + gla_exo_path_list\n",
        "gla_classes = extract_class(gla_ortho_path_list, \"ortho\") + extract_class(gla_eso_path_list, \"eso\") + extract_class(gla_exo_path_list, \"exo\")\n",
        "gla_id = extract_ids(gla_ortho_path_list) + extract_ids(gla_eso_path_list) + extract_ids(gla_exo_path_list)\n",
        "cont_dataset_path = cont_ortho_path_list + cont_eso_path_list + cont_exo_path_list\n",
        "cont_classes = extract_class(cont_ortho_path_list, \"ortho\") + extract_class(cont_eso_path_list, \"eso\") + extract_class(cont_exo_path_list, \"exo\")\n",
        "cont_id = extract_ids(cont_ortho_path_list) + extract_ids(cont_eso_path_list) + extract_ids(cont_exo_path_list)\n",
        "\n",
        "#convert to Numpy(for use of Scikit-Learn)\n",
        "gla_dataset_path = np.array(gla_dataset_path)\n",
        "gla_classes = np.array(gla_classes)\n",
        "gla_id = np.array(gla_id)\n",
        "cont_dataset_path = np.array(cont_dataset_path)\n",
        "cont_classes = np.array(cont_classes)\n",
        "cont_id = np.array(cont_id)\n",
        "\n",
        "print(len(gla_dataset_path))\n",
        "print(len(cont_dataset_path))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "------test_dataset[0]\n",
        "  |\n",
        "  |---train_dataset_gla[0]----0\n",
        "  |                        |--1\n",
        "  |                        |--2\n",
        "  |                        |--3\n",
        "  |                        |--4\n",
        "  |---train_dataset_cont[0]----0\n",
        "  |                         |--1\n",
        "  |                         |--2\n",
        "  |                         |--3\n",
        "  |                         |--4\n",
        "  |---val_dataset_gla[0]----0\n",
        "  |                      |--1\n",
        "  |                      |--2\n",
        "  |                      |--3\n",
        "  |                      |--4\n",
        "  |---val_dataset_cont[0]----0\n",
        "  |                       |--1\n",
        "  |                       |--2\n",
        "  |                       |--3\n",
        "  |                       |--4\n",
        "  |---test_dataset[1]\n",
        "  ...\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cBs5SZf2m7Bj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7c7316c-d237-480a-cd84-8057ad734acd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n------test_dataset[0]\\n  |\\n  |---train_dataset_gla[0]----0\\n  |                        |--1\\n  |                        |--2\\n  |                        |--3\\n  |                        |--4\\n  |---train_dataset_cont[0]----0\\n  |                         |--1\\n  |                         |--2\\n  |                         |--3\\n  |                         |--4\\n  |---val_dataset_gla[0]----0\\n  |                      |--1\\n  |                      |--2\\n  |                      |--3\\n  |                      |--4\\n  |---val_dataset_cont[0]----0\\n  |                       |--1\\n  |                       |--2\\n  |                       |--3\\n  |                       |--4\\n  |---test_dataset[1]\\n  ...\\n\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_gla, val_dataset_gla,train_dataset_cont, val_dataset_cont, testset, testset_label = [], [], [], [], [], []\n",
        "\n",
        "#まずglaのデータセットから1人分を抜き出す（LeaveOneGroupOut)\n",
        "# one group leave out 見本\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut\n",
        "# 今回のケースでは、groupがIDに該当\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(gla_dataset_path, gla_classes, gla_id)\n",
        "logo.get_n_splits(groups=gla_id)  # 'groups' is always required\n",
        "\n",
        "k=0\n",
        "for remain_index, test_index in logo.split(gla_dataset_path, gla_classes, gla_id):\n",
        "    gla_dataset_path_remain, gla_dataset_path_test = gla_dataset_path[remain_index], gla_dataset_path[test_index]\n",
        "    gla_classes_remain, gla_classes_test = gla_classes[remain_index], gla_classes[test_index]\n",
        "    gla_id_remain, gla_id_test = gla_id[remain_index], gla_id[test_index]\n",
        "    #print(gla_dataset_path, gla_dataset_path_test, gla_id_train, gla_id_test)\n",
        "    #print(\"test: \"+gla_id_test[0])\n",
        "    #print(\"TRAIN:\", remain_index, \"TEST:\", test_index)\n",
        "    #print(gla_dataset_path_test[0])\n",
        "    testset.append(gla_dataset_path_test.tolist())\n",
        "    testset_label.append(list(itertools.repeat(1, len(gla_dataset_path_test))))\n",
        "\n",
        "    #抜き出した残りのglaについてStratified group 5-foldをかける\n",
        "    # example of stratified group Kfold　見本\n",
        "    # 今回のケースでは、groupがID、yがclassesに該当\n",
        "\n",
        "    cv = StratifiedGroupKFold(n_splits=5, shuffle = True, random_state = random_seed)\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(gla_dataset_path_remain, gla_classes_remain, gla_id_remain):\n",
        "        #print(\"TRAIN:\", gla_classes_remain[train_idxs])\n",
        "        #print(\"      \", gla_id_remain[train_idxs])\n",
        "        #print(\"      \", gla_dataset_path_remain[train_idxs])\n",
        "        #print(\" TEST:\", gla_classes_remain[val_idxs])\n",
        "        #print(\"      \", gla_id_remain[val_idxs])\n",
        "        #print(\"      \", gla_dataset_path_remain[val_idxs])\n",
        "        train_miniset[m] = gla_dataset_path_remain[train_idxs].tolist()\n",
        "        val_miniset[m] = gla_dataset_path_remain[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_gla.append(train_miniset)\n",
        "    val_dataset_gla.append(val_miniset)\n",
        "    #print(\"train_dataset_added label[gla] \" + str(k))\n",
        "    k+=1\n",
        "\n",
        "    #control全体についてStratified group 5-foldをかける\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(cont_dataset_path, cont_classes, cont_id):\n",
        "        #print(\"TRAIN:\", cont_classes[train_idxs])\n",
        "        #print(\"      \", cont_id[train_idxs])\n",
        "        #print(\"      \", cont_dataset_path[train_idxs])\n",
        "        #print(\" TEST:\", cont_classes[val_idxs])\n",
        "        #print(\"      \", cont_id[val_idxs])\n",
        "        #print(\"      \", cont_dataset_path[val_idxs])\n",
        "        train_miniset[m] = cont_dataset_path[train_idxs].tolist()\n",
        "        val_miniset[m] = cont_dataset_path[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_cont.append(train_miniset)\n",
        "    val_dataset_cont.append(val_miniset)\n",
        "\n",
        "        \n",
        "#print(len(train_dataset_gla))    \n",
        "#print(len(val_dataset_gla))\n",
        "#print(val_dataset_gla)\n",
        "#print(len(train_dataset_cont))    \n",
        "#print(len(val_dataset_cont))\n",
        "#print(len(test_dataset))\n",
        "\n",
        "\n",
        "#同じくcontのデータセットから1人分抜き出してLeaveOneGroupOutをする\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(cont_dataset_path, cont_classes, cont_id)\n",
        "logo.get_n_splits(groups=cont_id)  # 'groups' is always required\n",
        "\n",
        "k=0\n",
        "for remain_index, test_index in logo.split(cont_dataset_path, cont_classes, cont_id):\n",
        "    cont_dataset_path_remain, cont_dataset_path_test = cont_dataset_path[remain_index], cont_dataset_path[test_index]\n",
        "    cont_classes_remain, cont_classes_test = cont_classes[remain_index], cont_classes[test_index]\n",
        "    cont_id_remain, cont_id_test = cont_id[remain_index], cont_id[test_index]\n",
        "    #print(cont_dataset_path_test[0])\n",
        "    testset.append(cont_dataset_path_test.tolist())\n",
        "    testset_label.append(list(itertools.repeat(0, len(cont_dataset_path_test))))\n",
        "\n",
        "    #抜き出した残りのcontについてStratified group 5-foldをかける\n",
        "\n",
        "    cv = StratifiedGroupKFold(n_splits=5, shuffle = True, random_state = random_seed)\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(cont_dataset_path_remain, cont_classes_remain, cont_id_remain):\n",
        "        train_miniset[m] = cont_dataset_path_remain[train_idxs].tolist()\n",
        "        val_miniset[m] = cont_dataset_path_remain[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_cont.append(train_miniset)\n",
        "    val_dataset_cont.append(val_miniset)\n",
        "\n",
        "    #gla全体についてStratified group 5-foldをかける\n",
        "    m=0 \n",
        "    train_miniset, val_miniset =  [0 for i in range(0, 5)], [0 for i in range(0, 5)]\n",
        "    for train_idxs, val_idxs in cv.split(gla_dataset_path, gla_classes, gla_id):\n",
        "        train_miniset[m] = gla_dataset_path[train_idxs].tolist()\n",
        "        val_miniset[m] = gla_dataset_path[val_idxs].tolist()\n",
        "        m+=1\n",
        "    train_dataset_gla.append(train_miniset)\n",
        "    val_dataset_gla.append(val_miniset)\n",
        "    #print(\"train_dataset_added label[cont] \"+ str(k))\n",
        "    k+=1\n",
        "        \n",
        "print(len(train_dataset_gla))    \n",
        "print(len(val_dataset_gla))\n",
        "print(len(train_dataset_cont))    \n",
        "print(len(val_dataset_cont))\n",
        "print(len(testset))\n",
        "print(len(testset_label))\n"
      ],
      "metadata": {
        "id": "XLe8wZOkQkkk",
        "outputId": "dd6e285f-dc98-4399-b2f8-174285db32d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "723\n",
            "723\n",
            "723\n",
            "723\n",
            "723\n",
            "723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Modules**"
      ],
      "metadata": {
        "id": "Ef0A_-M7wfS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PX = 224 #画像のサイズ\n",
        "TRAIN_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "TRAIN_CROP_SCALE =(0.9,1.0)\n",
        "#TRAIN_BRIGHTNESS_PARAM = 0.2\n",
        "#TRAIN_CONTRAST_PARAM = 0.1\n",
        "#TRAIN_SATURATION_PARAM = 0.1\n",
        "TRAIN_RANDOM_ROTATION = 3\n",
        "TRAIN_HUE_PARAM = 0.02\n",
        "VAL_NORMALIZE_PARAM = [0.494, 0.296, 0.197], [0.14,  0.114, 0.072]\n",
        "\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "class SimpleImageDataset(Dataset):\n",
        "    def __init__(self, img_list, label_list, transform):\n",
        "        self.transform = transform\n",
        "        self.img_list = img_list\n",
        "        self.label_list = label_list\n",
        "        self.item_dict = {}\n",
        "        self.age = []\n",
        "        #print(img_list)\n",
        "        #print(label_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.img_list[idx]\n",
        "        pilr_image = Image.open(image_path).convert(\"RGB\")\n",
        "        tensor_image = self.transform(pilr_image)\n",
        "        target = torch.tensor(self.label_list[idx])      \n",
        "        return tensor_image, target\n",
        "\n",
        "#画像読み込み時間削減のため、Expand2squareの処理は行っている\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            \n",
        "            # Runs the forward pass with autocasting.\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # scaler.step() first unscales the gradients of the optimizer's assigned params.\n",
        "            scaler.step(optimizer)\n",
        "\n",
        "            # Updates the scale for next iteration.\n",
        "            scaler.update()\n",
        "\n",
        "            \"\"\"\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \"\"\"\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "        #print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        #####################\n",
        "        # test the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, test_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "            \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        test_acc = running_corrects.item()/len(test_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}' +'\\n'\n",
        "                     f'test_acc: {test_acc:.5f}' + f'({running_corrects:.0f}/{len(test_dataset):.0f})') \n",
        "\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Define RepVGG\n",
        "##############################################\n",
        "\n",
        "import requests\n",
        "\n",
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "\n",
        "#RepVGGのpretrained modelをダウンロード\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "destination = \"F:\\先天性緑内障\\RepVGG-A2.pth\"\n",
        "\n",
        "if os.path.exists(destination) is not True:\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "else:\n",
        "    print(\"pretrained repVGG model already exists\")\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Deplpy RepVGG-A2\n",
        "##############################################\n",
        "\n",
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "#model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft.load_state_dict(torch.load (\"F:\\先天性緑内障\\RepVGG-A2.pth\"))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Dataset and dataloader\n",
        "##############################################\n",
        "pt=4\n",
        "fold=2\n",
        "train_list = train_dataset_gla[pt][fold] + train_dataset_cont[pt][fold]\n",
        "train_list_label = list(itertools.repeat(1, len(train_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(train_dataset_cont[pt][fold])))\n",
        "val_list = val_dataset_gla[pt][fold] + val_dataset_cont[pt][fold]\n",
        "val_list_label = list(itertools.repeat(1, len(val_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(val_dataset_cont[pt][fold])))\n",
        "test_list = testset[pt]\n",
        "test_list_label = testset_label[pt]\n",
        "\n",
        "#define dataset and dataloader\n",
        "train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\n",
        "\n",
        "# Make a grid from batch\n",
        "inputs, classes = next(iter(test_loader))\n",
        "print(classes)\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "class_names = [\"cont\", \"gla\"]\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "#データセットの確認\n",
        "for i, j in zip(test_list, test_list_label):\n",
        "    print(i,j)\n",
        "\n",
        "\n",
        "##############################################\n",
        "## Data augumentation\n",
        "##############################################\n",
        "\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(val_list))\n",
        "print(len(test_list))\n",
        "\n",
        "\"\"\"\n",
        "#データセットの確認\n",
        "for i, j in zip(train_list, train_list_label):\n",
        "    print(i,j)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NecL-52PwEgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training and evaluation**"
      ],
      "metadata": {
        "id": "cLaukgf2XfAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model_ft = torchvision.models.resnet50(pretrained=True)  \n",
        "#num_ftrs = model_ft.fc.in_features\n",
        "#model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "model_ft.load_state_dict(torch.load (\"F:\\先天性緑内障\\RepVGG-A2.pth\"))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=10, num_epochs=30)"
      ],
      "metadata": {
        "id": "CLT-Dhv-XiMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f07d20-82b7-4969-aecf-7554f38e9b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n",
            "----------\n",
            "Epoch: [ 0/30] \n",
            "train_loss: 0.44406 train_acc: 0.75469\n",
            "valid_loss: 0.45569 valid_acc: 0.83429\n",
            "test_acc: 1.00000(1/1)\n",
            "Validation loss decreased (inf --> 0.455692).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 1/30] \n",
            "train_loss: 0.17073 train_acc: 0.92895\n",
            "valid_loss: 0.45399 valid_acc: 0.83429\n",
            "test_acc: 1.00000(1/1)\n",
            "Validation loss decreased (0.455692 --> 0.453989).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 2/30] \n",
            "train_loss: 0.08884 train_acc: 0.97185\n",
            "valid_loss: 0.38098 valid_acc: 0.83429\n",
            "test_acc: 1.00000(1/1)\n",
            "Validation loss decreased (0.453989 --> 0.380980).  Saving model ...\n",
            "\n",
            "----------\n",
            "Epoch: [ 3/30] \n",
            "train_loss: 0.08005 train_acc: 0.96917\n",
            "valid_loss: 1.14617 valid_acc: 0.83429\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 1 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [ 4/30] \n",
            "train_loss: 0.11490 train_acc: 0.96113\n",
            "valid_loss: 0.93843 valid_acc: 0.82286\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 2 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [ 5/30] \n",
            "train_loss: 0.09647 train_acc: 0.96917\n",
            "valid_loss: 0.63743 valid_acc: 0.83429\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 3 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [ 6/30] \n",
            "train_loss: 0.09238 train_acc: 0.97051\n",
            "valid_loss: 0.60826 valid_acc: 0.82857\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 4 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [ 7/30] \n",
            "train_loss: 0.06248 train_acc: 0.97989\n",
            "valid_loss: 0.81126 valid_acc: 0.84000\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 5 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [ 8/30] \n",
            "train_loss: 0.12751 train_acc: 0.96247\n",
            "valid_loss: 1.16792 valid_acc: 0.84000\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 6 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [ 9/30] \n",
            "train_loss: 0.04472 train_acc: 0.98257\n",
            "valid_loss: 0.77771 valid_acc: 0.80000\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 7 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [10/30] \n",
            "train_loss: 0.05178 train_acc: 0.97855\n",
            "valid_loss: 0.93217 valid_acc: 0.82857\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 8 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [11/30] \n",
            "train_loss: 0.06950 train_acc: 0.97051\n",
            "valid_loss: 0.93460 valid_acc: 0.85143\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 9 out of 10\n",
            "\n",
            "----------\n",
            "Epoch: [12/30] \n",
            "train_loss: 0.05348 train_acc: 0.98123\n",
            "valid_loss: 0.81410 valid_acc: 0.82857\n",
            "test_acc: 1.00000(1/1)\n",
            "EarlyStopping counter: 10 out of 10\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft.eval() # prep model for evaluation\n",
        "\n",
        "targets, preds =[], []\n",
        "for image_tensor, target in test_loader:  \n",
        "      #target = target.squeeze(1)     \n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model_ft(image_tensor)\n",
        "      _, pred = torch.max(output, 1)  \n",
        "      preds.append(int(pred))  #予測結果\n",
        "      targets.append(int(target)) #ラベル\n",
        "\n",
        "y_test = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "print(\"label: \", y_test)\n",
        "print(\"pred: \", y_pred)"
      ],
      "metadata": {
        "id": "hDpz1ontYFbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77dc2e57-79f1-465d-91f8-d1db568cc070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label:  [1]\n",
            "pred:  [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GradCAM (診断根拠の可視化)\n"
      ],
      "metadata": {
        "id": "uQaq2zGvr1bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      #print('Image: '+ image_name)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      #print('Label: '+ label)\n",
        "      return(image_name, label)\n",
        "\n"
      ],
      "metadata": {
        "id": "-bg9YYJFr6ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split model in two parts\n",
        "features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        " #最後の2層\n",
        "\n",
        "#評価モードにする    \n",
        "model_ft = model_ft.eval()\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "\n",
        "classes = [\"cont\", \"gla\"]\n",
        "\n",
        "#画像のパスを指定\n",
        "#for j in range(1):\n",
        "for j in range(len(test_dataset)):\n",
        "\n",
        "    #元画像\n",
        "\n",
        "    image = test_dataset[j][0]\n",
        "    image = image.permute(1, 2, 0)\n",
        "\n",
        "    img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "    #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "    pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "    #pとcを対にして入力\n",
        "    for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "        sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "        tmp = image.to('cpu').detach().numpy().copy()\n",
        "        img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "        #TensorをImageに変換\n",
        "        sal = Image.fromarray(sal)\n",
        "        sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "        print()\n",
        "        #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "        #plt.title('')\n",
        "        print('label: '+classes[test_dataset[j][1]])\n",
        "        print('pred:  '+'{}  {:.1f}%'.format(classes[c], 100*float(p)))\n",
        "        #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "        \n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        #グラフを1行2列に並べたうちの1番目\n",
        "        plt.subplots_adjust(wspace=0,hspace=0)\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "        #元の画像を並べて表示\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3QYH4diyu1h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Automated analysis**"
      ],
      "metadata": {
        "id": "MRzEYQQekA6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#保存用の空CSVを作成\n",
        "pt_num = []\n",
        "k=0\n",
        "for data in testset:\n",
        "    pt_num.append([k]*len(data))\n",
        "    k+=1\n",
        "\n",
        "img_num = []\n",
        "for data in testset:\n",
        "    img_num.append(list(range(len(data))))\n",
        "\n",
        "patient_num = list(itertools.chain.from_iterable(pt_num))\n",
        "img_num = list(itertools.chain.from_iterable(img_num))\n",
        "patient_path = list(itertools.chain.from_iterable(testset))\n",
        "patient_label = list(itertools.chain.from_iterable(testset_label))\n",
        "\n",
        "df_result = pd.DataFrame(index=[],columns=[])\n",
        "df_result = pd.DataFrame(index=[],columns=[\"pt_number\",\"img_number\", \"path\",\"label\", \"0\",\"1\",\"2\",\"3\",\"4\", \"prob_1\", \"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"])\n",
        "df_result[\"pt_number\"] = patient_num\n",
        "df_result[\"img_number\"] = img_num\n",
        "df_result[\"path\"] = patient_path\n",
        "df_result[\"label\"] = patient_label\n",
        "\n",
        "df_result.to_csv(r\"F:\\先天性緑内障\\result.csv\",encoding=\"shift_jis\", index=False)\n",
        "df_result"
      ],
      "metadata": {
        "id": "hJAkQ_Bun31w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv"
      ],
      "metadata": {
        "id": "yOJJ87DGGkOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Open reslut_csv\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "\n",
        "time_start = time.perf_counter()\n",
        "\n",
        "#pt,foldの初期値を入力（CSVに対応）\n",
        "pt=0\n",
        "fold=0\n",
        "\n",
        "\n",
        "\n",
        "#Define Data Augumentation\n",
        "TRAIN_RANDOM_ROTATION = 1\n",
        "TRAIN_CROP_SCALE = (0.8,1.1)\n",
        "PX = 224\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.RandomResizedCrop(PX, scale=TRAIN_CROP_SCALE),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "val_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.RandomRotation(degrees=TRAIN_RANDOM_ROTATION),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "test_data_transforms = transforms.Compose([\n",
        "                #Expand2square((0,0,0)),\n",
        "                transforms.Resize(PX),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "\n",
        "\n",
        "\n",
        "for pt in range(pt,len(testset)): #指定したPtから開始\n",
        "    for fold in list(range(5)):\n",
        "        print(\"patient: \"+str(pt)+\", fold: \"+str(fold))\n",
        "\n",
        "        train_list = train_dataset_gla[pt][fold] + train_dataset_cont[pt][fold]\n",
        "        train_list_label = list(itertools.repeat(1, len(train_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(train_dataset_cont[pt][fold])))\n",
        "        val_list = val_dataset_gla[pt][fold] + val_dataset_cont[pt][fold]\n",
        "        val_list_label = list(itertools.repeat(1, len(val_dataset_gla[pt][fold])))+list(itertools.repeat(0, len(val_dataset_cont[pt][fold])))\n",
        "        test_list = testset[pt]\n",
        "        test_list_label = testset_label[pt]\n",
        "\n",
        "        print(len(train_list))\n",
        "        print(len(val_list))\n",
        "        print(len(test_list))\n",
        "\n",
        "\n",
        "        #define dataset and dataloader\n",
        "        train_dataset = SimpleImageDataset(train_list, train_list_label, train_data_transforms)\n",
        "        val_dataset = SimpleImageDataset(val_list, val_list_label, val_data_transforms)\n",
        "        test_dataset = SimpleImageDataset(test_list, test_list_label, test_data_transforms)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "        val_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True, pin_memory=True, num_workers=0)\n",
        "        test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\n",
        "\n",
        "        # show sample image\n",
        "        inputs, classes = next(iter(test_loader))\n",
        "        print(classes)\n",
        "        out = torchvision.utils.make_grid(inputs)\n",
        "        class_names = [\"cont\", \"gla\"]\n",
        "        imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "\n",
        "        model_ft = create_RepVGG_A2(deploy=False)\n",
        "        model_ft.load_state_dict(torch.load (\"F:\\先天性緑内障\\RepVGG-A2.pth\"))   \n",
        "        num_ftrs = model_ft.linear.in_features\n",
        "        model_ft.linear = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "        #GPU使用\n",
        "        model_ft = model_ft.to(device)\n",
        "\n",
        "        #損失関数を定義\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Observe that all parameters are being optimized\n",
        "        #https://blog.knjcode.com/adabound-memo/\n",
        "        #https://pypi.org/project/torch-optimizer/\n",
        "        from ranger_adabelief import RangerAdaBelief\n",
        "        optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))\n",
        "\n",
        "        model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=10, num_epochs=30)\n",
        "\n",
        "\n",
        "        # visualize the loss as the network trained\n",
        "        fig = plt.figure(figsize=(10,8))\n",
        "        plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "        plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "        # find position of lowest validation loss\n",
        "        minposs = valid_loss.index(min(valid_loss))+1 \n",
        "        plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "        plt.xlabel('epochs')\n",
        "        plt.ylabel('loss')\n",
        "        plt.ylim(0, 1.0) # consistent scale\n",
        "        plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "        plt.grid(True)\n",
        "        plt.legend()\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        fig.savefig('loss_plot.png', bbox_inches='tight')\n",
        "\n",
        "        #Prediction for testset\n",
        "        model_ft.eval() # prep model for evaluation\n",
        "        targets, probs, preds =[], [], []\n",
        "        for image_tensor, target in test_loader:  \n",
        "              #target = target.squeeze(1)     \n",
        "              image_tensor = image_tensor.to(device)\n",
        "              target = target.to(device)\n",
        "              # forward pass: compute predicted outputs by passing inputs to the model\n",
        "              output = model_ft(image_tensor)\n",
        "              _, pred = torch.max(output, 1) \n",
        "            \n",
        "              prob = nn.Softmax(dim=1)(output) #calculate probalility\n",
        "              prob = prob[0][1].cpu().detach() #probalility of being positive\n",
        "              print(prob)\n",
        "              print(pred) \n",
        "              \n",
        "              probs.append(prob)\n",
        "              preds.append(int(pred))  #予測結果\n",
        "              targets.append(int(target)) #ラベル\n",
        "        y_test = np.array(targets)\n",
        "        y_pred = np.array(preds)\n",
        "        y_prob = np.array(probs)\n",
        "        print(\"label\")\n",
        "        print(y_test)\n",
        "        print(\"pred\")\n",
        "        print(y_pred)\n",
        "        print(\"prob\")\n",
        "        print(y_prob)\n",
        "\n",
        "        #write result to df\n",
        "        row = 0\n",
        "        for i in testset[0:pt]:\n",
        "            row += len(i)\n",
        "        column = fold + 4\n",
        "        df_result.iloc[row:row+len(y_pred), column] = y_pred\n",
        "        column = fold + 9\n",
        "        df_result.iloc[row:row+len(y_pred), column] = y_prob\n",
        "        df_result.to_csv(result_csv_path,encoding=\"shift_jis\", index=False) #save as csv\n",
        "        \n",
        "\n",
        "        #経過時間を表示\n",
        "        time_end = time.perf_counter()\n",
        "        time_elapsed = (time_end - time_start)\n",
        "        print(\"Elapsed time: \"+str(time_elapsed))\n",
        "\n"
      ],
      "metadata": {
        "id": "wu9YkXhfJBFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**データセットをフォルダにコピー**"
      ],
      "metadata": {
        "id": "tWzsW2q6mnYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "#データのパスを指定\n",
        "pt=0\n",
        "fold=0\n",
        "train_list_gla = train_dataset_gla[pt][fold] \n",
        "train_list_cont = train_dataset_cont[pt][fold]\n",
        "val_list_gla = val_dataset_gla[pt][fold]\n",
        "val_list_cont = val_dataset_cont[pt][fold]\n",
        "\n",
        "#パスを指定\n",
        "train_gla = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\train\\gla\"\n",
        "train_cont = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\train\\cont\"\n",
        "val_gla = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\val\\gla\"\n",
        "val_cont = r\"F:\\先天性緑内障\\データ引継ぎ\\stratified\\val\\cont\"\n",
        "\n",
        "orig_path = [train_list_gla, train_list_cont, val_list_gla, val_list_cont]\n",
        "dst_path = [train_gla, train_cont, val_gla, val_cont]\n",
        "\n",
        "\n",
        "for folder in dst_path:\n",
        "    if os.path.exists(folder):\n",
        "        shutil.rmtree(folder)\n",
        "    os.makedirs(folder, exist_ok=True) \n",
        "\n",
        "for i in orig_path:\n",
        "    print(len(i))\n",
        "\n",
        "\n",
        "for orig_img_list, dst_folder in zip(orig_path, dst_path):\n",
        "    if not orig_img_list:\n",
        "        pass\n",
        "    else:\n",
        "        for origpath in orig_img_list:\n",
        "            basepath = os.path.basename(origpath)\n",
        "            dstpath = os.path.join(dst_folder, basepath)\n",
        "            shutil.copyfile(origpath, dstpath)\n",
        "            print(dstpath+ \" copied!\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "t-5NN-_smwNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**結果のCSVを開く**"
      ],
      "metadata": {
        "id": "anmRZaRx0acX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_result"
      ],
      "metadata": {
        "id": "HVZwL-S_xpla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 100)\n",
        "\n",
        "with codecs.open(result_csv_path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df_result = pd.read_csv(file, index_col=None, header=0)\n",
        "df_result"
      ],
      "metadata": {
        "id": "xdO8ZJ-qhV-5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "9d022645-4b8b-4126-fe6d-765da489b773"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     pt_number  img_number                                               path  \\\n",
              "0            0           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "1            0           1  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "2            0           2  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "3            0           3  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "4            0           4  F:\\先天性緑内障\\dataset_for_article_250px\\gla_exo\\15...   \n",
              "..         ...         ...                                                ...   \n",
              "917        738           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...   \n",
              "918        739           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...   \n",
              "919        740           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_eso...   \n",
              "920        741           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...   \n",
              "921        742           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...   \n",
              "\n",
              "     label    0    1    2    3    4        prob_1        prob_2    prob_3  \\\n",
              "0        1  0.0  0.0  0.0  0.0  0.0  4.165319e-05  3.190899e-08  0.000015   \n",
              "1        1  0.0  0.0  0.0  0.0  0.0  7.315485e-06  9.145639e-07  0.046556   \n",
              "2        1  0.0  0.0  0.0  0.0  0.0  4.044516e-03  7.267430e-03  0.000690   \n",
              "3        1  0.0  0.0  0.0  0.0  0.0  1.405735e-04  1.361361e-05  0.000459   \n",
              "4        1  0.0  0.0  0.0  0.0  0.0  2.691481e-03  3.929963e-04  0.008694   \n",
              "..     ...  ...  ...  ...  ...  ...           ...           ...       ...   \n",
              "917      0  0.0  0.0  0.0  0.0  0.0  9.160846e-03  1.301840e-01  0.000982   \n",
              "918      0  0.0  0.0  0.0  0.0  0.0  1.095138e-02  1.101165e-02  0.002216   \n",
              "919      0  0.0  0.0  0.0  0.0  0.0  1.177738e-03  5.399497e-03  0.132837   \n",
              "920      0  0.0  0.0  0.0  0.0  0.0  3.356482e-08  8.184286e-04  0.000129   \n",
              "921      0  0.0  0.0  0.0  0.0  0.0  2.145674e-02  4.892504e-03  0.221697   \n",
              "\n",
              "       prob_4    prob_5  \n",
              "0    0.032600  0.001643  \n",
              "1    0.015487  0.017604  \n",
              "2    0.044668  0.438548  \n",
              "3    0.286254  0.034377  \n",
              "4    0.213815  0.009396  \n",
              "..        ...       ...  \n",
              "917  0.045331  0.000930  \n",
              "918  0.051758  0.015773  \n",
              "919  0.005434  0.023663  \n",
              "920  0.000058  0.000059  \n",
              "921  0.001051  0.001390  \n",
              "\n",
              "[922 rows x 14 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pt_number</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>prob_1</th>\n",
              "      <th>prob_2</th>\n",
              "      <th>prob_3</th>\n",
              "      <th>prob_4</th>\n",
              "      <th>prob_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.165319e-05</td>\n",
              "      <td>3.190899e-08</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.032600</td>\n",
              "      <td>0.001643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.315485e-06</td>\n",
              "      <td>9.145639e-07</td>\n",
              "      <td>0.046556</td>\n",
              "      <td>0.015487</td>\n",
              "      <td>0.017604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.044516e-03</td>\n",
              "      <td>7.267430e-03</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.044668</td>\n",
              "      <td>0.438548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.405735e-04</td>\n",
              "      <td>1.361361e-05</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>0.286254</td>\n",
              "      <td>0.034377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px\\gla_exo\\15...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.691481e-03</td>\n",
              "      <td>3.929963e-04</td>\n",
              "      <td>0.008694</td>\n",
              "      <td>0.213815</td>\n",
              "      <td>0.009396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>738</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.160846e-03</td>\n",
              "      <td>1.301840e-01</td>\n",
              "      <td>0.000982</td>\n",
              "      <td>0.045331</td>\n",
              "      <td>0.000930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>739</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.095138e-02</td>\n",
              "      <td>1.101165e-02</td>\n",
              "      <td>0.002216</td>\n",
              "      <td>0.051758</td>\n",
              "      <td>0.015773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>740</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_eso...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.177738e-03</td>\n",
              "      <td>5.399497e-03</td>\n",
              "      <td>0.132837</td>\n",
              "      <td>0.005434</td>\n",
              "      <td>0.023663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>741</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.356482e-08</td>\n",
              "      <td>8.184286e-04</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>742</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.145674e-02</td>\n",
              "      <td>4.892504e-03</td>\n",
              "      <td>0.221697</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>0.001390</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>922 rows × 14 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# \\\\1546-2.jpg\n",
        "# \\\\1546-2.jpg\n",
        "#アンダーバーとハイフンが混ざっておりIDが誤って振られているので修正\n",
        "######################################################################\n",
        "\n",
        "k = 0\n",
        "for i in range(len(df_result)):\n",
        "    if k==0:\n",
        "        pt_number = 0\n",
        "        img_number = 0\n",
        "    else:\n",
        "        pt_path = df_result.loc[k, \"path\"]\n",
        "        pt_id = re.split(\"[-_]\", pt_path.rsplit(\"\\\\\", maxsplit=1)[1])[0]\n",
        "        pt_path_prev = df_result.loc[k-1, \"path\"]\n",
        "        pt_id_prev = re.split(\"[-_]\", pt_path_prev.rsplit(\"\\\\\", maxsplit=1)[1])[0]\n",
        "        if pt_id == pt_id_prev:\n",
        "            pt_number = pt_number\n",
        "            img_number += 1\n",
        "        elif pt_id != pt_id_prev:\n",
        "            pt_number += 1\n",
        "            img_number = 0 \n",
        "\n",
        "    df_result.loc[k, \"pt_number\"] = pt_number #同じ患者ではimg_numberを通し番号で割り振る\n",
        "    df_result.loc[k, \"img_number\"] = img_number #同じ患者ではimg_numberを通し番号で割り振る\n",
        "    k+= 1\n",
        "\n",
        "df_result\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "Oms485LS8jZU",
        "outputId": "3cf96cb5-42c9-492e-e099-6fbf6c18e019"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     pt_number  img_number                                               path  \\\n",
              "0            0           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "1            0           1  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "2            0           2  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "3            0           3  F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...   \n",
              "4            0           4  F:\\先天性緑内障\\dataset_for_article_250px\\gla_exo\\15...   \n",
              "..         ...         ...                                                ...   \n",
              "917        718           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...   \n",
              "918        719           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...   \n",
              "919        720           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_eso...   \n",
              "920        721           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...   \n",
              "921        722           0  F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...   \n",
              "\n",
              "     label    0    1    2    3    4        prob_1        prob_2    prob_3  \\\n",
              "0        1  0.0  0.0  0.0  0.0  0.0  4.165319e-05  3.190899e-08  0.000015   \n",
              "1        1  0.0  0.0  0.0  0.0  0.0  7.315485e-06  9.145639e-07  0.046556   \n",
              "2        1  0.0  0.0  0.0  0.0  0.0  4.044516e-03  7.267430e-03  0.000690   \n",
              "3        1  0.0  0.0  0.0  0.0  0.0  1.405735e-04  1.361361e-05  0.000459   \n",
              "4        1  0.0  0.0  0.0  0.0  0.0  2.691481e-03  3.929963e-04  0.008694   \n",
              "..     ...  ...  ...  ...  ...  ...           ...           ...       ...   \n",
              "917      0  0.0  0.0  0.0  0.0  0.0  9.160846e-03  1.301840e-01  0.000982   \n",
              "918      0  0.0  0.0  0.0  0.0  0.0  1.095138e-02  1.101165e-02  0.002216   \n",
              "919      0  0.0  0.0  0.0  0.0  0.0  1.177738e-03  5.399497e-03  0.132837   \n",
              "920      0  0.0  0.0  0.0  0.0  0.0  3.356482e-08  8.184286e-04  0.000129   \n",
              "921      0  0.0  0.0  0.0  0.0  0.0  2.145674e-02  4.892504e-03  0.221697   \n",
              "\n",
              "       prob_4    prob_5  \n",
              "0    0.032600  0.001643  \n",
              "1    0.015487  0.017604  \n",
              "2    0.044668  0.438548  \n",
              "3    0.286254  0.034377  \n",
              "4    0.213815  0.009396  \n",
              "..        ...       ...  \n",
              "917  0.045331  0.000930  \n",
              "918  0.051758  0.015773  \n",
              "919  0.005434  0.023663  \n",
              "920  0.000058  0.000059  \n",
              "921  0.001051  0.001390  \n",
              "\n",
              "[922 rows x 14 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pt_number</th>\n",
              "      <th>img_number</th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>prob_1</th>\n",
              "      <th>prob_2</th>\n",
              "      <th>prob_3</th>\n",
              "      <th>prob_4</th>\n",
              "      <th>prob_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.165319e-05</td>\n",
              "      <td>3.190899e-08</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.032600</td>\n",
              "      <td>0.001643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.315485e-06</td>\n",
              "      <td>9.145639e-07</td>\n",
              "      <td>0.046556</td>\n",
              "      <td>0.015487</td>\n",
              "      <td>0.017604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.044516e-03</td>\n",
              "      <td>7.267430e-03</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>0.044668</td>\n",
              "      <td>0.438548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\gla_orth...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.405735e-04</td>\n",
              "      <td>1.361361e-05</td>\n",
              "      <td>0.000459</td>\n",
              "      <td>0.286254</td>\n",
              "      <td>0.034377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px\\gla_exo\\15...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.691481e-03</td>\n",
              "      <td>3.929963e-04</td>\n",
              "      <td>0.008694</td>\n",
              "      <td>0.213815</td>\n",
              "      <td>0.009396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>917</th>\n",
              "      <td>718</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.160846e-03</td>\n",
              "      <td>1.301840e-01</td>\n",
              "      <td>0.000982</td>\n",
              "      <td>0.045331</td>\n",
              "      <td>0.000930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>918</th>\n",
              "      <td>719</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_ort...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.095138e-02</td>\n",
              "      <td>1.101165e-02</td>\n",
              "      <td>0.002216</td>\n",
              "      <td>0.051758</td>\n",
              "      <td>0.015773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>919</th>\n",
              "      <td>720</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_eso...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.177738e-03</td>\n",
              "      <td>5.399497e-03</td>\n",
              "      <td>0.132837</td>\n",
              "      <td>0.005434</td>\n",
              "      <td>0.023663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>920</th>\n",
              "      <td>721</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.356482e-08</td>\n",
              "      <td>8.184286e-04</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>921</th>\n",
              "      <td>722</td>\n",
              "      <td>0</td>\n",
              "      <td>F:\\先天性緑内障\\dataset_for_article_250px_2\\cont_exo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.145674e-02</td>\n",
              "      <td>4.892504e-03</td>\n",
              "      <td>0.221697</td>\n",
              "      <td>0.001051</td>\n",
              "      <td>0.001390</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>922 rows × 14 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#変更されたdf_resultの目視確認用\n",
        "df_result.to_csv(r\"F:\\先天性緑内障\\result_Random_確認用.csv\", encoding=\"shift_jis\")"
      ],
      "metadata": {
        "id": "p6a1VZLdKPfb"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "\n",
        "#sorted(sklearn.metrics.SCORERS.keys())\n",
        "\n",
        "\n",
        "#indexの内容を確認\n",
        "#print(df.columns.values.tolist())\n",
        "\n",
        "\n",
        "FEATURE_COLS=df_result.columns.values[1:].tolist()\n",
        "\n",
        "\"\"\"\n",
        "FEATURE_COLS=[\n",
        " 'cropped_A2',\n",
        " 'cropped_B3']\n",
        "\"\"\"\n",
        "\n",
        "print(FEATURE_COLS)\n",
        "\n",
        "# 訓練データとテストデータに分割する。\n",
        "from sklearn.model_selection import train_test_split\n",
        "# TODO:層別サンプリング train, test = train_test_split(df, test_size=0.20, stratify=df[\"町区分\"], random_state=100)\n",
        "train, test = train_test_split(df_result, test_size=0.20,random_state=100)\n",
        "\n",
        "X_train = train[FEATURE_COLS[8:13]]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[FEATURE_COLS[8:13]]\n",
        "Y_test = test[\"label\"]\n"
      ],
      "metadata": {
        "id": "YWTX_kVS1Btc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1adb89ca-cd13-4313-cd41-597aa49c3ee8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\compat\\pandas.py:65: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import Int64Index as NumericIndex\n",
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['img_number', 'path', 'label', '0', '1', '2', '3', '4', 'prob_1', 'prob_2', 'prob_3', 'prob_4', 'prob_5']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn; \n",
        "\n",
        "!pip install bayesian-optimization \n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "\n",
        "#　　精度確認\n",
        "# 自由度調整済みr2を算出\n",
        "def adjusted_r2(X,Y):\n",
        "    from sklearn.metrics import r2_score\n",
        "    import numpy as np\n",
        "    r_squared = r2_score(Y, X)\n",
        "    adjusted_r2 = 1 - (1-r_squared)*(len(Y)-1)/(len(Y)-2)\n",
        "    #yhat = model.predict(X) \\ #SS_Residual = sum((Y-yhat)**2) \\ #SS_Total = sum((Y-np.mean(Y))**2)\n",
        "    #r_squared = 1 - (float(SS_Residual))/ SS_Total\n",
        "    return adjusted_r2\n",
        "\n",
        "# 予測モデルの精度確認の各種指標を算出\n",
        "def get_model_evaluations(X_train,Y_train,X_test,Y_test):\n",
        "    from sklearn.metrics import explained_variance_score\n",
        "    from sklearn.metrics import mean_absolute_error\n",
        "    from sklearn.metrics import mean_squared_error\n",
        "    from sklearn.metrics import mean_squared_log_error\n",
        "    from sklearn.metrics import median_absolute_error\n",
        "\n",
        "   # 評価指標確認\n",
        "   # 参考: https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/\n",
        "    yhat_test = X_test\n",
        "\n",
        "    print(\"adjusted_r2(train)     :\" + str(adjusted_r2(X_train,Y_train)))\n",
        "    print(\"adjusted_r2(test)      :\" + str(adjusted_r2(X_test,Y_test)))   \n",
        "    #print(\"平均誤差率(test)       :\" + str(np.mean(abs(Y_test / yhat_test - 1)))) \n",
        "    print(\"MAE(test)              :\" + str(mean_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"MedianAE(test)         :\" + str(median_absolute_error(Y_test, yhat_test)))\n",
        "    print(\"RMSE(test)             :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test))))\n",
        "    print(\"RMSE(test) / MAE(test) :\" + str(np.sqrt(mean_squared_error(Y_test, yhat_test)) / mean_absolute_error(Y_test, yhat_test))) #better if result = 1.253\n",
        "\n",
        "for i in FEATURE_COLS[8:13]:\n",
        "    X_train = train[i]\n",
        "    Y_train = train[\"label\"]\n",
        "    X_test = test[i]\n",
        "    Y_test = test[\"label\"]\n",
        "    #print(str(i))\n",
        "    #get_model_evaluations(X_train,Y_train,X_test,Y_test)\n",
        "    #print(\"\")\n",
        "\n",
        "\n",
        "#後の解析のためにそれぞれの項目を戻しておく\n",
        "X_train = train[FEATURE_COLS[8:13]]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[FEATURE_COLS[8:13]]\n",
        "Y_test = test[\"label\"]\n"
      ],
      "metadata": {
        "id": "CYwTK7oJ2tIC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80fe50c-ebc7-48ac-c85b-d83c6ac56f5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bayesian-optimization in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bayesian-optimization) (1.22.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bayesian-optimization) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from bayesian-optimization) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (3.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: You are using pip version 22.0.2; however, version 22.0.4 is available.\n",
            "You should consider upgrading via the 'c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
        "\n",
        "\n",
        "\"\"\"XGBoost で二値分類するサンプルコード\"\"\"\n",
        "\n",
        "X_train = train[FEATURE_COLS[8:13]]\n",
        "Y_train = train[\"label\"]\n",
        "X_test = test[FEATURE_COLS[8:13]]\n",
        "Y_test = test[\"label\"]\n",
        "\n",
        "\n",
        "# XGBoost が扱うデータセットの形式に直す\n",
        "dtrain = xgb.DMatrix(X_train, label=Y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=Y_test)\n",
        "# 学習用のパラメータ\n",
        "xgb_params = {\n",
        "    # 二値分類問題\n",
        "    'objective': 'binary:logistic',\n",
        "    # 評価指標\n",
        "    'eval_metric': 'logloss',\n",
        "}\n",
        "# モデルを学習する\n",
        "bst = xgb.train(xgb_params,\n",
        "                dtrain,\n",
        "                num_boost_round=100,  # 学習ラウンド数は適当\n",
        "                )\n",
        "# 検証用データが各クラスに分類される確率を計算する\n",
        "Y_pred_proba = bst.predict(dtest)\n",
        "# しきい値 0.5 で 0, 1 に丸める\n",
        "Y_pred = np.where(Y_pred_proba > 0.5, 1, 0)\n",
        "# 精度 (Accuracy) を検証する\n",
        "acc = accuracy_score(Y_test, Y_pred)\n",
        "print('Accuracy:', acc)\n",
        "\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y_test, Y_pred).ravel()\n",
        "print(tp, fn, fp, tn)\n",
        "\n",
        "def specificity_score(label, pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "\n",
        "print('confusion matrix = \\n', confusion_matrix(Y_test, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y_test, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y_test, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y_test, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y_test, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y_test, Y_pred)}')\n",
        "\n",
        "\n",
        "#ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, Y_pred_proba)     \n",
        "plt.plot(fpr, tpr, marker='o')\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.grid()\n",
        "print(f'Area_under_ROC : {roc_auc_score(Y_test, Y_pred_proba)}')\n",
        "#plt.savefig('plots/roc_curve.png')\n"
      ],
      "metadata": {
        "id": "pto6ZDKycgFc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "outputId": "5d2b321a-ee5a-4edb-c780-089bb5185db1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9027027027027027\n",
            "42 13 5 125\n",
            "confusion matrix = \n",
            " [[125   5]\n",
            " [ 13  42]]\n",
            "Accuracy : 0.9027027027027027\n",
            "Precision (true positive rate) : 0.8936170212765957\n",
            "Recall (sensitivity): 0.7636363636363637\n",
            "Specificity : 0.9615384615384616\n",
            "F1 score : 0.8235294117647058\n",
            "Area_under_ROC : 0.9690909090909091\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "accuracy = []\n",
        "precision = []\n",
        "recall = []\n",
        "specificity = []\n",
        "f1score = []\n",
        "area_u_ROC = []\n",
        "\n",
        "\n",
        "for i in range(8,13):\n",
        "    print(\"fold\",i)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= 0.5, 1, 0)\n",
        "\n",
        "    acc = accuracy_score(Y, Y_pred)\n",
        "    print('Accuracy:',acc)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    print(tp, fn, fp, tn)\n",
        "\n",
        "    def specificity_score(label, pred):\n",
        "        tn, fp, fn, tp = confusion_matrix(label, pred).flatten()\n",
        "        return tn / (tn + fp)\n",
        "\n",
        "\n",
        "    print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "    #ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(Y, Y_pred_proba)     \n",
        "    plt.plot(fpr, tpr, marker='o')\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.grid()\n",
        "    print(f'Area_under_ROC : {roc_auc_score(Y, Y_pred_proba)}')\n",
        "    #plt.savefig('plots/roc_curve.png')\n",
        "\n",
        "    accuracy.append(accuracy_score(Y, Y_pred))\n",
        "    precision.append(precision_score(Y, Y_pred))\n",
        "    recall.append(recall_score(Y, Y_pred))\n",
        "    specificity.append(specificity_score(Y, Y_pred))\n",
        "    f1score.append(f1_score(Y, Y_pred))\n",
        "    area_u_ROC.append(roc_auc_score(Y, Y_pred_proba))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "print(\"Result of 5-fold crossvalidation\")\n",
        "print(\"accuracy: \", statistics.mean(accuracy))\n",
        "print(\"precision: \", statistics.mean(precision))\n",
        "print(\"recall (sensitivity): \", statistics.mean(recall))\n",
        "print(\"specifiity: \", statistics.mean(specificity))\n",
        "print(\"f1_score: \", statistics.mean(f1score))\n",
        "print(\"area_u_ROC: \", statistics.mean(area_u_ROC))"
      ],
      "metadata": {
        "id": "JxVZZLTNv_Ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ROC curve描き直し\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.rcParams[\"font.family\"] = \"Helvetica\"   # 使用するフォント\n",
        "    plt.rcParams[\"font.size\"] = 10 \n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == 1:\n",
        "                  y_true.append(1)\n",
        "            elif i == 0:\n",
        "                  y_true.append(0)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "for i in range(8,13):\n",
        "    print(\"fold\",i)\n",
        "    X = df_result[FEATURE_COLS[i]]\n",
        "    Y = df_result[\"label\"]\n",
        "\n",
        "    Y_pred_proba = X\n",
        "    Y_pred = np.where(Y_pred_proba >= 0.5, 1, 0)\n",
        "\n",
        "    label_list_list.append(Y)\n",
        "    model_pred_prob_list.append(Y_pred_proba)\n",
        "\n",
        "#Draw ROC curve\n",
        "roc_label_list = list(range(5))\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list))\n"
      ],
      "metadata": {
        "id": "ZBDF-nm0oJll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**患者ごとの正答率**"
      ],
      "metadata": {
        "id": "Cllzo5UeazmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 1000)\n",
        "df_result"
      ],
      "metadata": {
        "id": "_XkW7jUva_GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Draw_roc_curve_patients(fpr_list, tpr_list, thred_list):\n",
        "\n",
        "    #グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = \"r\"     # プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    roc_auc = auc(fpr_list, tpr_list)\n",
        "\n",
        "    plt.plot(fpr_list, tpr_list, color=ycolor,lw=lw, label= 'ROC curve (area = %0.2f)' % roc_auc)\n",
        "        \n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    #prob = np.round(prob, decimals=3) #probabilityの数字を小数点3桁までにする（ROC curveに斜めの線が入るのを防ぐため）\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist()\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "    return int(pred)\n",
        "\n",
        "\n",
        "def calculate_fpr_tpr(pt_gla, pt_cont, df_result, threshold):\n",
        "    label_list, pred_list = [], []\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(label_list, pred_list).ravel()\n",
        "    fpr, tpr = fp/(tn+fp), tp/(tp+fn)\n",
        "    return fpr, tpr"
      ],
      "metadata": {
        "id": "SMgmeYVU5UKV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "#ざっくり10点でROC curveを描いてみる\n",
        "thred_list = [i/100 for i in range(100)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)\n",
        "\n",
        "print(\"pt_gla: \", pt_gla)\n",
        "print(\"pt_cont: \", pt_cont)"
      ],
      "metadata": {
        "id": "YU3yDjBr5J8b",
        "outputId": "1a553556-1112-4973-c4ce-d7102bd65862",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "findfont: Font family ['Helvetica'] not found. Falling back to DejaVu Sans.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_gla:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "pt_cont:  [47, 86, 90, 94, 98, 138, 151, 158, 185, 203, 256, 259, 280, 293, 295, 316, 342, 352, 369, 376, 400, 479, 482, 501, 521, 540, 560, 572, 616, 631, 634, 644, 671, 701, 702]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "threshold = 0.05 #判定基準。ここは先に入力しておく\n",
        "random.seed(100)\n",
        "#################################################\n",
        "\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "df_pt_analysis\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "print(Y)\n",
        "print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "##Calcurate the Youden's J static\n",
        "#https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "tpr = np.array(tpr_list)\n",
        "fpr = np.array(fpr_list)\n",
        "thresholds = np.array(thred_list)\n",
        "\n",
        "youdenJ = tpr - fpr\n",
        "\n",
        "# Calculate the G-mean\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "\n",
        "#Find the optimal threshold\n",
        "# Find the optimal threshold\n",
        "index = np.argmax(youdenJ)\n",
        "\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))\n",
        "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "print(\"\")\n",
        "\n",
        "##Youden's indexをもとにした正答率を計算\n",
        "#################################################\n",
        "threshold = thresholdOpt #判定基準\n",
        "#################################################\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "df_pt_analysis\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "#print(Y)\n",
        "#print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print(\"Using Youden's index\")\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IwAhKEE8bAUj",
        "outputId": "627f897c-36fa-4c72-c3e6-25ae4d6362b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "confusion matrix = \n",
            " [[31  4]\n",
            " [ 6 29]]\n",
            "Accuracy : 0.8571428571428571\n",
            "Precision (true positive rate) : 0.8787878787878788\n",
            "Recall (sensitivity): 0.8285714285714286\n",
            "Specificity : 0.8857142857142857\n",
            "F1 score : 0.8529411764705883\n",
            "\n",
            "Best Threshold: 0.06 with Youden J statistic: 0.8839\n",
            "FPR: 0.0571, TPR: 0.8286\n",
            "\n",
            "Using Youden's index\n",
            "confusion matrix = \n",
            " [[32  3]\n",
            " [ 6 29]]\n",
            "Accuracy : 0.8714285714285714\n",
            "Precision (true positive rate) : 0.90625\n",
            "Recall (sensitivity): 0.8285714285714286\n",
            "Specificity : 0.9142857142857143\n",
            "F1 score : 0.8656716417910447\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**患者毎のROC curveを出す**"
      ],
      "metadata": {
        "id": "XwL_bOd5Kute"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Draw_roc_curve_patients(fpr_list, tpr_list, thred_list):\n",
        "\n",
        "    #グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = \"r\"     # プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    roc_auc = auc(fpr_list, tpr_list)\n",
        "\n",
        "    plt.plot(fpr_list, tpr_list, color=ycolor,lw=lw, label= 'ROC curve (area = %0.2f)' % roc_auc)\n",
        "        \n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    #prob = np.round(prob, decimals=3) #probabilityの数字を小数点3桁までにする（ROC curveに斜めの線が入るのを防ぐため）\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist()\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "    return int(pred)\n",
        "\n",
        "\n",
        "def calculate_fpr_tpr(pt_gla, pt_cont, df_result, threshold):\n",
        "    label_list, pred_list = [], []\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        label_list.append(label)\n",
        "        pred_list.append(pred)\n",
        "    tn, fp, fn, tp = confusion_matrix(label_list, pred_list).ravel()\n",
        "    fpr, tpr = fp/(tn+fp), tp/(tp+fn)\n",
        "    return fpr, tpr\n",
        " "
      ],
      "metadata": {
        "id": "Emx_Nw5NnJ62"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "#ざっくり10点でROC curveを描いてみる\n",
        "thred_list = [i/100 for i in range(100)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)\n",
        "\n",
        "print(\"pt_gla: \", pt_gla)\n",
        "print(\"pt_cont: \", pt_cont)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "w5hlns7iMy9Q",
        "outputId": "25b34638-cc4f-4273-ee93-e97686c2adc4"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAGDCAYAAAA72Cm3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABOXUlEQVR4nO3dd3hUZfrG8e+ThBAIVbp0FaRJM4AgCAIiIoiCihRXEAuusLa1l7WgP1dRsa0IymJBcAUUVBRFUVCkhN6UJlKVSO8hyfv74wxxgBAGksnJJPfnuuZiTr/nJOSZ9z3NnHOIiIhI5InyO4CIiIicHhVxERGRCKUiLiIiEqFUxEVERCKUiriIiEiEUhEXERGJUCriIscws2Vm1sbvHH4zs2Fm9mgOb3OUmQ3OyW2Gi5n1NrOvTnNZ/Q5KSEzXiUtuZmbrgHJAKrAX+BIY6Jzb62euvMbM+gI3Oeda+pxjFLDROfeIzzkeB85xzvXJgW2NIhd8ZolMaolLJOjinCsCNAQaAQ/6G+fUmVlMfty2n7TPJT9QEZeI4Zz7HZiCV8wBMLMLzGymme00s0XBXZBmdoaZ/dfMNpvZDjP7JGhaZzNbGFhuppnVD5q2zszam9mZZnbAzM4ImtbIzP40swKB4RvNbEVg/VPMrGrQvM7MbjezVcCqjD6TmV0R6DrdaWbfmVntY3I8aGbLA+v/r5nFncJnuN/MFgP7zCzGzB4wszVmtiewzqsC89YGhgHNzWyvme0MjE/v2jazNma20czuMbOtZrbFzPoFba+UmX1qZrvNbK6ZDTazH070szSzlkE/tw2BnoAjSprZ54Gcs83s7KDlXg7Mv9vM5plZq6Bpj5vZODN738x2A33NrKmZ/RTYzhYze83MYoOWqWtmX5vZdjP7w8weMrOOwENAj8D+WBSYt7iZvR1Yz6bAZ4wOTOtrZj+a2Utmtg14PDDuh8B0C0zbGsi+xMzqmdktQG/gvsC2Pg36+bUPvI8O5Drys5tnZpVPtG8ln3HO6aVXrn0B64D2gfeVgCXAy4HhisA2oBPeF9JLAsNlAtM/Bz4ESgIFgNaB8Y2ArUAzIBq4IbCdghls81vg5qA8zwPDAu+7AquB2kAM8AgwM2heB3wNnAEUyuCz1QT2BXIXAO4LrC82KMdSoHJgHT8Cg0/hMywMLFsoMO4a4MzAvuoR2HaFwLS+wA/H5BsVtL02QArwZCBrJ2A/UDIwfWzgVRioA2w4dn1B660K7AF6BtZVCmgYtM1tQNPAPh0NjA1atk9g/hjgHuB3IC4w7XHgMHBl4DMWAs4HLgjMXw1YAdwZmL8osCWwnrjAcLOgdb1/TO6PgTeBeKAsMAe4NWj/pQCDAtsqFLxPgUuBeUAJwPB+Zyocu59P8Ht/L97v/bmBZRsApfz+v6lX7nj5HkAvvTJ7Bf6Y7Q380XfAN0CJwLT7gfeOmX8KXkGrAKQdKTLHzPMG8NQx437hryIf/Af0JuDbwHsLFKeLAsNfAP2D1hGFV9iqBoYd0DaTz/Yo8L9jlt8EtAnKMSBoeidgzSl8hhtPsm8XAl0D79MLTtD09OKCV8QPADFB07fiFchovOJ5btC0wceuL2jag8DHJ5g2CnjrmM/8cyafYQfQIPD+cWD6ST7znUe2jfclYsEJ5nucoCKOd17GIYK+jAWWnxa0/9Yfs470fQq0BVYG9lfUifbzMb/3R34Hfznyc9JLr2Nf6k6XSHClc64oXiGpBZQOjK8KXBPoKt0Z6AZuiVfAKwPbnXM7MlhfVeCeY5arjNdKPdZ4vG7mCsBFeF8MZgSt5+WgdWzHK/QVg5bfkMnnOhP47ciAcy4tMP+Jlv8tKGMon+GobZvZ34K633cC9fhrX4Zim3MuJWh4P1AEKIPX+gzeXmafuzKwJpPpv2ewDQDM7J/mHb7YFfgMxTn6Mxz7mWua2Wdm9nugi/2ZoPlPliNYVbxegy1B++9NvBZ5htsO5pz7FngNeB3YambDzaxYiNs+lZySz6iIS8Rwzn2P12oZEhi1Aa8lXiLoFe+cezYw7QwzK5HBqjYATx+zXGHn3JgMtrkD+Aqv+7kXXteuC1rPrcesp5BzbmbwKjL5SJvxigPgHTfF+4O9KWie4GOfVQLLhPoZ0rdt3rH6EcBAvK7YEnhd9RZCzpNJwutKrnSC3MfaAJydyfQMBY5/3wdci9fDUgLYxV+fAY7/HG8APwM1nHPF8I51H5l/A3DWCTZ37Ho24LXESwft72LOubqZLHP0Cp17xTl3Pt7hhpp43eQnXY7T3F+SP6iIS6QZClxiZg2A94EuZnZp4OSfuMAJWJWcc1vwurv/Y2YlzayAmV0UWMcIYICZNQuccBRvZpebWdETbPMD4G/A1YH3RwwDHjSzupB+4tM1p/BZ/gdcbmbtzDtR7h68QhH8JeB2M6tk3sl1D+Md4z+dzxCPVyySAln74bXEj/gDqBR80leonHOpwAS8k7kKm1ktvP11IqOB9mZ2rXkn3JUys4YhbKoo3peFJCDGzB4DTtaaLQrsBvYGct0WNO0zoIKZ3WlmBc2sqJk1C0z7A6hmZlGBz7gF78vcC2ZWzMyizOxsM2sdQm7MrEngZ1UA71yEg3i9Oke2daIvEwBvAU+ZWY3Az7q+mZUKZbuS96mIS0RxziUB7wKPOec24J1c9hDeH/YNeK2bI7/X1+Mdq/0Z7/jtnYF1JAI343Vv7sA7maxvJpudBNQAfnfOLQrK8jHwb2BsoKt2KXDZKXyWX/BO1HoV+BPognc5XXLQbB/gFY+1eF2qg0/nMzjnlgMvAD/hFY3z8E6UO+JbYBnwu5n9GepnCDIQr2v7d+A9YAzeF5KMsqzHO9Z9D94hiIV4J2udzBS8+wSsxDu0cJDMu+0B/onXg7IH74vPkS9BOOf24J1U2CWQexVwcWDyR4F/t5nZ/MD7vwGxwHK8fT4O79BNKIoFtr8jkH0b3kmSAG8DdQLd9J9ksOyLeF/4vsL7QvI23olzIrrZi0huZd6Nbm5yzk31O8upMrN/A+Wdczf4nUUkL1NLXESyzMxqBbp5zcyaAv3xLskSkTDSXYVEJDsUxetCPxOvu/4FYKKviUTyAXWni4iIRCh1p4uIiEQoFXEREZEIFXHHxEuXLu2qVavmdwwREZEcMW/evD+dc2UymhZxRbxatWokJib6HUNERCRHmNlvJ5qm7nQREZEIpSIuIiISoVTERUREIpSKuIiISIRSERcREYlQKuIiIiIRSkVcREQkQqmIi4iIRCgVcRERkQgVtiJuZiPNbKuZLT3BdDOzV8xstZktNrPG4coiIiKSF4WzJT4K6JjJ9MuAGoHXLcAbYcwiIiKS54Tt3unOuelmVi2TWboC7zrvgeazzKyEmVVwzm0JVyYREZEsSUmB3bth507vtWvXUf/u+O0PSnIQHnwQypYNexw/H4BSEdgQNLwxMO64Im5mt+C11qlSpUqOhBMRkTzGOTh48IQFOP3fzMbt3ZvpJkoeeXPDDXm+iIfMOTccGA6QkJDgfI4jIiJ+SEv7qxV8OgV45044fDhrGcygeHEoUSL9370xhfhu4S7WbEtjj8XRtnsjWpQvn7XthMjPIr4JqBw0XCkwTkRE8qJDh7JWgPfs8VrTWREbCyVLHleIj3qf2bgiRSDq6NPJru00mi+2raZq1eKMGdOd5s0rk1P8LOKTgIFmNhZoBuzS8XARkVzKOa8rOZRie6JxBw9mPUexYqEV2xNNi4vLeoZjDBvWmSee+I4XXriUEiWyf/2ZCVsRN7MxQBugtJltBP4FFABwzg0DJgOdgNXAfqBfuLKIiOR7hw+ffgt41y7vlZaWtQwxMccX1lMpwMWKQXR01jJkgwULtvDWW/N59dVOREUZVaoU5+23u/qSJZxnp/c8yXQH3B6u7YuI5BnOwf79p1+Ad+70ls+q+PjTL8AlSkChQt4x5QjlnOOVV2Zz331TSU5OpXHjCvTv7+8tTiLixDYRkYiWmvpXa/Z0CvCuXd6lTVkRFZW1AlysGBQokLUMEezPP/fTr99EPvtsJQC33ZZAr17n+ZxKRVxEJHNHLkvKSgHesyfrOQoVOv2TsUqU8FrREdwK9tN3362jd+8JbN68hxIl4nj77Svo1q2237EAFXERyevS0rwieroFeOdOSE7OWgYzryV7Oi3gI+9jY7OWQU7L1Klr6dDhPZyDCy+szAcfdKdKleJ+x0qnIi4iuVtyctYK8O7d2XNZUlYKcNGix12WJJGhdeuqtGhRmbZtq/PYY62JicldP0cVcREJnyOXJZ1uAd65M3suSypa9PQLcIkSYbksSXKviRN/pkWLypQpE0+BAtF8913fXFe8j1ARF5ETS0nJWgHOzsuSTrcA55LLkiT3O3DgMPfc8xVvvJHI5ZfX4NNPe2JmubaAg4q4SN7lHBw4kLUCvG9f1nMULnzqJ2EFjytcWCdkSdgtW7aV664bz9KlW4mNjaZDh7P9jhQSFXGR3Co1Nev3ic6Oy5JOtwVcvLj3yseXJUnu55zjrbfmc8cdX3LgQAo1a5Zi7NjuNGpUwe9oIVERFwmXI09Lysp9orMqLu70C/CR+0SrFSx5VFqao3fvCYwduxSAvn0b8uqrl1GkSORcCaAiLpKRI5clZeU2lYcOZT3Hkdbs6RTg4sWhYMGsZxDJo6KijMqVi1GkSCzDhl1O7971/Y50ysxl9dKLHJaQkOASExP9jiHhtnUrzJgBP/2UPcdlM5LZMeNdu7J+WVKBAqHdJ/pEBbhoUZ2QJZLN0tIc69fvolq1EgAkJ6eyadNuqlcvmfmCPjKzec65hIymqSUuucPGjTB9uvf6/nv4+We/E3ldyadbgI9clqSuaJFcY8uWPVx//cf8/POfLFo0gFKlChMbG52rC/jJqIhLznMOfv3VK9ZHCvfatUfPU6gQtGgBrVpB2bLhy1Ko0InvEx2j/x4iecUXX6zihhs+ISlpP2XKFGbNmh2UKlXY71hZpr9SEn7OeS3rI63s6dNh06aj5ylWDFq2hIsu8l7nn6/bTIpIliUnp/Lgg1N58cVZALRvfxbvvnslFSoU9TlZ9lARl+yXlgZLlhzd0k5KOnqeM87winXr1t6/DRro+K+IZKvVq7fTs+d4EhM3Ex1tDB7clvvuu5CoqLxzmEtFXLLu8GFYsOCvlvYPP3gniAUrX/6vgn3RRVCnju4lLSJhtWrVNhITN1OtWgnGjOnOBRdU8jtStlMRl1N36BDMmfNXK/vHH48/g7xq1aNb2ueco5O8RCTsUlPTiI72GgiXXVaD99+/issvr0mJEnnz/vcq4nJy+/bBrFl/dY/PmnX8NdA1a/7Vyr7oIq+Ii4jkoPnzt9CnzwSGD+9Cy5ZVACLy2u9ToSIux9u7969W9vTpMHfu8bfvrFfvr5Z2q1ZQITJuUSgieY9zjpdfns39908lOTmVZ5/9gc8+6+V3rByhIi5H+/lnaNMG/vjjr3FRUd7Z4kda2a1aQalSvkUUETkiKWkf/fpN5PPPVwHw978nMGRIB59T5RwVcfnLxo3QoYNXwOvWhS5dvKLdooV3/bSISC4ybdqv9O49gS1b9lKiRBwjR17BVVfV9jtWjlIRF8/27XDppbBhAzRvDlOneo+AFBHJhfbtS6ZHj3EkJe3nwgsr88EH3alSJf81NlTExTtxrXNnWL7cu/Trs89UwEUkV4uPj2XkyK7MmbOJxx5rTUxM/rxkVUU8vzt8GK65xnvQSOXKMGWKdyMWEZFcZsKEFWzcuJt//KMZAJ0716Rz55o+p/KXinh+lpYGN94IX3zhnaj21VdQKe/dDEFEItuBA4e5++4pDBs2j+hoo1276tStG8ZnKkQQFfH8yjm49154/32Ij4fJk6FWLb9TiYgcZdmyrfToMY5ly5KIjY1myJBLqFOnjN+xcg0V8fzq+efhxRe9Z15PmABNm/qdSEQknXOO4cPnceedUzh4MIVzzy3F2LFX07Bheb+j5Sr580yA/G7kSLj/fu82qO+8411WJiKSiwwePJ0BAz7n4MEU+vZtSGLiLSrgGVARz28mTYKbb/bev/wy9Ozpbx4RkQz07duQqlWLM3p0N/77364UKaJHE2dERTw/mTEDevTwTmh75BEYNMjvRCIiAKSlOUaPXkxamgOgcuXirFo1iF69zvM5We6mIp5fLF7s3YHt4EG45RZ48km/E4mIALB58x46dHiPPn0+ZsiQmenjCxSI9jFVZNCJbfnBr79Cx46waxd06wb/+Y8eCyoiucLkyau44YZP+PPP/ZQtG0/9+uX8jhRRVMTzuq1bvRPXtmzxHmwyejRE69utiPjr0KEUHnzwG156aRYA7dufxXvvXUX58kV8ThZZVMTzst274bLLYPVqaNQIJk6EuDi/U4lIPvfHH3vp1OkD5s/fQkxMFIMHX8y9915IVJR6CE+VinhedegQXHUVzJ8PZ5/t3ZWtWDG/U4mIUKpUYeLiYqhWrQRjxnTnggt0p8jTpSIeTps3Q7lyOd99nZoKffrAt99C+fLe7VTL6TiTiPhn795kDh1KoVSpwsTERPHRR9cQH1+A4sXVO5gVOjs9XCZOhIoVoWpV78Yqy5blzHadg4EDYdw4r+X95Zdw1lk5s20RkQzMn7+Fxo3f5PrrP06/hOzMM4uqgGcDFfFwWbPG+3fTJnjuOahXDxo3hqFD4Y8/wrfdJ56AYcOgYEHvxi4NGoRvWyIimXDOMXToLC644C1WrdrOxo272bZtv9+x8hQV8XDr1Mm7Lrt4cViwAO66y2uhX345jB0LBw5k37b+8x+viEdFeetu3Tr71i0icgqSkvbRufMY7rprCocPp3H77U2YM+dmypSJ9ztanqIiHm7nngtvvgm//w4ffeTdcMXMe2pYz57eMeubboLvv/fupHa6/vc/rxsdvO1deWW2xBcROVXffvsrDRoMY/LkVZQsGceECdfy2mudiIvTaVjZTUU8p8TFwdVXe13cmzfDK69AkybeZWBvv+1dw33WWd7tUH/55dTWPXWqdyKbc/DMM96XAhERn3z99Rq2bNlLy5ZVWLhwAFddVdvvSHmWirgfypTx7ls+Zw6sWAEPPQSVK8Nvv8HTT3vP9W7WDF5/Hf78M/N1JSZ6l5IdPgx33AEPPJAzn0FEJEhq6l89iU8+eTFvvHE506bdQJUqxX1MlfepiPutVi2vcK9bB9OmQb9+ULSoV+AHDoQKFbyu8fHjvWu/g61c6d3MZe9e6NXLez64bqcqIjls3Ljl1K8/jD//9E5aK1AgmgEDEoiJUYkJN+3h3CIqyutSHznSO37+wQdegU5L8y5Xu/pqr6APGAAzZ3pnvXfo4LXUO3aE//7XW4eISA45cOAwAwZ8xjXXfMTy5UmMGDHP70j5js4yyI0KF/ZOeuvZ0yvoY8bAu+/CwoXeSWtvvgmxsZCc7HW7jxvnDYuI5JClS7dy3XXjWLYsidjYaIYMuYSBA5v6HSvfUdMttytf3rssbcEC73Gi997rtciTk72u+M8/h3hdsiEiOcM5x5tvJtKkyQiWLUvi3HNLMXv2TQwa1AzT4bwcpyIeSc47z7txzIYNMGsWzJ4NpUr5nUpE8pEFC35nwIDPOXgwhRtvbMi8ebfQsGF5v2PlW+pOj0TR0V43uohIDmvcuAKPP96amjVL0bPneX7HyfdUxEVE5IRSU9N49tkfaNmyCq1bVwPgX/9q42sm+YuKuIiIZGjz5j306TOBadPWUblyMVauHKS7ruUyYT0mbmYdzewXM1ttZsfdhcTMqpjZNDNbYGaLzaxTOPOIiEhoPv98JQ0aDGPatHWULRvPiBFdVMBzobD9RMwsGngduATYCMw1s0nOueVBsz0C/M8594aZ1QEmA9XClUlERDJ36FAKDzwwlaFDZwNwySVn8e67V1G+fBGfk0lGwvm1qimw2jm3FsDMxgJdgeAi7oBigffFgc1hzCMiIidx5ZUf8uWXq4mJieLpp9vyz3+2ICpKl47lVuEs4hWBDUHDG4FjT6l+HPjKzAYB8UD7MOYREZGTGDSoKStXbuODD7rRrFklv+PISfh9nXhPYJRzrhLQCXjPzI7LZGa3mFmimSUmJSXleEgRkbxqz55DTJr015MTO3WqwYoVt6uAR4hwFvFNQOWg4UqBccH6A/8DcM79BMQBpY9dkXNuuHMuwTmXUKZMmTDFFRHJX+bN20zjxsPp1u1Dfvxxffr42NhoH1PJqQhnEZ8L1DCz6mYWC1wHTDpmnvVAOwAzq41XxNXUFhEJI+ccL730E82bv83q1dupW7csZ5xRyO9YchrCdkzcOZdiZgOBKUA0MNI5t8zMngQSnXOTgHuAEWZ2F95Jbn2dcy5cmURE8rukpH307TuRyZNXAXD77U0YMqSDLh+LUGH9qTnnJuNdNhY87rGg98uBC8OZQUREPHPmbOLKK8eyZcteSpaMY+TIrlx5ZS2/Y0kW6KuXiEg+ceaZRTl0KJVWraowenQ3Klcu7nckySIVcRGRPGzTpt2UL1+E6OgoKlUqxg8/9KNGjVLExPh9cZJkB/0Uw+X7771/333X3xwikm+NG7ecunX/w3PP/Zg+rnbtMirgeYha4uEyKXAi/rZt/uYQkXxn//7D3HXXlwwfPh+AefO24JzDTHdey2tUxEVE8pClS7dy3XXjWLYsiYIFo3nhhQ78/e9NVMDzKBVxEZE8wDnH8OHzuPPOKRw8mMK555biww+vpkGD8n5HkzBSERcRyQPS0hyjRy/h4MEUbryxIa+8chnx8bF+x5IwUxEXEYlgaWmOqCgjOjqK0aO7MXPmBnr0qOd3LMkhOkVRRCQCpaam8fTT0+nSZQxpad6NLitXLq4Cns+oJS4iEmE2b95Dnz4TmDZtHQDTp/9GmzbVfM0k/lARFxGJIJ9/vpK+fSfy55/7KVs2nvfeu0oFPB9TERcRiQCHDqXwwANTGTp0NgAdOpzNu+9eSblyRXxOJn7SMXERkQgwfPg8hg6dTUxMFM89154vvuitAi5qiYuIRIIBAxKYNWsTd9zRjKZNK/odR3IJtcRFRHKhPXsO8Y9/fMHWrfsAKFAgmtGju6mAy1HUEhcRyWXmzdvMddeNZ/Xq7WzevIdx4671O5LkUmqJi4jkEmlpjhdf/Inmzd9m9ert1K9fjsGD2/odS3IxtcRFRHKBrVv30bfvJ3zxxWoABg5swvPPdyAuTn+m5cT02yEi4rPduw/RqNGbbN68hzPOKMTIkVfQtWstv2NJBMjfRTz40Xz164e2TJs2MHTo0cuKiGRBsWIFuf76+vz000ZGj+5GpUrF/I4kESJ/F/FgixeHPt9558FNN4U3j4jkaevW7WTr1n3pZ5s/9dTF6Q8yEQmVivgRCxeefJ4ZM2DQILjrLmjXDqpXP/G8L7wA99zjzSsiEuSjj5Zx882fEh8fy6JFAyhdujAFCkT7HUsikIr4EQ0anHye+vXh++9h3Djo1w++/Rai9K1ZREKzf/9h7rzzS0aMmA9AmzbViIrSoTk5fapAp8IM3ngDypXzivnLL/udSEQixJIlf9CkyQhGjJhPwYLRvPbaZXz8cQ/OOKOQ39EkgqmIn6rSpWHECO/9gw/CihX+5hGRXO/ddxfRtOlbLF+eRK1apZk9+yZuv70pphNkJYtUxE9Hly5ed/qhQ/C3v8Hhw34nEpFcrGzZeA4eTKF//0YkJt5Mgwbl/Y4keYSK+OkaOhSqVIHERHjmGb/TiEgus3nznvT3HTuew4IFt/LWW1cQHx/rYyrJa1TET1exYjBqlPd+8GCYN8/XOCKSO6SmpjF48HSqV3+ZGTN+Sx/fsKFa35L9VMSz4uKL4Y47ICXF61Y/eNDvRCLio02bdtO+/Xs8+ug0kpNTmT17k9+RJI9TEc+q//s/OPdcWL4cHnnE7zQi4pPPPltJgwbD+O67dZQrF89XX/Xhn/9s4XcsyeNUxLOqUCF4912IjoYXX4Tp0/1OJCI56NChFO6880u6dBnDtm0H6NDhbBYtGsAll5ztdzTJB1TEs0PTpt7lZs5B376wZ89JFxGRvGH79gOMHr2EmJgonnuuPV980Zty5Yr4HUvyCd2xLbs8+ih8/jksWODdbrWWnkAkklc55wAwMypUKMqYMd0pVqxg+n3QRXKKWuLZJTbW61aPjfVuBvPFF34nEpEw2LPnENdf/zHPPDMjfVz79mepgIsvVMSzU7163uVmAFOn+ptFRLJdYuJmGjV6k9Gjl/DcczPZvv2A35Ekn1MRz2533w0tW/qdQkSyUVqa44UXZtKixdusWbODBg3KMXv2TbrvufhORTy7RUd7N4GJj/c7iYhkg61b93H55R/wz39+zeHDaQwa1JRZs26iVq3SfkcTUREPi7PPhtdeg5gYaNjQ7zQikgWDBn3Bl1+u5owzCvHJJz145ZXLiIvTOcGSO+g3MVz69oUePbzryEUkYr3wQgeSk1N59dXLqFSpmN9xRI6ilng4qYCLRJxff93BPfdMIS3Nu4ysUqVifPxxDxVwyZXUEhcRCfjf/5Zx882fsnv3IapUKc4dd1zgdySRTIVcxM2ssHNufzjDiIj4Yf/+w9x555eMGDEfgCuvrMX11zfwOZXIyZ20O93MWpjZcuDnwHADM/tP2JOJiOSAJUv+ICFhOCNGzKdgwWhef70TEyZcq8vHJCKE0hJ/CbgUmATgnFtkZheFNZWISA6YM2cTF130Xw4dSqV27dKMHXs19euX8zuWSMhC6k53zm0ws+BRqeGJIyKScxo3rkCTJhWpVasUQ4d2JD4+1u9IIqcklCK+wcxaAM7MCgB3ACvCG0tEJDx+/HE955xzBuXKFSEmJoqvvupDoUIF/I4lclpCucRsAHA7UBHYBDQE/h7GTCIi2S41NY2nnvqeiy4axQ03fJJ+CZkKuESyUFri5zrnegePMLMLgR/DE0lEJHtt2rSbPn0+5rvv1gHQsGF50tIcUVGW+YIiuVwoRfxVoHEI40REcp1PP/2Ffv0msm3bAcqVi+e9967ikkvO9juWSLY4YRE3s+ZAC6CMmd0dNKkYEB3uYCIiWeGc4557vuKll2YBcOmlZ/POO1dSrlwRn5OJZJ/MWuKxQJHAPEWDxu8Grg5nKBGRrDIzChWKISYmimefbcdddzVX97nkOeacy3wGs6rOud9Oa+VmHYGX8Vrubznnns1gnmuBxwEHLHLO9cpsnQkJCS4xMfF04mQU8K/3J9kPIpL7Oef44499lC/vtbZTUtJYvjxJ135LRDOzec65hIymhXJMfL+ZPQ/UBeKOjHTOtT3JRqOB14FLgI3AXDOb5JxbHjRPDeBB4ELn3A4zKxtCHhGR4+zefYjbbvucadN+ZdGiAZQpE09MTJQKuORpoVxiNhrvlqvVgSeAdcDcEJZrCqx2zq11ziUDY4Gux8xzM/C6c24HgHNua4i5RUTSzZ27icaN3+SDD5awa9chFi783e9IIjkilCJeyjn3NnDYOfe9c+5GINNWeEBFYEPQ8MbAuGA1gZpm9qOZzQp0vx/HzG4xs0QzS0xKSgph0yKSH6SlOYYMmUmLFiNZs2YHDRuWZ/78W3T2ueQboXSnHw78u8XMLgc2A2dk4/ZrAG2ASsB0MzvPObczeCbn3HBgOHjHxLNp2yISwf74Yy833PAJU6asAeAf/2jKv/99CXFxesKy5B+h/LYPNrPiwD1414cXA+4MYblNQOWg4UqBccE2ArOdc4eBX81sJV5RD6W7XkTysSVLtjJlyhpKlSrEf//blS5dzvU7kkiOO2kRd859Fni7C7gY0u/YdjJzgRpmVh2veF8HHHvm+SdAT+C/ZlYar3t9bUjJRSTfcc5x5GFM7dufxVtvdeHSS8+hUqViPicT8ccJj4mbWbSZ9TSzf5pZvcC4zmY2E3jtZCt2zqUAA4EpeA9M+Z9zbpmZPWlmVwRmmwJsCzyvfBpwr3NuWxY/k4jkQb/+uoOWLf+bfutUgP79G6uAS752wuvEzWwUXnf4HKAZ3rHwBOAB59wnOZTvOLpOXCT/+fDDpdxyy2fs3n2I5s0r8eOPN6a3yEXyutO9TjwBqO+cSzOzOOB34Gy1lEUkp+zbl8ydd37JW28tAODKK2vx9ttXqICLBGRWxJOdc2kAzrmDZrZWBVxEcsrixX/Qo8c4fv75TwoWjObFFy/lttsSVMBFgmRWxGuZ2eLAewPODgwb4Jxz9cOeTkTypeTkVDp3/oANG3ZTu3ZpPvzwas47T3deEzlWZkW8do6lEBEJEhsbzZtvdubjj39m6NCOFC5cwO9IIrnSCYv46T70RETkdMyY8RuLFv3BwIFNAbjsshpcdlkNn1OJ5G66tZGI+Co1NY2nn57BE098D0CzZhVp0uTYOzSLSEZUxEXENxs37qZPnwl8//1vmMEDD7SkYcPyfscSiRghFXEzKwRUcc79EuY8IpJPTJr0C/36TWT79gOUL1+E9967ivbtz/I7lkhEOelTzMysC7AQ+DIw3NDMJoU5l4jkYW+8MZeuXceyffsBLrvsHBYtGqACLnIaQnkU6eN4zwbfCeCcW4j3bHERkdNyxRXnUqFCEYYMuYTPPutF2bLxfkcSiUghPYrUObfrmBss6B6lIhIy5xyff76Kyy47h+joKCpWLMbq1f/QpWMiWRRKS3yZmfUCos2shpm9CswMcy4RySN27z5E794T6NJlDM8++0P6eBVwkawLpYgPAuoCh4AP8B5JemcYM4lIHjF37iYaNXqTMWOWEh9fgMqVi/sdSSRPCaU7vZZz7mHg4XCHEZG8IS3N8cILM3nooW9JSUmjUaPyjBnTnXPPLe13NJE8JZQi/oKZlQfGAR8655aGOZOIRLBduw7So8c4pkxZA8AddzTj3/9uT8GCui2FSHY76f8q59zFgSJ+LfCmmRXDK+aDw55ORCJOkSKxHDiQQqlShRg16ko6d67pdySRPMucC/1EczM7D7gP6OGciw1bqkwkJCS4xMTE7FlZ8Bn3p7AfRORohw+nsndvMiVLFgJg06bdAFSsWMzPWCJ5gpnNc84lZDQtlJu91Dazx81sCXDkzPRK2ZxRRCLUr7/uoFWr/3LtteNIS/O+DFesWEwFXCQHhHKQaiTwIXCpc25zmPOISAT58MOl3HLLZ+zefYjKlYuxceNuqlTRGegiOSWUY+LNcyKIr46+kY2InMS+fcnccceXvP32AgC6davNW291Se9OF5GcccIibmb/c85dG+hGDz5gbIBzztUPe7pwq1sXli2D117zO4lIxFi06Heuu248P//8JwULRjN0aEduvfV8TF+GRXJcZi3xOwL/ds6JIL5o3Ngr4kWK+J1EJGJMmLCCn3/+kzp1yjB2bHfOO6+c35FE8q0TFnHn3JbA27875+4PnmZm/wbuP34pEcmLnHPpLe1HH21NfHwsAwc21a1TRXwWym1XL8lg3GXZHUREcqcZM36jWbO3+OOPvQDExERx330XqoCL5AInLOJmdlvgePi5ZrY46PUrsDjnIoqIH1JT03jiie9o0+Yd5s7dzJAheu6RSG6T2THxD4AvgP8DHggav8c5tz2sqUTEVxs37qZ37wlMn/4bZvDggy154ok2fscSkWNkVsSdc26dmd1+7AQzO0OFXCRvmjjxZ268cRLbtx+gfPkivP/+VbRrd5bfsUQkAydriXcG5uFdYhZ8/YgD9L9aJI9ZuXIbV131Ic7BZZedw6hRV1K2bLzfsUTkBDI7O71z4N/qORdHRPxUs2YpHn30IooXj+POOy8gKkrXfovkZie9Y5uZXQgsdM7tM7M+QGNgqHNufdjTiUhYOecYNWoh1aqV4OKLve/rTzxxsc+pRCRUoVxi9gaw38waAPcAa4D3wppKRMJu9+5D9O49gRtvnETv3hPYvfuQ35FE5BSFUsRTnPe80q7Aa86514Gi4Y0lIuE0Z84mGjV6kzFjlhIfX4Bnn21PsWIF/Y4lIqcolKeY7TGzB4HrgVZmFgXoLg8iESgtzTFkyEwefvhbUlLSaNSoPGPHXk3NmqX8jiYipyGUlngP4BBwo3Pud7xniT8f1lQiEhZ9+37C/fdPJSUljTvuaMZPP/VXAReJYCct4oHCPRoobmadgYPOuXfDnkxEsl2fPvUpU6Ywn37ak6FDO1KwYCidcSKSW520iJvZtcAc4BrgWmC2mV0d7mAiknWHD6fy9ddr0oc7dDibtWvvoHPnmj6mEpHsEsrX8IeBJs65rQBmVgaYCowLZzARyZq1a3fQs+d4EhM38+23f6N162oAFCkS628wEck2oRTxqCMFPGAboR1LFxGfjB27lFtv/Yzduw9RpUpxYmOj/Y4kImEQShH/0symAGMCwz2AyeGLJCKna9++ZP7xjy8YOXIhAN261eatt7pQsmQhf4OJSFictIg75+41s25Ay8Co4c65j8MbS0RO1c8//8lVV33Izz//SVxcDEOHXsott5yPmW6dKpJXnbCIm1kNYAhwNrAE+KdzblNOBRORU1O8eEG2bdtPnTpl+PDDq6lXr6zfkUQkzDJriY8E3gWmA12AV4FuORFKREKzY8cBihUrSHR0FBUqFOXrr6+nRo1SFC6s+zGJ5AeZnaBW1Dk3wjn3i3NuCFAthzKJSAimT/+N+vWH8fTTM9LHNWhQXgVcJB/JrIjHmVkjM2tsZo2BQscMi4gPUlLSePzx77j44nfYuHE3X3+9lpSUNL9jiYgPMutO3wK8GDT8e9CwA9qGK5SIZGzDhl307j2BGTPWYwYPPdSSxx9vQ0yMrvoUyY9OWMSdc3n/ocIlSkCFClBIl99I7jdx4s/ceOMktm8/QIUKRXjvvato1+4sv2OJiI/y942TX3nFe4nkcs45Xn55Ntu3H6BTpxqMGtWVMmXi/Y4lIj7L30VcJJdzzmFmmBnvvXcVEyas4PbbmxIVpWu/RUS3TxXJlZxzjBy5gK5dx5Ka6p20VrFiMQYNaqYCLiLpQnmKmZlZHzN7LDBcxcyahj+aSP60a9dBevWaQP/+k/j005V8+ulKvyOJSC4VSkv8P0BzoGdgeA/weigrN7OOZvaLma02swcyma+7mTkzSwhlvSJ51Zw5m2jU6E3Gjl1KfHwB3nnnSq68spbfsUQklwrlmHgz51xjM1sA4JzbYWYnfZahmUXjFftLgI3AXDOb5Jxbfsx8RYE7gNmnnF4kj0hLcwwZMpOHH/6WlJQ0GjUqz9ixV1OzZim/o4lILhZKS/xwoCA7SH+eeCh3lmgKrHbOrXXOJQNjga4ZzPcU8G/gYGiRRfKe995bxP33TyUlJY0772zGTz/1VwEXkZMKpYi/AnwMlDWzp4EfgGdCWK4isCFoeGNgXLrAnd8qO+c+z2xFZnaLmSWaWWJSUlIImxaJLL1716dbt9p89llPXnqpIwUL6sIRETm5UB5FOtrM5gHtAAOudM6tyOqGzSwK7w5wfUPIMBwYDpCQkOCyum0RvyUnp/LMMzMYMCCB8uWLEBMTxfjx1/odS0QizEmLuJlVAfYDnwaPc86tP8mim4DKQcOVAuOOKArUA74LPO+4PDDJzK5wziWGFl8k8qxdu4PrrhvH3LmbmTNnE5Mn9/Y7kohEqFD67D7HOx5uQBxQHfgFqHuS5eYCNcysOl7xvg7odWSic24XUPrIsJl9h/fMchVwybPGjFnCrbd+xp49yVSpUpyHH27ldyQRiWChdKefFzwcOI799xCWSzGzgcAUIBoY6ZxbZmZPAonOuUmnmVkk4uzbl8ygQV/w3/8uBKB799qMGNGFkiV1334ROX2nfPaMc26+mTULcd7JwORjxj12gnnbnGoWkUhw8GAKTZu+xfLlScTFxTB06KXccsv5BA4jiYictlCOid8dNBgFNAY2hy2RSB4TFxdDt261MIOxY6+mXr2yfkcSkTzCnMv8ZG8z+1fQYAqwDhjvnPPluu6EhASXmKjD5pK7bdu2n3XrdnL++WcCkJKSRnJyKoULF/A5mYhEGjOb55zL8I6mmbbEAzd5Keqc+2dYkonkQd9/v47evSeQmupYtGgAZcvGExMTRUyMnjckItnrhH9VzCzGOZcKXJiDeUQiVkpKGo8//h1t277Lpk17OOuskiQnp/odS0TysMxa4nPwjn8vNLNJwEfAviMTnXMTwpxNJGJs2LCL3r0nMGPGeszg4Ydb8fjjbdT6FpGwCuXs9DhgG9CWv64Xd4CKuAgwefIq+vSZwI4dB6lQoQjvv9+Ntm2r+x1LRPKBzIp42cCZ6Uv5q3gfoVufigTExkazc+dBOnWqwahRXSlTJt7vSCKST2RWxKOBIhxdvI9QEZd8bfv2A5xxhnejlvbtz2L69H5ceGFlXfstIjkqsyK+xTn3ZI4lEYkAzjlGjlzAnXdOYdKk67j4Yq/bvGXLKj4nE5H8KLOzbtSkEAmya9dBevYcz003fcrevclMnrzK70giks9l1hJvl2MpRHK52bM30rPneH79dSdFisTyxhuX06dPfb9jiUg+d8Ii7pzbnpNBRHKjtDTH88//yCOPTCMlJY3GjSswdmx3atQo5Xc0EZFMu9NF8r3t2w/w4ouzSElJ4667LmDmzBtVwEUk1zjlp5iJ5CelSxdm9OhuJCen0qlTDb/jiIgcRUVcJEhycioPP/wNRYsW5LHHWgPeJWQiIrmRirhIwJo12+nZczxz524mNjaa/v0bUbFiMb9jiYickI6JiwAffLCERo3eZO7czVStWpxp025QAReRXE8tccnX9u5NZtCgLxg1aiEAV19dhxEjulCiRJy/wUREQqAiLvnaXXd9yahRC4mLi+Hllzty882NdetUEYkYKuKSrz3xxMWsWbODV165jHr1yvodR0TklOiYuOQr27bt51//mkZqahoAZ55ZlG+/vUEFXEQiklrikm98//06eveewKZNeyhUqAAPPNDS70giIlmilrjkeSkpafzrX9No2/ZdNm3aQ4sWlenZs57fsUREskwtccnTNmzYRa9eE/jhh/WYwcMPt+Lxx9sQE6PvryIS+VTEJc9asSKJCy8cyY4dB6lQoQjvv9+Ntm2r+x1LRCTbqIhLnlWzZikaNChP4cIFGDWqK2XKxPsdSUQkW6mIS56yYkUSJUrEUaFCUaKjo5g48TqKFo3Vtd8ikifpwKDkCc453nprPuefP5zrr/+YtDQHQLFiBVXARSTPUktcIt6uXQe59dbP+PDDZQBUrFiMQ4dSKFSogM/JRETCS0VcItqsWRvp2XM869btpEiRWN5443L69KnvdywRkRyhIi4R6/nnf+Shh74lJSWNxo0rMHZsd2rUKOV3LBGRHKNj4hKx9u07TEpKGnfffQEzZ96oAi4i+Y5a4hJRdu48mP6Y0EceuYh27arTqlVVn1OJiPhDLXGJCMnJqfzzn19Ru/br/PHHXgBiYqJUwEUkX1MRl1xv9ertXHjhSF544SeSkvbx/fe/+R1JRCRXUHe65GqjRy9mwIDP2bs3mapVizNmTHeaN6/sdywRkVxBRVxypb17kxk4cDLvvLMIgGuuqcPw4V3Sj4eLiIiKuORS8+dv4d13F1GoUAwvv9yRm25qrDuviYgcQ0VccqWLLqrK6693onXratSpU8bvOCIiuZJObJNc4c8/99O161imTl2bPu6225qogIuIZEItcfHdd9+to3fvCWzevIfVq7ezZMltREWp61xE5GTUEhffpKSk8dhj02jb9h02b97DhRdWZvLkXirgIiIhUktcfLF+/S569RrPjz9uwAweffQiHnusNTEx+l4pIhIqFXHJcWlpjo4d32fFij8588yijB7djTZtqvkdS0Qk4qjZIzkuKsp4+eWOXHHFuSxaNEAFXETkNKmIS45YvjyJYcMS04cvueRsJk68jtKlC/uYSkQksqk7XcLKOcdbb83njju+5ODBFOrWLaOHloiIZBMVcQmbnTsPcsstn/LRR8sBuOGGBjRqVMHnVCIieYeKuITFTz9toFevCaxbt5MiRWIZNuxyeveu73csEZE8RUVcst3//reMXr3Gk5rqSEg4kzFjunPOOWf4HUtEJM8J64ltZtbRzH4xs9Vm9kAG0+82s+VmttjMvjEzHSzNA1q1qkLp0oW5557m/PjjjSrgIiJhEraWuJlFA68DlwAbgblmNsk5tzxotgVAgnNuv5ndBjwH9AhXJgmfH35YT/PmlYiOjqJChaKsWHE7JUsW8juWiEieFs6WeFNgtXNurXMuGRgLdA2ewTk3zTm3PzA4C6gUxjwSBsnJqdxzzxRatfovgwdPTx+vAi4iEn7hPCZeEdgQNLwRaJbJ/P2BL8KYR7LZ6tXbue66ccybt4XoaKNQoQJ+RxIRyVdyxYltZtYHSABan2D6LcAtAFWqVMnBZHIi77+/mNtu+5y9e5OpWrU4Y8Z0p3nzyn7HEhHJV8LZnb4JCP6rXikw7ihm1h54GLjCOXcooxU554Y75xKccwllyuj50n46cOAwfft+wvXXf8zevclce21dFi4coAIuIuKDcLbE5wI1zKw6XvG+DugVPIOZNQLeBDo657aGMYtkk9jYaNav30WhQjG88spl9O/fCDM9OlRExA9hK+LOuRQzGwhMAaKBkc65ZWb2JJDonJsEPA8UAT4KFIL1zrkrwpVJTo9zjj17kilWrCDR0VG8/343du48SJ066hUREfGTOef8znBKEhISXGJi4slnlGzx55/76ddvInv3JjN16vVER+uZOSIiOcnM5jnnEjKalitObJPcadq0X+nT52M2b95DiRJxrFy5jdq11foWEckt1KyS46SkpPHoo9/Srt27bN68h5Ytq7Bo0QAVcBGRXEYtcTnK+vW76NVrPD/+uAEzeOyxi3j00dbExOj7nohIbqMiLkcZPXoxP/64gTPPLMro0d1o06aa35FEROQEVMTlKPfddyH79x/mjjsuoHTpwn7HERGRTKiPNJ9bvjyJdu3eZcuWPQBER0fx1FNtVcBFRCKAing+5Zxj+PB5JCQM59tvf+Wxx6b5HUlERE6RutPzoZ07D3LLLZ/y0UfeU2H79m3ISy919DmViIicKhXxfOannzbQs+d4fvttF0WLxjJsWGd69TrP71giInIaVMTzkU2bdtOmzTskJ6eSkHAmY8d25+yzz/A7loiInCYV8XykYsViPPhgS/btS+bpp9sRGxvtdyQREckCFfE87osvVhEbG027dmcB8K9/tdZTx0RE8gidnZ5HJSencs89U+jU6QN69ZpAUtI+ABVwEZE8RC3xPGjVqm307DmeefO2EBMTxd13X0CpUrruW0Qkr1ERz2Pef38xt932OXv3JlOtWgnGjOnOBRdU8juWiIiEgYp4HnLvvV8xZMhPAFx7bV3efLMzJUrE+ZxKRETCRcfE85DLLqtBkSKxjBjRhbFju6uAi4jkcWqJRzDnHD/9tJEWLSoD0LZtddatu0PHv0VE8gm1xCNUUtI+unQZQ8uWI/nmm7Xp41XARUTyD7XEI9C0ab/Su/cEtmzZS8mScRw8mOJ3JBER8YGKeARJSUnj8ce/45lnZuActGxZhdGju1GlSnG/o4mIiA9UxCPExo276dFjHDNnbiAqynj00VY8+mhrYmJ0REREJL9SEY8QBQpEsWbNdipWLMro0d1o3bqa35FERMRnKuK52IEDhylQIJqYmCjKlSvCp5/2pHr1kpQurZPXREREZ6fnWsuWbaVp07d48snv08c1aVJRBVxERNKpiOcyzjmGD59HkyYjWLp0K+PGLdfZ5yIikiEV8Vxk586DXHvtOG699TMOHEihb9+GzJlzM3FxOuohIiLHU3XIJWbO3ECvXuP57bddFC0ay7BhnenV6zy/Y4mISC6mIp5LDB48nd9+20VCwpmMHduds88+w+9IIiKSy6mI5xIjR3blP/+ZyyOPXERsbLTfcUREJALomLhPJk9exTXXfERqahoA5csX4cknL1YBFxGRkKmI57BDh1K4++4pXH75B4wbt5z331/sdyQREYlQ6k7PQatWbeO668Yzf/4WYmKiGDz4Yq6/voHfsUREJEKpiOeQ995bxN//Ppm9e5OpVq0EY8Z054ILKvkdS0REIpiKeA6YOPFn/va3TwDo0aMub77ZmeLF4/wNJSIiEU9FPAd07lyTyy+vwVVX1eLGGxthZn5HEhGRPEBFPAycc7z++ly6davNmWcWJTo6ik8/7aniLSIi2Upnp2ezpKR9dO48hkGDvuD66z/GOQegAi4iItlOLfFs9O23v9KnzwS2bNlLyZJxDBrUVMVbRETCRkU8G6SkpPGvf03j//7vB5yDVq2qMHp0NypXLu53NBERycNUxLMoJSWNtm3fYcaM9URFGY89dhGPPHIRMTE6UiEiIuGlIp5FMTFRtGtXnbVrdzB6dDdat67mdyQREckn7MiJV5EiISHBJSYm+pph//7DrFq1jQYNygOQmprGrl2HOOOMQr7mEhGRvMfM5jnnEjKapj7fU7R06VaaNh1Bhw7v8/vvewGIjo5SARcRkRynIh4i5xxvvplIkyYjWLYsiZIl49ix44DfsUREJB/TMfEQ7NhxgJtv/pTx41cAcOONDXnllcuIj4/1OZmIiORnKuInMWvWRnr0GMf69bsoWjSWN9/sTM+e5/kdS0TC7PDhw2zcuJGDBw/6HUXyibi4OCpVqkSBAgVCXkZF/CQOHkxhw4ZdNGlyJmPGdOfss8/wO5KI5ICNGzdStGhRqlWrpps2Sdg559i2bRsbN26kevXqIS+nIp6BffuS07vK27Spxpdf9qFNm2rExkb7nExEcsrBgwdVwCXHmBmlSpUiKSnplJbTiW3H+PzzlZx11it8/fWa9HEdOpytAi6SD6mAS046nd83FfGAQ4dSuOuuL+nceQxbt+7j3XcX+x1JREQkU2Et4mbW0cx+MbPVZvZABtMLmtmHgemzzaxaOPOcyMqV22jRYiRDh84mJiaKf/+7Pe+8c6UfUURE0kVHR9OwYUPq1atHly5d2LlzZ/q0ZcuW0bZtW84991xq1KjBU089RfDNu7744gsSEhKoU6cOjRo14p577vHhE2RuwYIF9O/f3+8YJ3To0CF69OjBOeecQ7NmzVi3bl2G87388svUq1ePunXrMnTo0OOmv/DCC5gZf/75JwCfffYZjz32WPaEdM6F5QVEA2uAs4BYYBFQ55h5/g4MC7y/DvjwZOs9//zzXXZ6552FLj7+aQePu+rVh7pZszZk6/pFJDItX77c7wguPj4+/f3f/vY3N3jwYOecc/v373dnnXWWmzJlinPOuX379rmOHTu61157zTnn3JIlS9xZZ53lVqxY4ZxzLiUlxf3nP//J1myHDx/O8jquvvpqt3Dhwhzd5ql4/fXX3a233uqcc27MmDHu2muvPW6eJUuWuLp167p9+/a5w4cPu3bt2rlVq1alT1+/fr3r0KGDq1KliktKSnLOOZeWluYaNmzo9u3bd9z6Mvq9AxLdCWpiOFviTYHVzrm1zrlkYCzQ9Zh5ugLvBN6PA9pZDh6E2r37EPffP5V9+w5z3XX1WLDgVpo1q5RTmxeRSGEWntcpaN68OZs2bQLggw8+4MILL6RDhw4AFC5cmNdee41nn30WgOeee46HH36YWrVqAV6L/rbbbjtunXv37qVfv36cd9551K9fn/HjxwNQpEiR9HnGjRtH3759Aejbty8DBgygWbNm3HfffVSrVu2o3oEaNWrwxx9/kJSURPfu3WnSpAlNmjThxx9/PG7be/bsYfHixTRo0ACAOXPm0Lx5cxo1akSLFi345ZdfABg1ahRXXHEFbdu2pV27duzbt48bb7yRpk2b0qhRIyZOnAjAunXraNWqFY0bN6Zx48bMnDnzlPZvRiZOnMgNN9wAwNVXX80333xzVG8HwIoVK2jWrBmFCxcmJiaG1q1bM2HChPTpd911F88999xRx7vNjDZt2vDZZ59lOWM4z06vCGwIGt4INDvRPM65FDPbBZQC/gyeycxuAW4BqFKlSrYFLFasIKNHd2Pdup3069dQJ7GISK6UmprKN998k971vGzZMs4///yj5jn77LPZu3cvu3fvZunSpSF1nz/11FMUL16cJUuWALBjx46TLrNx40ZmzpxJdHQ0qampfPzxx/Tr14/Zs2dTtWpVypUrR69evbjrrrto2bIl69ev59JLL2XFihVHrScxMZF69eqlD9eqVYsZM2YQExPD1KlTeeihh9K/VMyfP5/Fixdzxhln8NBDD9G2bVtGjhzJzp07adq0Ke3bt6ds2bJ8/fXXxMXFsWrVKnr27ElGz9lo1aoVe/bsOW78kCFDaN++/VHjNm3aROXKlQGIiYmhePHibNu2jdKlS6fPU69ePR5++GG2bdtGoUKFmDx5MgkJ3m3OJ06cSMWKFdO/qARLSEhgxowZXHvttSfd55mJiEvMnHPDgeHgPQAlO9fdtm3o1+OJSD7l04OiDhw4QMOGDdm0aRO1a9fmkksuydb1T506lbFjx6YPlyxZ8qTLXHPNNURHe1fr9OjRgyeffJJ+/foxduxYevTokb7e5cuXpy+ze/du9u7de1QLf8uWLZQpUyZ9eNeuXdxwww2sWrUKM+Pw4cPp0y655BLOOMO7R8dXX33FpEmTGDJkCOBdCrh+/XrOPPNMBg4cyMKFC4mOjmblypUZ5p8xY8ZJP+OpqF27Nvfffz8dOnQgPj6ehg0bEh0dzf79+3nmmWf46quvMlyubNmybN68OcvbD2d3+iagctBwpcC4DOcxsxigOLAtjJlERCJGoUKFWLhwIb/99hvOOV5//XUA6tSpw7x5846ad+3atRQpUoRixYpRt27d46afiuBeyWPvWBcfH5/+vnnz5qxevZqkpCQ++eQTunXrBkBaWhqzZs1i4cKFLFy4kE2bNh1VwI98tuB1P/roo1x88cUsXbqUTz/99Khpwdt0zjF+/Pj0da9fv57atWvz0ksvUa5cORYtWkRiYiLJyckZfrZWrVrRsGHD415Tp049bt6KFSuyYYPXoZySksKuXbsoVarUcfP179+fefPmMX36dEqWLEnNmjVZs2YNv/76Kw0aNKBatWps3LiRxo0b8/vvv6fv10KFsv7grHAW8blADTOrbmaxeCeuTTpmnknADYH3VwPfumMPOIiI5HOFCxfmlVde4YUXXiAlJYXevXvzww8/pBeeAwcO8I9//IP77rsPgHvvvZdnnnkmvTWalpbGsGHDjlvvJZdckv7FAP7qTi9XrhwrVqwgLS2Njz/++IS5zIyrrrqKu+++m9q1a6cXuA4dOvDqq6+mz7dw4cLjlq1duzarV69OH961axcVK1YEvOPgJ3LppZfy6quvph+bXrBgQfryFSpUICoqivfee4/U1NQMl58xY0b6F4Dg17Fd6QBXXHEF77zjnbY1btw42rZtm+Fh161btwKwfv16JkyYQK9evTjvvPPYunUr69atY926dVSqVIn58+dTvrz3COuVK1cedTjhdIWtiDvnUoCBwBRgBfA/59wyM3vSzK4IzPY2UMrMVgN3A8ddhiYiItCoUSPq16/PmDFjKFSoEBMnTmTw4MGce+65nHfeeTRp0oSBAwcCUL9+fYYOHUrPnj2pXbs29erVY+3atcet85FHHmHHjh3Uq1ePBg0aMG3aNACeffZZOnfuTIsWLahQoUKmuXr06MH777+f3pUO8Morr5CYmEj9+vWpU6dOhl8gatWqxa5du9KPT9933308+OCDNGrUiJSUlBNu79FHH+Xw4cPUr1+funXr8uijjwLw97//nXfeeYcGDRrw888/H9V6P139+/dn27ZtnHPOObz44ovpJw5u3ryZTp06pc/XvXt36tSpQ5cuXXj99dcpUaLESdc9bdo0Lr/88ixntEhr+CYkJLiMTlYQEclOK1asoHbt2n7HyNNeeuklihYtyk033eR3lBz1xx9/0KtXL7755pvjpmX0e2dm85xzCRmtS3dsExERX9x2220ULFjQ7xg5bv369bzwwgvZsq6IODtdRETynri4OK6//nq/Y+S4Jk2aZNu61BIXETmBSDvcKJHtdH7fVMRFRDIQFxfHtm3bVMglR7jA88Tj4uJOaTl1p4uIZKBSpUps3LjxlJ/vLHK64uLiqFTp1G79rSIuIpKBAgUKUL267ugouZu600VERCKUiriIiEiEUhEXERGJUBF3xzYzSwJ+y8ZVluaYR5/KadF+zDrtw6zTPsw67cOsy+59WNU5VyajCRFXxLObmSWe6HZ2Ejrtx6zTPsw67cOs0z7Mupzch+pOFxERiVAq4iIiIhFKRRyG+x0gj9B+zDrtw6zTPsw67cOsy7F9mO+PiYuIiEQqtcRFREQiVL4p4mbW0cx+MbPVZvZABtMLmtmHgemzzayaDzFztRD24d1mttzMFpvZN2ZW1Y+cudnJ9mHQfN3NzJmZzhLOQCj70cyuDfw+LjOzD3I6Y24Xwv/nKmY2zcwWBP5Pd/IjZ25lZiPNbKuZLT3BdDOzVwL7d7GZNQ5LEOdcnn8B0cAa4CwgFlgE1Dlmnr8DwwLvrwM+9Dt3bnqFuA8vBgoH3t+mfXjq+zAwX1FgOjALSPA7d257hfi7WANYAJQMDJf1O3dueoW4D4cDtwXe1wHW+Z07N72Ai4DGwNITTO8EfAEYcAEwOxw58ktLvCmw2jm31jmXDIwFuh4zT1fgncD7cUA7M7MczJjbnXQfOuemOef2BwZnAaf2OJ68L5TfQ4CngH8DB3MyXAQJZT/eDLzunNsB4JzbmsMZc7tQ9qEDigXeFwc252C+XM85Nx3YnsksXYF3nWcWUMLMKmR3jvxSxCsCG4KGNwbGZTiPcy4F2AWUypF0kSGUfRisP963UPnLSfdhoMutsnPu85wMFmFC+V2sCdQ0sx/NbJaZdcyxdJEhlH34ONDHzDYCk4FBORMtzzjVv5mnRY8ilWxnZn2ABKC131kiiZlFAS8CfX2OkhfE4HWpt8HrEZpuZuc553b6GSrC9ARGOedeMLPmwHtmVs85l+Z3MPlLfmmJbwIqBw1XCozLcB4zi8HrPtqWI+kiQyj7EDNrDzwMXOGcO5RD2SLFyfZhUaAe8J2ZrcM7jjZJJ7cdJ5TfxY3AJOfcYefcr8BKvKIunlD2YX/gfwDOuZ+AOLx7gktoQvqbmVX5pYjPBWqYWXUzi8U7cW3SMfNMAm4IvL8a+NYFzk4QIIR9aGaNgDfxCriOQR4v033onNvlnCvtnKvmnKuGd17BFc65RH/i5lqh/H/+BK8VjpmVxuteX5uDGXO7UPbheqAdgJnVxiviSTmaMrJNAv4WOEv9AmCXc25Ldm8kX3SnO+dSzGwgMAXvrMyRzrllZvYkkOicmwS8jdddtBrvZIXr/Euc+4S4D58HigAfBc4JXO+cu8K30LlMiPtQTiLE/TgF6GBmy4FU4F7nnHrWAkLch/cAI8zsLryT3PqqYfMXMxuD90WxdOC8gX8BBQCcc8PwziPoBKwG9gP9wpJDPxMREZHIlF+600VERPIcFXEREZEIpSIuIiISoVTERUREIpSKuIiISIRSERfxgZmlmtnCoFe1TObdmw3bG2Vmvwa2NT9wB65TXcdbZlYn8P6hY6bNzGrGwHqO7JelZvapmZU4yfwN9XQtyc90iZmID8xsr3OuSHbPm8k6RgGfOefGmVkHYIhzrn4W1pflTCdbr5m9A6x0zj2dyfx98Z70NjC7s4hEArXERXIBMysSeAb7fDNbYmbHPd3MzCqY2fSglmqrwPgOZvZTYNmPzOxkxXU6cE5g2bsD61pqZncGxsWb2edmtigwvkdg/HdmlmBmzwKFAjlGB6btDfw71swuD8o8ysyuNrNoM3vezOYGnq18awi75ScCD4wws6aBz7jAzGaa2bmBO409CfQIZOkRyD7SzOYE5s3oKXEieUa+uGObSC5UyMwWBt7/ClwDXOWc2x24TegsM5t0zB2yegFTnHNPm1k0UDgw7yNAe+fcPjO7H7gbr7idSBdgiZmdj3cXqWZ4zzyebWbf4z1jerNz7nIAMysevLBz7gEzG+ica5jBuj8ErgU+DxTZdnjPlu+Pd9vJJmZWEPjRzL4K3Nf8OIHP1w7vTooAPwOtAncaaw8845zrbmaPEdQSN7Nn8G6ZfGOgK36OmU11zu3LZH+IRCwVcRF/HAgugmZWAHjGzC4C0vBaoOWA34OWmQuMDMz7iXNuoZm1BurgFUWAWLwWbEaeN7NH8O5/3R+vSH58pMCZ2QSgFfAl8IKZ/RuvC37GKXyuL4CXA4W6IzDdOXcg0IVf38yuDsxXHO+BJMcW8SNfbioCK4Cvg+Z/x8xq4N0CtMAJtt8BuMLM/hkYjgOqBNYlkueoiIvkDr2BMsD5zrnD5j3FLC54Bufc9ECRvxwYZWYvAjuAr51zPUPYxr3OuXFHBsysXUYzOedWmvdc807AYDP7xjmXWcs+eNmDZvYdcCnQAxh7ZHPAIOfclJOs4oBzrqGZFca7r/ftwCvAU8A059xVgZMAvzvB8gZ0d879EkpekUinY+IiuUNxYGuggF8MVD12BjOrCvzhnBsBvAU0xnvS2YVmduQYd7yZ1QxxmzOAK82ssJnFA1cBM8zsTGC/c+59vIfaNM5g2cOBHoGMfIjXTX+kVQ9eQb7tyDJmVjOwzQw55/YD/wDusb8eDXzkMY59g2bdg/cI1yOmAIMs0C1h3pP1RPIsFXGR3GE0kGBmS4C/4R0DPlYbYJGZLcBr5b7snEvCK2pjzGwxXld6rVA26JybD4wC5gCzgbeccwuA8/COJS/EezLT4AwWHw4sPnJi2zG+AloDU51zyYFxbwHLgflmthTvkbWZ9gQGsiwGegLPAf8X+OzBy00D6hw5sQ2vxV4gkG1ZYFgkz9IlZiIiIhFKLXEREZEIpSIuIiISoVTERUREIpSKuIiISIRSERcREYlQKuIiIiIRSkVcREQkQqmIi4iIRKj/B0oJ8dR3qMUNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pt_gla:  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34]\n",
            "pt_cont:  [73, 103, 107, 121, 123, 133, 166, 185, 195, 211, 215, 272, 300, 310, 338, 372, 399, 434, 439, 461, 464, 472, 484, 524, 530, 535, 538, 573, 593, 596, 624, 634, 645, 698, 721]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**人力判定との比較**\n",
        "\n",
        "##使用データ\n",
        "- 緑内障群  \n",
        "各患者よりランダムに1枚ずつ選択（30枚）\n",
        "\n",
        "- コントロール群  \n",
        "ランダムに患者を選択し1枚ずつ選択（30枚）  \n",
        "内斜視:正位:外斜視 = 1:5:4\n",
        "\n",
        "\n",
        "##検討方法\n",
        "- AI群  \n",
        "one subject out stratified 5-fold crossvalidation法  \n",
        "5-foldの判定の多数決でpredを決定  \n",
        "Thresholdの決定にはYouden J staticを使用  \n",
        "\n",
        "- 人力群  \n",
        "緑内障のスペシャリスト 3名\n",
        "一般眼科医  3名  \n",
        "先天性緑内障の特徴について説明（角膜混濁、眼球あるいは角膜の拡大）  \n",
        "緑内障群、コントロール群の両方に斜視患者がいることを説明  \n",
        "画像を見てもらって判定  \n",
        "\n",
        "- 検討項目  \n",
        "感度、特異度、陽性的中率、F_value"
      ],
      "metadata": {
        "id": "hnQ-WPXIzFhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###############################\n",
        "#患者ごとの正解率を計算\n",
        "#※結果の良いseedを探索\n",
        "###############################\n",
        "\n",
        "seed_list = []\n",
        "f1_list = []\n",
        "specificity_list =  []\n",
        "sensitivity_list = []\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    #df_temp = df_temp.sample(n=1) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "\n",
        "for seed in list(range(1100, 1500, 1)):\n",
        "    random.seed(seed) #結果の良いrandom seedを探索する\n",
        "\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "    #gla群\n",
        "    pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "    #cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "    pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "    pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "    ##Calcurate the Youden's J static\n",
        "    #https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "    tpr = np.array(tpr_list)\n",
        "    fpr = np.array(fpr_list)\n",
        "    thresholds = np.array(thred_list)\n",
        "\n",
        "    youdenJ = tpr - fpr\n",
        "\n",
        "    #Find the optimal threshold\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(youdenJ)\n",
        "\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "    ##Youden's indexをもとにした正答率を計算\n",
        "    #################################################\n",
        "    threshold = thresholdOpt #判定基準\n",
        "    #################################################\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    Y = df_pt_analysis[\"label\"].tolist()\n",
        "    Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    #print(tp, fn, fp, tn)\n",
        "    \"\"\"\n",
        "    print(f'Random_seed : {str(seed)}')\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "    print(\"\")\n",
        "    \"\"\"\n",
        "\n",
        "    seed_list.append(seed)\n",
        "    f1_list.append(f1_score(Y, Y_pred))\n",
        "    specificity_list.append(specificity_score(Y, Y_pred))\n",
        "    sensitivity_list.append(recall_score(Y, Y_pred))\n",
        "\n",
        "print(seed_list)\n",
        "print(f1_list)\n",
        "\n",
        "max_value = max(f1_list)\n",
        "idx = f1_list.index(max_value)\n",
        "print(\"seed: \", seed_list[idx])\n",
        "print(\"f1_score: \", f1_list[idx])\n",
        "\n",
        "\n",
        "df_f1 = pd.DataFrame(columns = [])\n",
        "df_f1[\"seed\"] = seed_list\n",
        "df_f1[\"f1_score\"] = f1_list\n",
        "df_f1[\"specificity\"] = specificity_list\n",
        "df_f1[\"sensitivity\"] = sensitivity_list\n",
        "df_f1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "8mcX3i_VRGjM",
        "outputId": "4f6452d4-e1ba-4645-fa03-9defa2e7ae14"
      },
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [339]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m youdenJ \u001b[38;5;241m=\u001b[39m tpr \u001b[38;5;241m-\u001b[39m fpr\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#Find the optimal threshold\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Find the optimal threshold\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43myoudenJ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m thresholdOpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(thresholds[index], ndigits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     58\u001b[0m youdenJOpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(gmean[index], ndigits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
            "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "#患者毎の正答率を表示\n",
        "#ここは先に入力しておく\n",
        "random.seed(1398)\n",
        "#################################################\n",
        "\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    #df_temp = df_temp.sample(n=1, random_state=random_state) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "\n",
        "##Calcurate the Youden's J static\n",
        "#https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "tpr = np.array(tpr_list)\n",
        "fpr = np.array(fpr_list)\n",
        "thresholds = np.array(thred_list)\n",
        "\n",
        "youdenJ = tpr - fpr\n",
        "\n",
        "# Calculate the G-mean\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "\n",
        "#Find the optimal threshold\n",
        "# Find the optimal threshold\n",
        "index = np.argmax(youdenJ)\n",
        "\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))\n",
        "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "print(\"\")\n",
        "\n",
        "##Youden's indexをもとにした正答率を計算\n",
        "#################################################\n",
        "threshold = thresholdOpt #判定基準\n",
        "#################################################\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "#print(Y)\n",
        "#print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print(\"Using Youden's index\")\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8qSHqNtlt7u",
        "outputId": "d3df9b54-2e3c-4ba3-adda-c4ab1d2023ea"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.03 with Youden J statistic: 0.9285\n",
            "FPR: 0.0571, TPR: 0.9143\n",
            "\n",
            "Using Youden's index\n",
            "confusion matrix = \n",
            " [[34  1]\n",
            " [ 5 30]]\n",
            "Accuracy : 0.9142857142857143\n",
            "Precision (true positive rate) : 0.967741935483871\n",
            "Recall (sensitivity): 0.8571428571428571\n",
            "Specificity : 0.9714285714285714\n",
            "F1 score : 0.909090909090909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#ざっくり10点でROC curveを描いてみる\n",
        "thred_list = [i/100 for i in range(100)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)\n",
        "\n",
        "print(\"pt_gla: \", pt_gla)\n",
        "print(\"pt_cont: \", pt_cont)"
      ],
      "metadata": {
        "id": "pfKbgAQamSBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#点数を増やして描画し直し\n",
        "#※ものすごく時間かかる\n",
        "thred_list = [i/100000 for i in range(100000)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "PQVuhK83yKKV",
        "outputId": "8efb08a0-4875-4e8f-da4d-5183bb20d00e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1症例1枚ずつ選択した場合の正解率を計算\n",
        "#1症例中の画像の選択 -> random_state で探索\n",
        "#controlの画像選択 -> random.seedで固定\n",
        "\n",
        "##############################\n",
        "random.seed(1398) #ここは先に入力しておく\n",
        "##############################\n",
        "\n",
        "seed_list = []\n",
        "f1_list = []\n",
        "specificity_list =  []\n",
        "sensitivity_list = []\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    df_temp = df_temp.sample(n=1, random_state = seed) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred\n",
        "\n",
        "\n",
        "for seed in list(range(0, 100, 1)):\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "    df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"number_of_img\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "    #gla群\n",
        "    pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "    #cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "    pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "    pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "    ##Calcurate the Youden's J static\n",
        "    #https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "    tpr = np.array(tpr_list)\n",
        "    fpr = np.array(fpr_list)\n",
        "    thresholds = np.array(thred_list)\n",
        "\n",
        "    youdenJ = tpr - fpr\n",
        "\n",
        "    #Find the optimal threshold\n",
        "    # Find the optimal threshold\n",
        "    index = np.argmax(youdenJ)\n",
        "\n",
        "    thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "    youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "    fprOpt = round(fpr[index], ndigits = 4)\n",
        "    tprOpt = round(tpr[index], ndigits = 4)\n",
        "\n",
        "    ##Youden's indexをもとにした正答率を計算\n",
        "    #################################################\n",
        "    threshold = thresholdOpt #判定基準\n",
        "    #################################################\n",
        "    for i in pt_gla:\n",
        "        pt_number = i\n",
        "        label = 1\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    for i in pt_cont:\n",
        "        pt_number = i\n",
        "        label = 0\n",
        "        threshold = threshold\n",
        "        number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "        pred = judgement(df_result, label, threshold, i)\n",
        "        df_pt_analysis.loc[i,:] = [pt_number, number_of_img, threshold, label, pred]\n",
        "\n",
        "    Y = df_pt_analysis[\"label\"].tolist()\n",
        "    Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "    #print(tp, fn, fp, tn)\n",
        "    \"\"\"\n",
        "    print(f'Random_seed : {str(seed)}')\n",
        "    print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "    print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "    print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "    print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "    print(\"\")\n",
        "    \"\"\"\n",
        "\n",
        "    seed_list.append(seed)\n",
        "    f1_list.append(f1_score(Y, Y_pred))\n",
        "    specificity_list.append(specificity_score(Y, Y_pred))\n",
        "    sensitivity_list.append(recall_score(Y, Y_pred))\n",
        "\n",
        "print(seed_list)\n",
        "print(f1_list)\n",
        "\n",
        "max_value = max(f1_list)\n",
        "idx = f1_list.index(max_value)\n",
        "print(\"seed: \", seed_list[idx])\n",
        "print(\"f1_score: \", f1_list[idx])\n",
        "\n",
        "\n",
        "df_f1 = pd.DataFrame(columns = [])\n",
        "df_f1[\"seed\"] = seed_list\n",
        "df_f1[\"f1_score\"] = f1_list\n",
        "df_f1[\"specificity\"] = specificity_list\n",
        "df_f1[\"sensitivity\"] = sensitivity_list\n",
        "df_f1"
      ],
      "metadata": {
        "id": "5HsR9cdDhzs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################################\n",
        "#ここは先に入力しておく\n",
        "random.seed(1398)\n",
        "random_state = 0\n",
        "#################################################\n",
        "\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[])\n",
        "df_pt_analysis = pd.DataFrame(index=[],columns=[\"pt_number\",\"path\",\"threshold\", \"label\", \"pred\"])\n",
        "\n",
        "#gla群\n",
        "pt_gla = df_result.loc[df_result[\"label\"]==1][\"pt_number\"].drop_duplicates().tolist()\n",
        "\n",
        "#cont群（数をgla群に揃えるよう、ランダムにピックアップ）\n",
        "pt_cont= df_result.loc[df_result[\"label\"]==0][\"pt_number\"].drop_duplicates().tolist()\n",
        "pt_cont = sorted(random.sample(pt_cont, len(pt_gla)))\n",
        "\n",
        "\n",
        "#ProbがThresholdをこえているものをカウントする\n",
        "def judgement(df_result, label, threshold, pt_number):\n",
        "    df_temp = df_result.loc[df_result[\"pt_number\"]==pt_number] #患者の画像リストをすべて抜き出す\n",
        "    df_temp = df_temp.sample(n=1, random_state=random_state) #画像が複数ある症例では、1つの画像をランダムに選択する\n",
        "    path = df_temp[\"path\"].tolist()[0]\n",
        "    prob = df_temp[[\"prob_1\",\"prob_2\", \"prob_3\", \"prob_4\", \"prob_5\"]].values.flatten() #probalilityの項目をnumpyに変換して1次元に変換\n",
        "    pred = np.where(prob > threshold, 1, 0)\n",
        "\n",
        "    #print(pt_number)\n",
        "    #print(df_temp)\n",
        "    #print(\"\")\n",
        "\n",
        "    #print(pred)\n",
        "    if label ==1:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 1, 0).tolist() #正解と不正解のどちらかが多いかの多数決をとる\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TP\", \"FN\")\n",
        "    elif label ==0:\n",
        "        pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), 0, 1).tolist()\n",
        "        #pred = np.where(np.count_nonzero(pred == label) >= np.count_nonzero(pred != label), \"TN\", \"FP\")\n",
        "    return pred, path\n",
        "\n",
        "\n",
        "##Calcurate the Youden's J static\n",
        "#https://ichi.pro/fukinkona-bunrui-no-saiteki-nashi-kiichi-97327858631315\n",
        "tpr = np.array(tpr_list)\n",
        "fpr = np.array(fpr_list)\n",
        "thresholds = np.array(thred_list)\n",
        "\n",
        "youdenJ = tpr - fpr\n",
        "\n",
        "# Calculate the G-mean\n",
        "gmean = np.sqrt(tpr * (1 - fpr))\n",
        "\n",
        "#Find the optimal threshold\n",
        "# Find the optimal threshold\n",
        "index = np.argmax(youdenJ)\n",
        "\n",
        "thresholdOpt = round(thresholds[index], ndigits = 4)\n",
        "youdenJOpt = round(gmean[index], ndigits = 4)\n",
        "fprOpt = round(fpr[index], ndigits = 4)\n",
        "tprOpt = round(tpr[index], ndigits = 4)\n",
        "print('Best Threshold: {} with Youden J statistic: {}'.format(thresholdOpt, youdenJOpt))\n",
        "print('FPR: {}, TPR: {}'.format(fprOpt, tprOpt))\n",
        "print(\"\")\n",
        "\n",
        "##Youden's indexをもとにした正答率を計算\n",
        "#################################################\n",
        "threshold = thresholdOpt #判定基準\n",
        "#################################################\n",
        "\n",
        "for i in pt_gla:\n",
        "    pt_number = i\n",
        "    label = 1\n",
        "    threshold = threshold\n",
        "    path = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred, path = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, path, threshold, label, pred]\n",
        "\n",
        "for i in pt_cont:\n",
        "    pt_number = i\n",
        "    label = 0\n",
        "    threshold = threshold\n",
        "    number_of_img = df_result[\"pt_number\"][df_result[\"pt_number\"] == i].count()\n",
        "    pred, path = judgement(df_result, label, threshold, i)\n",
        "    df_pt_analysis.loc[i,:] = [pt_number, path, threshold, label, pred]\n",
        "\n",
        "\n",
        "Y = df_pt_analysis[\"label\"].tolist()\n",
        "Y_pred = df_pt_analysis[\"pred\"].tolist()\n",
        "\n",
        "#print(Y)\n",
        "#print(Y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(Y, Y_pred).ravel()\n",
        "#print(tp, fn, fp, tn)\n",
        "print(\"Using Youden's index\")\n",
        "print('confusion matrix = \\n', confusion_matrix(Y, Y_pred))\n",
        "print(f'Accuracy : {accuracy_score(Y, Y_pred)}')\n",
        "print(f'Precision (true positive rate) : {precision_score(Y, Y_pred)}')\n",
        "print(f'Recall (sensitivity): {recall_score(Y, Y_pred)}')\n",
        "print(f'Specificity : {specificity_score(Y, Y_pred)}')\n",
        "print(f'F1 score : {f1_score(Y, Y_pred)}')\n",
        "\n",
        "#df_pt_analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "1CrsGCam63DW",
        "outputId": "7205f9a0-c87b-43bf-9d48-d1f0a6462aa7"
      },
      "execution_count": 337,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [337]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m gmean \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(tpr \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m fpr))\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m#Find the optimal threshold\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Find the optimal threshold\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43myoudenJ\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m thresholdOpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(thresholds[index], ndigits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     56\u001b[0m youdenJOpt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(gmean[index], ndigits \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m)\n",
            "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1216\u001b[0m, in \u001b[0;36margmax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   1129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m \u001b[38;5;124;03mReturns the indices of the maximum values along an axis.\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;124;03m(2, 1, 4)\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m kwds \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeepdims\u001b[39m\u001b[38;5;124m'\u001b[39m: keepdims} \u001b[38;5;28;01mif\u001b[39;00m keepdims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39m_NoValue \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m-> 1216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
            "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ざっくり10点でROC curveを描いてみる\n",
        "thred_list = [i/100 for i in range(100)]\n",
        "fpr_list = []\n",
        "tpr_list = []\n",
        "cutoff_criterions = []\n",
        "\n",
        "for i in thred_list:\n",
        "    fpr, tpr = calculate_fpr_tpr(pt_gla, pt_cont, df_result, i)\n",
        "    fpr_list.append(fpr)\n",
        "    tpr_list.append(tpr)\n",
        "\n",
        "#print(fpr_list)\n",
        "#print(tpr_list)\n",
        "#print(thred_list)\n",
        "\n",
        "Draw_roc_curve_patients(fpr_list, tpr_list, thred_list)\n",
        "\n",
        "print(\"pt_gla: \", pt_gla)\n",
        "print(\"pt_cont: \", pt_cont)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "W_w_ojI_JNuW",
        "outputId": "5f21eed8-c402-43a0-f87e-dce4283b4aaa"
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Input \u001b[1;32mIn [336]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m cutoff_criterions \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m thred_list:\n\u001b[1;32m---> 11\u001b[0m     fpr, tpr \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_fpr_tpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpt_gla\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpt_cont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     fpr_list\u001b[38;5;241m.\u001b[39mappend(fpr)\n\u001b[0;32m     13\u001b[0m     tpr_list\u001b[38;5;241m.\u001b[39mappend(tpr)\n",
            "Input \u001b[1;32mIn [185]\u001b[0m, in \u001b[0;36mcalculate_fpr_tpr\u001b[1;34m(pt_gla, pt_cont, df_result, threshold)\u001b[0m\n\u001b[0;32m     53\u001b[0m     label_list\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[0;32m     54\u001b[0m     pred_list\u001b[38;5;241m.\u001b[39mappend(pred)\n\u001b[1;32m---> 55\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m     56\u001b[0m fpr, tpr \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m/\u001b[39m(tn\u001b[38;5;241m+\u001b[39mfp), tp\u001b[38;5;241m/\u001b[39m(tp\u001b[38;5;241m+\u001b[39mfn)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fpr, tpr\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    224\u001b[0m ):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
            "File \u001b[1;32mc:\\users\\ykita\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
            "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multiclass-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pt_analysis"
      ],
      "metadata": {
        "id": "8cgB_7wdpjHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nineplotを用いた描画（今回は不要）\n",
        "\n",
        "# Import module for data manipulation\n",
        "import pandas as pd\n",
        "# Import module for linear algebra\n",
        "import numpy as np\n",
        "# Import module for data simulation\n",
        "from sklearn.datasets import make_classification     # Create a synthetic dataframe\n",
        "from sklearn.linear_model import LogisticRegression  # Classification model\n",
        "from sklearn.model_selection import train_test_split # Split the dataframe\n",
        "from sklearn.metrics import roc_curve                # Calculate the ROC curve\n",
        "from sklearn.metrics import precision_recall_curve   # Calculate the Precision-Recall curve\n",
        "from sklearn.metrics import f1_score                 # Calculate the F-score\n",
        "# Import module for data visualization\n",
        "import plotnine\n",
        "from plotnine import ggplot, geom_point, geom_path, geom_text, labs, aes, xlab, ylab, stat_smooth, theme_minimal, facet_wrap\n",
        "from plotnine.data import mtcars\n",
        "\n",
        "\n",
        "# Plot the ROC curve\n",
        "df_fpr_tpr = pd.DataFrame({'FPR':fpr, 'TPR':tpr, 'Threshold':thresholds})\n",
        "df_fpr_tpr.head()\n",
        "\n",
        "\n",
        "plotnine.options.figure_size = (8, 6)\n",
        "(\n",
        "ggplot(data = df_fpr_tpr)+\n",
        "    geom_point(aes(x = 'FPR',\n",
        "                   y = 'TPR'),\n",
        "               size=0.01)+ \n",
        "    \n",
        "    # Best threshold\n",
        "    geom_point(aes(x = fprOpt,\n",
        "                   y = tprOpt),\n",
        "               color = '#981220',\n",
        "               size = 4)+\n",
        "    \n",
        "\n",
        "    geom_path(aes(x = 'FPR',\n",
        "                  y = 'TPR'))+\n",
        "    # Annotate the text\n",
        "    geom_text(aes(x = fprOpt,\n",
        "                  y = tprOpt),\n",
        "              label = 'Optimal threshold for \\n negative class {}'.format(thresholdOpt),\n",
        "              nudge_x = 0.14,\n",
        "              nudge_y = -0.10,\n",
        "              size = 10,\n",
        "              family = 'arial',\n",
        "              fontstyle = 'normal')+\n",
        "    labs(title = 'ROC Curve')+\n",
        "    xlab('False Positive Rate (FPR)')+\n",
        "    ylab('True Positive Rate (TPR)')+\n",
        "    theme_minimal()\n",
        ")"
      ],
      "metadata": {
        "id": "F1OyKBSsbB-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_imglist = pd.DataFrame(columns = [\"path\", \"label\", \"AI\"])\n",
        "df_imglist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "7BFaIIH3E9lC",
        "outputId": "d023a9dd-0531-47cb-cb1d-ac83ce2ff20f"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [path, label]\n",
              "Index: []"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KNwO8jq_A_5T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}